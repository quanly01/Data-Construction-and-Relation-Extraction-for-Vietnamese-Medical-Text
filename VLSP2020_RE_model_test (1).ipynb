{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["cJJS0PLthZZE","JcwMQApng86X"],"machine_shape":"hm","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"db2490257a1f4c3987221f328a5fe50b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc784e410ea846d6a93ad44276558dce","IPY_MODEL_c76a14f7f1f04fafb5ddea23df1b0f14","IPY_MODEL_8ef9915c5f3c4894a638db21165de2ae"],"layout":"IPY_MODEL_7720382dbb90415299464ec071d86010"}},"cc784e410ea846d6a93ad44276558dce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8a1900375f94d348175a67f60441331","placeholder":"​","style":"IPY_MODEL_1663ebc6776b4be69a89470f259a38f8","value":"config.json: 100%"}},"c76a14f7f1f04fafb5ddea23df1b0f14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82ede0c8ddd7495a9087f001efb8b847","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e53a721a37c4ac89ea08ba0ade154b4","value":557}},"8ef9915c5f3c4894a638db21165de2ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad78a146179a4a84a4ed04f6afb18d05","placeholder":"​","style":"IPY_MODEL_97e9667ba90b4605af0f3db4a718f798","value":" 557/557 [00:00&lt;00:00, 17.5kB/s]"}},"7720382dbb90415299464ec071d86010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a1900375f94d348175a67f60441331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1663ebc6776b4be69a89470f259a38f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82ede0c8ddd7495a9087f001efb8b847":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e53a721a37c4ac89ea08ba0ade154b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad78a146179a4a84a4ed04f6afb18d05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97e9667ba90b4605af0f3db4a718f798":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd991df19d054a95bc797f8512b9a843":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_515d452cfb614ac68bcd85e90833689f","IPY_MODEL_2b8da848464b4944a297559caa73b1b6","IPY_MODEL_bc819b39848d49ceb6ce1d9bfe6f61c0"],"layout":"IPY_MODEL_cc48aab445ce4779b88030779526ab0c"}},"515d452cfb614ac68bcd85e90833689f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1065b961d3044719d483eb5b3591f43","placeholder":"​","style":"IPY_MODEL_18737bb3284d491da82b681700560010","value":"vocab.txt: 100%"}},"2b8da848464b4944a297559caa73b1b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb73d971096b4da0a33f122fc53b94ba","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30146bfd162146c18d30726deac25276","value":895321}},"bc819b39848d49ceb6ce1d9bfe6f61c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd01e6796a94411c94138e4aaa790561","placeholder":"​","style":"IPY_MODEL_c0b609489b6945e59838c4593e143f81","value":" 895k/895k [00:00&lt;00:00, 3.86MB/s]"}},"cc48aab445ce4779b88030779526ab0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1065b961d3044719d483eb5b3591f43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18737bb3284d491da82b681700560010":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb73d971096b4da0a33f122fc53b94ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30146bfd162146c18d30726deac25276":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd01e6796a94411c94138e4aaa790561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0b609489b6945e59838c4593e143f81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9515a031c6ad4e798b695b595b1afae4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3442301c928642528be3ac1ae1eeeb12","IPY_MODEL_d2de6a3922494e5bb42a3adcdd271fdc","IPY_MODEL_bce71def893149e4b7dd30ce3e0f23f3"],"layout":"IPY_MODEL_fbea91a6a780458c959177f3074e07f8"}},"3442301c928642528be3ac1ae1eeeb12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d33b75c9c6ab4f90bd62f086be566be4","placeholder":"​","style":"IPY_MODEL_9d6f15bbc36349949e38badef3fb7e7f","value":"bpe.codes: 100%"}},"d2de6a3922494e5bb42a3adcdd271fdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2d5c31fd6c447ddaf775ba4acf26918","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a577488c7fc4564be73ad31fd60b173","value":1135173}},"bce71def893149e4b7dd30ce3e0f23f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e89ec46a4a434fcabc515301a672ad61","placeholder":"​","style":"IPY_MODEL_8eb7b03a42464d25aab6f9fbadbfe27f","value":" 1.14M/1.14M [00:00&lt;00:00, 1.43MB/s]"}},"fbea91a6a780458c959177f3074e07f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d33b75c9c6ab4f90bd62f086be566be4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d6f15bbc36349949e38badef3fb7e7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2d5c31fd6c447ddaf775ba4acf26918":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a577488c7fc4564be73ad31fd60b173":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e89ec46a4a434fcabc515301a672ad61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb7b03a42464d25aab6f9fbadbfe27f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"157307f9b64f4e1289296c724232a89d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65e3541be15e40ada4a3aefad5d446e8","IPY_MODEL_40edc72976034beeb53efb24db1848a0","IPY_MODEL_003afa1110b14256a721f0e6d1ea76c3"],"layout":"IPY_MODEL_f95c57f4ae64433fbbe407e32d4b295f"}},"65e3541be15e40ada4a3aefad5d446e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a27a5544e805455ca7be5ef5b844601f","placeholder":"​","style":"IPY_MODEL_e9f8ca3d59274eddba53f463f6253a6e","value":"tokenizer.json: 100%"}},"40edc72976034beeb53efb24db1848a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9dbbec7a8d0466d9013fe753e523d96","max":3132320,"min":0,"orientation":"horizontal","style":"IPY_MODEL_972f2e403c1c4dd9b4393cadcbee1933","value":3132320}},"003afa1110b14256a721f0e6d1ea76c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a8d67377e6246fa8cec09096ba39175","placeholder":"​","style":"IPY_MODEL_c7640e7b918241b89473eecce9b718d7","value":" 3.13M/3.13M [00:03&lt;00:00, 802kB/s]"}},"f95c57f4ae64433fbbe407e32d4b295f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27a5544e805455ca7be5ef5b844601f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9f8ca3d59274eddba53f463f6253a6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9dbbec7a8d0466d9013fe753e523d96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"972f2e403c1c4dd9b4393cadcbee1933":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a8d67377e6246fa8cec09096ba39175":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7640e7b918241b89473eecce9b718d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2c2c87be7b54207b4aa2d80e2c85031":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db66da187baa4a86b5ce568fba46eeef","IPY_MODEL_908f9971a60e4e9bacfd33b9dacb4f0e","IPY_MODEL_eb7fcc35052a494ca795dc69de48992c"],"layout":"IPY_MODEL_2bb5c47550884936ac20601c71fc8836"}},"db66da187baa4a86b5ce568fba46eeef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_936f5967caa7465fa698348d98cb6f39","placeholder":"​","style":"IPY_MODEL_3f4bae5074f541cbaa4f90dec8fae6d2","value":"config.json: 100%"}},"908f9971a60e4e9bacfd33b9dacb4f0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47e9a3e5cca84537b871d1a3f1a34de3","max":558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06dc0ac2437d42e0811e16bb6e71ce73","value":558}},"eb7fcc35052a494ca795dc69de48992c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdf44127480247dda5498dc2cc708919","placeholder":"​","style":"IPY_MODEL_0d887999f962471e8f8f1ad30241d32c","value":" 558/558 [00:00&lt;00:00, 10.8kB/s]"}},"2bb5c47550884936ac20601c71fc8836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"936f5967caa7465fa698348d98cb6f39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f4bae5074f541cbaa4f90dec8fae6d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47e9a3e5cca84537b871d1a3f1a34de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06dc0ac2437d42e0811e16bb6e71ce73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fdf44127480247dda5498dc2cc708919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d887999f962471e8f8f1ad30241d32c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9faf786b6b12481a9f0053a1379b61b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bc10d1dc34f473085711fe97bb7702b","IPY_MODEL_460e68ae0df445a5bc59af15c2255a44","IPY_MODEL_911a290f767f45c58f0d225b820d0f01"],"layout":"IPY_MODEL_d1058877cef84901941dcaaf9a302faa"}},"4bc10d1dc34f473085711fe97bb7702b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd033c47510846cf8d16e8ba933da003","placeholder":"​","style":"IPY_MODEL_21525531c8724178a3a236829e2ee085","value":"vocab.txt: 100%"}},"460e68ae0df445a5bc59af15c2255a44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec142c0397b342bba4ad840835a774ab","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05cfe5ce0ac24f62a152c630f6fc038d","value":895321}},"911a290f767f45c58f0d225b820d0f01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39b197e78dea4c9d97fbec70f4aeef22","placeholder":"​","style":"IPY_MODEL_d991c6803cb248b4aaee52c48cbf0e73","value":" 895k/895k [00:00&lt;00:00, 1.12MB/s]"}},"d1058877cef84901941dcaaf9a302faa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd033c47510846cf8d16e8ba933da003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21525531c8724178a3a236829e2ee085":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec142c0397b342bba4ad840835a774ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05cfe5ce0ac24f62a152c630f6fc038d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39b197e78dea4c9d97fbec70f4aeef22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d991c6803cb248b4aaee52c48cbf0e73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40ad02638b174e7fa4890ab9ef992001":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88c1d2d6383a47fa800b059fb6a873fd","IPY_MODEL_7c9dd791dd4d47f5b9af957bae334f79","IPY_MODEL_f63bff3c862d4a9783adbeff352d838b"],"layout":"IPY_MODEL_3fabc18e4564481c9345cec0aa73c0bf"}},"88c1d2d6383a47fa800b059fb6a873fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf47f8efd86d489bb116bab1cd091f9d","placeholder":"​","style":"IPY_MODEL_4bf39bc437fa46d6ab4d7a294fe3609c","value":"bpe.codes: 100%"}},"7c9dd791dd4d47f5b9af957bae334f79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b615cbacc594dab94688158b2ced87f","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24be0f87fdd04b2f8da8aa13a13a76af","value":1135173}},"f63bff3c862d4a9783adbeff352d838b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_689e1083c1d64022a8c399b755802d5f","placeholder":"​","style":"IPY_MODEL_f8e1757f1e524baea9917f5b9b1606c5","value":" 1.14M/1.14M [00:00&lt;00:00, 2.70MB/s]"}},"3fabc18e4564481c9345cec0aa73c0bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf47f8efd86d489bb116bab1cd091f9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bf39bc437fa46d6ab4d7a294fe3609c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b615cbacc594dab94688158b2ced87f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24be0f87fdd04b2f8da8aa13a13a76af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"689e1083c1d64022a8c399b755802d5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e1757f1e524baea9917f5b9b1606c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"352559c3b5f746ec8a231768e3493818":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c9fcf3ae099415d9a03d69ff6e60809","IPY_MODEL_b5e304ea085f4614875a1baf29375442","IPY_MODEL_af315ad357484d93a4b0fd37745b3524"],"layout":"IPY_MODEL_034cfc0b8589446cad48d20405d1c55b"}},"0c9fcf3ae099415d9a03d69ff6e60809":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f413df97da3e44f0abed098a4ef35363","placeholder":"​","style":"IPY_MODEL_af63673e3aa34a57af83b71a74adf194","value":"tokenizer.json: 100%"}},"b5e304ea085f4614875a1baf29375442":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad5e1dce0544dcf86fb9ade999986b3","max":3132320,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c41eefb0d41546dbb162d704e4c3757b","value":3132320}},"af315ad357484d93a4b0fd37745b3524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a448589abb1c4a7191235990a630914f","placeholder":"​","style":"IPY_MODEL_4195a8bb7ba74cebb8f674bf26239c93","value":" 3.13M/3.13M [00:02&lt;00:00, 1.09MB/s]"}},"034cfc0b8589446cad48d20405d1c55b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f413df97da3e44f0abed098a4ef35363":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af63673e3aa34a57af83b71a74adf194":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ad5e1dce0544dcf86fb9ade999986b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41eefb0d41546dbb162d704e4c3757b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a448589abb1c4a7191235990a630914f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4195a8bb7ba74cebb8f674bf26239c93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfa6b2c4846d4ed18b58c0fafff59883":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebedbeb711714718bc103551b27b1898","IPY_MODEL_d107fa4dd0414b048ce042dd350ad37e","IPY_MODEL_17153b4cb847435bbe5b8a577fc4279b"],"layout":"IPY_MODEL_cdcb5a0aa062457086ff75a9acacb982"}},"ebedbeb711714718bc103551b27b1898":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a98b337efbf4c5fbdd1009ee059ff14","placeholder":"​","style":"IPY_MODEL_4309dca5fbef404785f93d8b78013702","value":"tokenizer_config.json: 100%"}},"d107fa4dd0414b048ce042dd350ad37e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6141883516e7482ab67f96ddbff61796","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30d263de09c04ab3b0bb5d8202302bf1","value":25}},"17153b4cb847435bbe5b8a577fc4279b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b39d76f833524a7c86152798870ce4d9","placeholder":"​","style":"IPY_MODEL_9de7716bc26d4c6eba078eb1e041619f","value":" 25.0/25.0 [00:00&lt;00:00, 1.53kB/s]"}},"cdcb5a0aa062457086ff75a9acacb982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a98b337efbf4c5fbdd1009ee059ff14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4309dca5fbef404785f93d8b78013702":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6141883516e7482ab67f96ddbff61796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30d263de09c04ab3b0bb5d8202302bf1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b39d76f833524a7c86152798870ce4d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9de7716bc26d4c6eba078eb1e041619f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f8fbccbf80d4879b9c01172b0f0b07c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22085ef061da4cde8cfdacf432aa0e1f","IPY_MODEL_a180af7667914d64bef82827a8404d05","IPY_MODEL_d92d0fddb44347d985a4c6f87930a481"],"layout":"IPY_MODEL_96eb8c4d95bc4a0cb3dc7146a9e2e96b"}},"22085ef061da4cde8cfdacf432aa0e1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef610bf4a5a4e7eaf725daf988463e8","placeholder":"​","style":"IPY_MODEL_989bcb5bad464ab2833ec8c7cffa189d","value":"sentencepiece.bpe.model: 100%"}},"a180af7667914d64bef82827a8404d05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3d5a4a48ded4300b41e442368fd140f","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9513e81b1db14731979ac125c54b8d33","value":5069051}},"d92d0fddb44347d985a4c6f87930a481":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b99414edac014d68860690afa198ed83","placeholder":"​","style":"IPY_MODEL_416ad08d91174ace95ccd048cf277c3a","value":" 5.07M/5.07M [00:00&lt;00:00, 11.4MB/s]"}},"96eb8c4d95bc4a0cb3dc7146a9e2e96b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fef610bf4a5a4e7eaf725daf988463e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"989bcb5bad464ab2833ec8c7cffa189d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3d5a4a48ded4300b41e442368fd140f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9513e81b1db14731979ac125c54b8d33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b99414edac014d68860690afa198ed83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416ad08d91174ace95ccd048cf277c3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fe4e95222364ce49315b30690434060":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c69a17e4965d44c7a18fc85803111841","IPY_MODEL_7c10c61c7f52412b944150b07201ec49","IPY_MODEL_b8cf99ad2b2a4c7f854178837434abdb"],"layout":"IPY_MODEL_4d90e4e8d33f44ed8c51206e2c34be99"}},"c69a17e4965d44c7a18fc85803111841":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4079f6743b6f47ffa0ab5396249dfe6b","placeholder":"​","style":"IPY_MODEL_c40484c17ea14588bc568c0895591e6e","value":"tokenizer.json: 100%"}},"7c10c61c7f52412b944150b07201ec49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b42b2806e9094203af8d7796f65e723a","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bd13a768f6d40dd964cda589f21de10","value":9096718}},"b8cf99ad2b2a4c7f854178837434abdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0d2acabf3ce4901acf1e255a2dddbeb","placeholder":"​","style":"IPY_MODEL_ae23e80e0fdb488c8dc08240ccb66508","value":" 9.10M/9.10M [00:01&lt;00:00, 7.95MB/s]"}},"4d90e4e8d33f44ed8c51206e2c34be99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4079f6743b6f47ffa0ab5396249dfe6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c40484c17ea14588bc568c0895591e6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b42b2806e9094203af8d7796f65e723a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bd13a768f6d40dd964cda589f21de10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0d2acabf3ce4901acf1e255a2dddbeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae23e80e0fdb488c8dc08240ccb66508":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e12e084d9490418fa4b6097f3b2d23c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1d2bf7b147d4e96b09719fbd58c3ab1","IPY_MODEL_3daf23f10f2d4c2f8672bea34baec6c3","IPY_MODEL_b2a70ee9e05f430da5cfb3970cd23570"],"layout":"IPY_MODEL_fd04dd2a96fd4f229f36fb0bbf121993"}},"d1d2bf7b147d4e96b09719fbd58c3ab1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_844eb6e2e34c457f8f859522d266b842","placeholder":"​","style":"IPY_MODEL_6f6476e1a95d4f1d988d5b26d74bd89d","value":"config.json: 100%"}},"3daf23f10f2d4c2f8672bea34baec6c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_748fe039ee0847ef83b36acc37f4efef","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd8e99fb82cf46cb9a8179451da59c9d","value":615}},"b2a70ee9e05f430da5cfb3970cd23570":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72f59b531bac41e2b62b9383cedced1c","placeholder":"​","style":"IPY_MODEL_9eaa04a8988a4c0f84328fd16d1f3c80","value":" 615/615 [00:00&lt;00:00, 22.7kB/s]"}},"fd04dd2a96fd4f229f36fb0bbf121993":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844eb6e2e34c457f8f859522d266b842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f6476e1a95d4f1d988d5b26d74bd89d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"748fe039ee0847ef83b36acc37f4efef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd8e99fb82cf46cb9a8179451da59c9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72f59b531bac41e2b62b9383cedced1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eaa04a8988a4c0f84328fd16d1f3c80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53444fe889174f79a26cda68a6478dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75b18326b4fb428daa311d35069f6bee","IPY_MODEL_e8318e7a10634a0b90368843f892aca7","IPY_MODEL_a917bbe12cb84cd38d41d7ccc117b5d3"],"layout":"IPY_MODEL_68bcca7aab2b4a2aa29a85d61c3ec423"}},"75b18326b4fb428daa311d35069f6bee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8e10a3f0537423fa995682e790325e8","placeholder":"​","style":"IPY_MODEL_e17cb1dabce045a7bdf040b3a4339ff1","value":"tokenizer_config.json: 100%"}},"e8318e7a10634a0b90368843f892aca7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4817be7d0c343959d866f368ae308e8","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f905098202c242b1adcb163229dde08c","value":25}},"a917bbe12cb84cd38d41d7ccc117b5d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93f6b27f3e654af8b9da176f80d7f906","placeholder":"​","style":"IPY_MODEL_2b821f2c59024041bfef2706213620ee","value":" 25.0/25.0 [00:00&lt;00:00, 1.64kB/s]"}},"68bcca7aab2b4a2aa29a85d61c3ec423":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8e10a3f0537423fa995682e790325e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e17cb1dabce045a7bdf040b3a4339ff1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4817be7d0c343959d866f368ae308e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f905098202c242b1adcb163229dde08c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93f6b27f3e654af8b9da176f80d7f906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b821f2c59024041bfef2706213620ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f7bd6f631264a48b03054ef6566c9c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35526c78c698493585376c52d4b7f68c","IPY_MODEL_efdadd624f4f48b0ab7f54ff8a205639","IPY_MODEL_db55de1fe8c84ebf8b85debb83123403"],"layout":"IPY_MODEL_1f94dbe1bc9a471ca81d9b20d77435c4"}},"35526c78c698493585376c52d4b7f68c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e9ae9e7a6414ddaa4bb24e79ddd131c","placeholder":"​","style":"IPY_MODEL_7bfbf827e4b64a38aeaad15c20f8b0b6","value":"sentencepiece.bpe.model: 100%"}},"efdadd624f4f48b0ab7f54ff8a205639":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1d669bb6df409aa75c8d45a5678368","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_608be1953ff448f0b71803fcc95c1f3a","value":5069051}},"db55de1fe8c84ebf8b85debb83123403":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aea8268213e84badbbdd928cd6a228e4","placeholder":"​","style":"IPY_MODEL_602192a9fa96415f9c92ea18553ef46d","value":" 5.07M/5.07M [00:00&lt;00:00, 12.4MB/s]"}},"1f94dbe1bc9a471ca81d9b20d77435c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e9ae9e7a6414ddaa4bb24e79ddd131c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bfbf827e4b64a38aeaad15c20f8b0b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e1d669bb6df409aa75c8d45a5678368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"608be1953ff448f0b71803fcc95c1f3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aea8268213e84badbbdd928cd6a228e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"602192a9fa96415f9c92ea18553ef46d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39c428138a5b4377bf64483e09f563ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a61c918696e48c986298f008fbf3b3e","IPY_MODEL_5c12dbe3a5d24111b10e41bd9a9b8077","IPY_MODEL_a419934029ee49af9d23142545f8b9ad"],"layout":"IPY_MODEL_70ccd0a7e13940fd9a9cbddf481b4393"}},"3a61c918696e48c986298f008fbf3b3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d66a68732b044739cea603db9dc0d1c","placeholder":"​","style":"IPY_MODEL_e033bfaf5db348b89c6f1983cccd2d97","value":"tokenizer.json: 100%"}},"5c12dbe3a5d24111b10e41bd9a9b8077":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91b4d7997fb3456e87177d6d98a531dc","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45e5c095a29b4d93b4a74edd1a11718b","value":9096718}},"a419934029ee49af9d23142545f8b9ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5dba4d83ee54468b309d1ba33188bc9","placeholder":"​","style":"IPY_MODEL_d20a167a5c214d06811636f303d6b692","value":" 9.10M/9.10M [00:00&lt;00:00, 31.8MB/s]"}},"70ccd0a7e13940fd9a9cbddf481b4393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d66a68732b044739cea603db9dc0d1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e033bfaf5db348b89c6f1983cccd2d97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91b4d7997fb3456e87177d6d98a531dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e5c095a29b4d93b4a74edd1a11718b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5dba4d83ee54468b309d1ba33188bc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d20a167a5c214d06811636f303d6b692":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf90bf113cb74d39812efe68cb285372":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b28aed0a641844fe8df6a2f7c357f24c","IPY_MODEL_bcc9bd832ae94af1bc302d3bbc3fd68b","IPY_MODEL_a85ca344ca264b30af21c2d6d048c452"],"layout":"IPY_MODEL_1654c4191e1c4c5694e36c931a89e9e6"}},"b28aed0a641844fe8df6a2f7c357f24c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be282a816b8c4932a2ed1993d330564f","placeholder":"​","style":"IPY_MODEL_bd69cca9c4f8448cb9c20d7e84196783","value":"config.json: 100%"}},"bcc9bd832ae94af1bc302d3bbc3fd68b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1598ef5c8589408f838c683ec00a9b96","max":616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c250d90c8f840d299e31313c25a638c","value":616}},"a85ca344ca264b30af21c2d6d048c452":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faebc45024d94675a09324ce14a39aae","placeholder":"​","style":"IPY_MODEL_a395d5aa58954d799903a96ab792dbff","value":" 616/616 [00:00&lt;00:00, 43.9kB/s]"}},"1654c4191e1c4c5694e36c931a89e9e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be282a816b8c4932a2ed1993d330564f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd69cca9c4f8448cb9c20d7e84196783":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1598ef5c8589408f838c683ec00a9b96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c250d90c8f840d299e31313c25a638c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"faebc45024d94675a09324ce14a39aae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a395d5aa58954d799903a96ab792dbff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"XFbOntuVkYZ7"},"source":["# Get data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBXHW6YDkJGo","outputId":"6c4c864a-57c1-42e5-cda9-486f689cc883","executionInfo":{"status":"ok","timestamp":1717425063339,"user_tz":-420,"elapsed":29239,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4i008g3mMQjV","outputId":"b19bab80-a8fc-462d-a3bd-e5d66585c0e5","executionInfo":{"status":"ok","timestamp":1717425065774,"user_tz":-420,"elapsed":2437,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["!ls \"/gdrive/MyDrive/VLSP2020_RE/json_data\""],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["dev_data.json\t     train_data_new_10.json  train_data_new_18.json  train_data_new_26.json\n","RE_dev_data.json     train_data_new_11.json  train_data_new_19.json  train_data_new_3.json\n","RE_dev.json\t     train_data_new_12.json  train_data_new_20.json  train_data_new_5.json\n","RE_train_data.json   train_data_new_13.json  train_data_new_21.json  train_data_new_6.json\n","RE__train.json\t     train_data_new_14.json  train_data_new_22.json  train_data_new_7.json\n","RE__train_ver2.json  train_data_new_15.json  train_data_new_23.json  train_data_new_9.json\n","test_data_v2.json    train_data_new_16.json  train_data_new_24.json  train_data_new.json\n","train_data.json      train_data_new_17.json  train_data_new_25.json  train_data_new_new.json\n"]}]},{"cell_type":"code","metadata":{"id":"D-e5X6WSNPUk","executionInfo":{"status":"ok","timestamp":1717425065774,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# !cp -i \"/gdrive/MyDrive/VLSP2020_RE/json_data/test_data_v2.json\" test_data.json"],"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!cp -i \"/gdrive/MyDrive/VLSP2020_RE/json_data/dev_data.json\" test_data.json"],"metadata":{"id":"Q2d86xD3fD2z","executionInfo":{"status":"ok","timestamp":1717425066369,"user_tz":-420,"elapsed":597,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HsVFPOEqKivl"},"source":["# Install Library"]},{"cell_type":"markdown","metadata":{"id":"YmLDKiKvqMvj"},"source":["## Intsall Pytorch"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpLCC4CRqP2A","outputId":"fd9b397f-7b0a-4ac6-fd11-e15cb9b8a505","executionInfo":{"status":"ok","timestamp":1717425076627,"user_tz":-420,"elapsed":10260,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.5.1+cu101 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6, 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.5.1+cu101\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"rbbwIE69LJGt"},"source":["## Install Huggingface Transformers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0wOcO4VKUgl","outputId":"339c5b13-0bd7-4be0-cfbe-1d05f166ab56","executionInfo":{"status":"ok","timestamp":1717425091197,"user_tz":-420,"elapsed":14575,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# new command in huggingface v4.x has some anoy change. so better use old version for now\n","# https://github.com/huggingface/transformers/releases\n","\n","!pip install transformers==3.5.1"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from transformers==3.5.1) (1.25.2)\n","Collecting tokenizers==0.9.3 (from transformers==3.5.1)\n","  Downloading tokenizers-0.9.3.tar.gz (172 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from transformers==3.5.1) (24.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==3.5.1) (3.14.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==3.5.1) (2.31.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==3.5.1) (4.66.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==3.5.1) (2024.5.15)\n","Collecting sentencepiece==0.1.91 (from transformers==3.5.1)\n","  Downloading sentencepiece-0.1.91.tar.gz (500 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}]},{"cell_type":"markdown","metadata":{"id":"3HoxrF8WKupX"},"source":["## Install VNCoreNLP"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYXTRsYRKoJn","outputId":"823798d9-f84a-4f1a-ef9b-c1cbd21a9a20","executionInfo":{"status":"ok","timestamp":1717425099339,"user_tz":-420,"elapsed":8144,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# Install the vncorenlp python wrapper\n","!pip install vncorenlp"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vncorenlp) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2024.2.2)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645932 sha256=46abf3a6bd29127d7ae4cb27252ae55939fcc9d47fb24e55d81c59b112d71f1f\n","  Stored in directory: /root/.cache/pip/wheels/5d/d9/b3/41f6c6b1ab758561fd4aab55dc0480b9d7a131c6aaa573a3fa\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G95nbje5KxnD","outputId":"d80b6f4c-bf85-4853-aaaa-6348a740c737","executionInfo":{"status":"ok","timestamp":1717425112431,"user_tz":-420,"elapsed":13094,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# Download VnCoreNLP-1.1.1.jar & all of its  component (i.e. RDRSegmenter, pos, ner, deprel)\n","!mkdir -p vncorenlp/models/wordsegmenter\n","!mkdir -p vncorenlp/models/dep\n","!mkdir -p vncorenlp/models/ner\n","!mkdir -p vncorenlp/models/postagger\n","\n","\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/dep/vi-dep.xz\n","\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n","\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger\n","\n","\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/\n","\n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n","\n","!mv vi-dep.xz vncorenlp/models/dep/\n","\n","!mv vi-500brownclusters.xz vncorenlp/models/ner/\n","!mv vi-ner.xz vncorenlp/models/ner/\n","!mv vi-pretrainedembeddings.xz vncorenlp/models/ner/\n","\n","!mv vi-tagger vncorenlp/models/postagger/\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-06-03 14:31:34--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27412575 (26M) [application/octet-stream]\n","Saving to: ‘VnCoreNLP-1.1.1.jar’\n","\n","VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  55.1MB/s    in 0.5s    \n","\n","2024-06-03 14:31:36 (55.1 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n","\n","--2024-06-03 14:31:36--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 526544 (514K) [application/octet-stream]\n","Saving to: ‘vi-vocab’\n","\n","vi-vocab            100%[===================>] 514.20K  3.03MB/s    in 0.2s    \n","\n","2024-06-03 14:31:37 (3.03 MB/s) - ‘vi-vocab’ saved [526544/526544]\n","\n","--2024-06-03 14:31:37--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 128508 (125K) [text/plain]\n","Saving to: ‘wordsegmenter.rdr’\n","\n","wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.08s   \n","\n","2024-06-03 14:31:37 (1.54 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n","\n","--2024-06-03 14:31:37--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/dep/vi-dep.xz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16048864 (15M) [application/octet-stream]\n","Saving to: ‘vi-dep.xz’\n","\n","vi-dep.xz           100%[===================>]  15.30M  38.9MB/s    in 0.4s    \n","\n","2024-06-03 14:31:39 (38.9 MB/s) - ‘vi-dep.xz’ saved [16048864/16048864]\n","\n","--2024-06-03 14:31:39--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5599844 (5.3M) [application/octet-stream]\n","Saving to: ‘vi-500brownclusters.xz’\n","\n","vi-500brownclusters 100%[===================>]   5.34M  21.2MB/s    in 0.3s    \n","\n","2024-06-03 14:31:40 (21.2 MB/s) - ‘vi-500brownclusters.xz’ saved [5599844/5599844]\n","\n","--2024-06-03 14:31:40--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9956876 (9.5M) [application/octet-stream]\n","Saving to: ‘vi-ner.xz’\n","\n","vi-ner.xz           100%[===================>]   9.50M  29.4MB/s    in 0.3s    \n","\n","2024-06-03 14:31:41 (29.4 MB/s) - ‘vi-ner.xz’ saved [9956876/9956876]\n","\n","--2024-06-03 14:31:41--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 57313672 (55M) [application/octet-stream]\n","Saving to: ‘vi-pretrainedembeddings.xz’\n","\n","vi-pretrainedembedd 100%[===================>]  54.66M  67.3MB/s    in 0.8s    \n","\n","2024-06-03 14:31:45 (67.3 MB/s) - ‘vi-pretrainedembeddings.xz’ saved [57313672/57313672]\n","\n","--2024-06-03 14:31:45--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29709468 (28M) [application/octet-stream]\n","Saving to: ‘vi-tagger’\n","\n","vi-tagger           100%[===================>]  28.33M  48.8MB/s    in 0.6s    \n","\n","2024-06-03 14:31:46 (48.8 MB/s) - ‘vi-tagger’ saved [29709468/29709468]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"fD22vnF7K4Ta"},"source":["## Install UndertheSea"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZnrrGI2LB_D","outputId":"5c3f363d-95fd-4b8c-a0e0-d9ed9fbf58cd","executionInfo":{"status":"ok","timestamp":1717425121011,"user_tz":-420,"elapsed":8589,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["!pip install underthesea"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting underthesea\n","  Downloading underthesea-6.8.0-py3-none-any.whl (20.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n","Collecting python-crfsuite>=0.9.6 (from underthesea)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n","Collecting underthesea-core==1.0.4 (from underthesea)\n","  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2024.5.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n","Installing collected packages: underthesea-core, python-crfsuite, underthesea\n","Successfully installed python-crfsuite-0.9.10 underthesea-6.8.0 underthesea-core-1.0.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"InJpM7aDEtHB"},"source":["# Read and Clean Data"]},{"cell_type":"code","metadata":{"id":"wcW3ncfLE_sB","executionInfo":{"status":"ok","timestamp":1717425123605,"user_tz":-420,"elapsed":2596,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["import unicodedata\n","import os, time\n","import copy, json\n","\n","from underthesea import sent_tokenize, word_tokenize\n","from vncorenlp import VnCoreNLP"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eCOWz9EfFPzn"},"source":["## Read data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OukJU79aE1pl","outputId":"2f5ca08e-7d77-4a76-8f9a-830353f8a44b","executionInfo":{"status":"ok","timestamp":1717425123605,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["with open('test_data.json') as test_data_json:\n","  jtest_data = json.load(test_data_json)\n","\n","print(type(jtest_data))\n","print(*jtest_data[0:6], sep='\\n')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","{'doc_id': '23351996', 'sent_id': 1, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'label': 'OTHERS'}\n","{'doc_id': '23351996', 'sent_id': 2, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS'}\n","{'doc_id': '23351996', 'sent_id': 3, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n","{'doc_id': '23351996', 'sent_id': 4, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS'}\n","{'doc_id': '23351996', 'sent_id': 5, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n","{'doc_id': '23351996', 'sent_id': 6, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"0jyBD2u1NP3r"},"source":["## Clean func"]},{"cell_type":"markdown","metadata":{"id":"sgaMrjV05d1k"},"source":["### Normalize text"]},{"cell_type":"markdown","metadata":{"id":"Xy2V2T-h5orS"},"source":["Bên dưới, ta sẽ normalize lại các câu và normalize cả entity text. Tuy nhiên, ta sẽ tạo bản copy, vẫn giữ lại câu gốc và entity gốc để tiện sau này match cho tập test. Normalize sẽ giúp các mô hình BERT nhận diện, word peice câu tốt hơn.\n","\n","Và do nhiều câu bị lỗi unicode, chưa được normalize nên sau khi normalize thì pos entity bị thay đổi nên ta phải tìm pos mới của entity trong câu mới.\n","\n","\n","Vấn đề:\n","- do sau khi được normalize thì pos của entity sẽ thay đổi nên ta cần tìm lại pos của entity trong câu mới\n","- trong câu có thể có nhiều cụm từ giống entity đang xét trong câu (nhiều entity giống nhau trong câu) nên cũng phải cẩn thận khi tìm pos của entity trong câu mới.\n","\n","Ý tưởng:\n","- giả sử trong câu có 5 entity giống hệt nhau. và entity ta đang xét là entity thứ 3 trong số 5 entity kia.\n","  + ... entity_1 ... entity_2 ... **entity_3** ... entity_4 ... entity_5 ...  (dù tên khác nhưng text sau khi được normlize sẽ là một.)\n","- Từ **câu gốc** ta tạo thành 3 câu:\n","  + ... entity_1 ... entity_2 ... **entity_3** ... entity_4 ... entity_5 ... (vẫn là câu gốc)\n","  + ... entity_1 ... entity_2 ... (phần trước entity trong câu gốc - dùng **pos cũ** của entity trong câu cũ)\n","  + ... entity_4 ... entity_5 ... (phần sau entity trong câu gốc - dùng **pos cũ** của entity trong câu cũ)\n","- đầu tiên ta normalize cả 3 câu trên và normalize entity_text đang xét\n","- sau đó tìm pos indice của 'normalized entity_text' trong cả 3 câu đã được nomalize trên, sẽ thu được kết quả như dưới:\n","  + ``` [[ent_1_pos], [ent_2_pos], [ent_3_pos], [ent_4_pos], [ent_5_pos]] ```\n","  + ``` [[ent_1_pos], [ent_2_pos]] ```\n","  + ``` [[ent_4_pos], [ent_5_pos]] ```\n","- cuối cùng chỉ cần lấy list đầu trừ đi tổng 2 list dưới là sẽ thu được: ```[ent_3_pos]```\n","\n","- Hiểu một cách đơn giản là tìm pos pos trong cả câu, rồi tìm trong phần trước xem có những cái nào, tìm trong phần sau xem có những cái nào. rồi cái còn lại chưa xuất hiện thì chính là pos entity của cái cần tìm\n","\n","Sau khi so một vài kết quả của cách này với cách cũ (có bug nên chỉ in ra được vài kết quả) thì thấy đều ổn, giống nhau.\n","\n","**Lưu ý:** cần xem entity có bị overlap không, không thì mới dùng được. do code bên dưới là dùng cho tìm pos non overlap. (ví dụ overlap: tìm ACA trong ACACA thì code bên dưới chỉ tìm được 1 pos đầu dù có 2 cái). Dùng code không overlap vì muốn xem data kĩ hơn. xem có bị xấu như kia không.\n","https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLR5EJB1uq9l","outputId":"0f28b32d-9b94-490a-efab-3570a964abe7","executionInfo":{"status":"ok","timestamp":1717425123605,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["import re\n","\n","txt = \"Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\"\n","\n","print([i for i in range(len(txt)) if txt.startswith('Hoàng Sa', i)])\n","\n","print([[a.start(), a.end()] for a in list(re.finditer('Hoàng Sa', txt))])\n","\n","print([[m.start(), m.end()] for m in re.finditer('Hoàng Sa', txt)])  # <--- dùng code này\n","                                                                     # không dùng được cho overlap (find 'ACA' in 'ACACA' sẽ chỉ cho 1 kết quả)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[109, 200, 232]\n","[[109, 117], [200, 208], [232, 240]]\n","[[109, 117], [200, 208], [232, 240]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1B6xMCyZ62y","outputId":"f80bc7c5-17d6-43b3-c46d-3cdeb4247035","executionInfo":{"status":"ok","timestamp":1717425123605,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["a = [[1,2], [6,8]]\n","b = [[1,2], [3,5], [6,8], [11,22]]\n","print(all(i in b for i in a))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","metadata":{"id":"Vyhi7xJi5hpl","executionInfo":{"status":"ok","timestamp":1717425123605,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def normalize_sentif(jdata):\n","\n","    new_jdata = []\n","\n","    count_changed_sent = 0\n","\n","    for sentif in jdata:\n","\n","        new_sentence = copy.deepcopy(sentif['sentence'])\n","        new_entity_1_text, new_entity_1_pos = copy.deepcopy(sentif['entity_1']['text']), copy.deepcopy(sentif['entity_1']['pos'])\n","        new_entity_2_text, new_entity_2_pos = copy.deepcopy(sentif['entity_2']['text']), copy.deepcopy(sentif['entity_2']['pos'])\n","\n","        if sentif['sentence'] != unicodedata.normalize(\"NFC\", sentif['sentence']):\n","\n","            new_sentence = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['sentence']))\n","            new_entity_1_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['entity_1']['text']))\n","            new_entity_2_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['entity_2']['text']))\n","\n","            # tìm trong cả câu đã được normalized:  A B C entity D E F\n","            entity_1_all_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_1_text), new_sentence)]\n","            entity_2_all_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_2_text), new_sentence)]\n","\n","            # tìm trong phần đằng trước entity: A B C\n","            sent_before_entity_1 = sentif['sentence'][:sentif['entity_1']['pos'][0]]\n","            sent_before_entity_1 = unicodedata.normalize(\"NFC\", sent_before_entity_1)\n","\n","            sent_before_entity_2 = sentif['sentence'][:sentif['entity_2']['pos'][0]]\n","            sent_before_entity_2 = unicodedata.normalize(\"NFC\", sent_before_entity_2)\n","\n","            entity_1_before_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_1_text), sent_before_entity_1)]\n","            entity_2_before_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_2_text), sent_before_entity_2)]\n","\n","            assert (all(i in entity_1_all_pos for i in entity_1_before_pos)), str('\\nPROBLEM WITH POS BEFORE ENTITY 1')\n","            assert (all(i in entity_2_all_pos for i in entity_2_before_pos)), str('\\nPROBLEM WITH POS BEFORE ENTITY 2')\n","\n","            # tìm trong phần đằng sau entity: D E F\n","            sent_after_entity_1 = sentif['sentence'][sentif['entity_1']['pos'][1]:]\n","            sent_after_entity_1 = unicodedata.normalize(\"NFC\", sent_after_entity_1)\n","\n","            sent_after_entity_2 = sentif['sentence'][sentif['entity_2']['pos'][1]:]\n","            sent_after_entity_2 = unicodedata.normalize(\"NFC\", sent_after_entity_2)\n","\n","            entity_1_after_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_1_text), sent_after_entity_1)]\n","            entity_2_after_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_2_text), sent_after_entity_2)]\n","\n","            change_index_after_1 = len(unicodedata.normalize(\"NFC\", sentif['sentence'][:sentif['entity_1']['pos'][1]]))\n","            change_index_after_2 = len(unicodedata.normalize(\"NFC\", sentif['sentence'][:sentif['entity_2']['pos'][1]]))\n","\n","            entity_1_after_pos = [[(tmp[0]+change_index_after_1), (tmp[1]+change_index_after_1)] for tmp in entity_1_after_pos]\n","            entity_2_after_pos = [[(tmp[0]+change_index_after_2), (tmp[1]+change_index_after_2)] for tmp in entity_2_after_pos]\n","\n","            assert (all(i in entity_1_all_pos for i in entity_1_after_pos)), str('\\nPROBLEM WITH POS AFTER ENTITY 1')\n","            assert (all(i in entity_2_all_pos for i in entity_2_after_pos)), str('\\nPROBLEM WITH POS AFTER ENTITY 2')\n","\n","\n","            new_entity_1_pos = [itm for itm in entity_1_all_pos if itm not in (entity_1_before_pos + entity_1_after_pos)]\n","            new_entity_2_pos = [itm for itm in entity_2_all_pos if itm not in (entity_2_before_pos + entity_2_after_pos)]\n","\n","\n","            assert (len(new_entity_1_pos) == 1), str('BELLELEELL 1')\n","            assert (len(new_entity_2_pos) == 1), str('BELLELEELL 2')\n","\n","            '''\n","            if (len(new_entity_1_pos) != 1):\n","                print(sentif)\n","                print(entity_1_all_pos)\n","                print(entity_1_before_pos)\n","                print(entity_1_after_pos)\n","\n","            if (len(new_entity_2_pos) != 1):\n","                print(sentif)\n","                print(entity_2_all_pos)\n","                print(entity_2_before_pos)\n","                print(entity_2_after_pos)\n","            '''\n","\n","            new_entity_1_pos = copy.deepcopy(new_entity_1_pos[0])\n","            new_entity_2_pos = copy.deepcopy(new_entity_2_pos[0])\n","\n","\n","            assert (new_sentence[new_entity_1_pos[0]:new_entity_1_pos[1]] == new_entity_1_text), \\\n","            str('\\nAFTER NORMALIZE, ENTITY 1 TEXT NOT MATCH ENTITY 1 POS. sent_id: ' + str(sent_id))\n","\n","            assert (new_sentence[new_entity_2_pos[0]:new_entity_2_pos[1]] == new_entity_2_text), \\\n","            str('\\nAFTER NORMALIZE, ENTITY 2 TEXT NOT MATCH ENTITY 2 POS. sent_id: ' + str(sent_id))\n","\n","\n","        # thêm vào new_jdata\n","        new_sentif = copy.deepcopy(sentif)\n","\n","        new_sentif['new_sentence'] = copy.deepcopy(new_sentence)\n","\n","        new_entity_1 = copy.deepcopy({'text': copy.deepcopy(new_entity_1_text), 'pos': copy.deepcopy(new_entity_1_pos)})\n","        new_entity_2 = copy.deepcopy({'text': copy.deepcopy(new_entity_2_text), 'pos': copy.deepcopy(new_entity_2_pos)})\n","\n","        new_sentif['new_entity_1'] = copy.deepcopy(new_entity_1)\n","        new_sentif['new_entity_2'] = copy.deepcopy(new_entity_2)\n","\n","        new_jdata.append(copy.deepcopy(new_sentif))\n","\n","\n","\n","        # in để check xem code chạy đúng không\n","        if new_jdata[-1]['new_sentence'] != sentif['sentence']:\n","            count_changed_sent += 1\n","\n","            print('\\n\\n----- ', count_changed_sent,  ' - sent_id: ', sentif['sent_id'])\n","            print('Original sent:   ', sentif['sentence'])\n","            print('Normalized sent: ', new_jdata[-1]['new_sentence'])\n","\n","            print('Previous entity 1:   ', sentif['entity_1'])\n","            print('Normalized entity 1: ', new_jdata[-1]['new_entity_1'])\n","\n","            print('Previous entity 2:   ', sentif['entity_2'])\n","            print('Normalized entity 2: ', new_jdata[-1]['new_entity_2'])\n","\n","        # phần cũ vẫn phải y nguyên. bên trên chỉ thêm 'new_sentence', 'new_entity_1' và 'new_entity_2'\n","        assert (new_jdata[-1]['sent_id'] == sentif['sent_id']), str('FAILED TO COPY sent_id. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['doc_id'] == sentif['doc_id']), str('FAILED TO COPY doc_id. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['sentence'] == sentif['sentence']), str('FAILED TO COPY sentence. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['entity_1'] == sentif['entity_1']), str('FAILED TO COPY entity_1. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['entity_2'] == sentif['entity_2']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['label'] == sentif['label']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['spos'] == sentif['spos']), str('FAILED TO COPY spos. sent_id: ' + sentif['sent_id'])\n","\n","\n","    return copy.deepcopy(new_jdata)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNfcso5IDPPK"},"source":["### Remove non alnum character at start and end of entity_text"]},{"cell_type":"markdown","metadata":{"id":"bjsrq58pDZVj"},"source":["Trong data nhiều entity ở đầu hoặc cuối (kí tự đầu hoặc cuối) bị lẫn dấu câu như (, ',... hay khoảng trắng. Điều này làm ảnh hướng tới mô hình nếu sau này ta pooling vectors của các word piece trong entity để được vector đại diện cho entity thì sẽ bị lẫn các kí tự không cần kia.\n","\n","Ngoài ra, cách tìm index các wordpiece của entity (để sau pooling được) bên dưới ta dùng không cho phép có khoảng trắng lẫn vào ở đầu hoặc cuối entity nên cần loại bỏ."]},{"cell_type":"code","metadata":{"id":"3-ly6uxrDOmI","executionInfo":{"status":"ok","timestamp":1717425123605,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def remove_entity_non_alnum_start_end(sent_id, sentence, entity_if):\n","    '''\n","    Bên trên ở phần \"check\", thấy rằng nhiều entity bị lẫn những kí tự \"thừa\" ở đầu hoặc ở cuối entity\n","    ví dụ: (Thái Nguyên    <----- bị lẫn kí tự (\n","\n","    Sau khi xem dữ liệu, ta thấy những kí tự \"thừa\" là những kí tự không phải là chữ cái hay chữ số. (not .isalnum())\n","    (trừ dấu \".\" và trường hợp entity là \"6+\")\n","\n","    Ngoài ra, bên trên trong phần check, thấy rằng nếu trong (giữa) entity có kí tự không phải chữ số hay chữ cái thì cũng đều hợp lý\n","    chứ không phải lỗi.\n","\n","    Trong hàm này, ta sẽ tạo ra một sửa, loại bỏ các kí tự kia khỏi entity lỗi.\n","\n","    Tuy nhiên, để tránh việc sau này trên tập test khó match được entity thì ta sẽ chỉ tạo bản copy và sửa trên bản copy thôi.\n","    '''\n","\n","    # just double check\n","    assert ((not entity_if['text'][0].isalnum()) or (not entity_if['text'][-1].isalnum())), \\\n","    str('Both First and last character of entity are  alnum.')\n","\n","    # count non alnum character at start\n","    count_at_start = 0\n","    for c in entity_if['text']:\n","        if (not c.isalnum()):\n","            count_at_start += 1\n","        else:\n","            break\n","\n","    # count non alnum character at end\n","    count_at_end = 0\n","    for c in entity_if['text'][::-1]:\n","        if (not c.isalnum()) and (c != '+') and (c != '.'):   # trong tập train, dev, thì + và . chỉ xuất hiện ở cuối entity nên phần count start k có\n","            count_at_end += 1\n","        else:\n","            break\n","\n","    entity_text = entity_if['text']\n","    entity_pos = entity_if['pos']   # pos trong câu\n","\n","    new_entity_text = entity_text[(count_at_start):(len(entity_text) - count_at_end)]   # slice trong entity không phải slice trong sentence\n","    new_entity_pos = [(entity_pos[0] + count_at_start), (entity_pos[1] - count_at_end)]   # pos trong câu\n","\n","    assert (sentence[new_entity_pos[0]:new_entity_pos[1]] == new_entity_text), \\\n","    str('\\nNew entity text not match new entity pos.')\n","\n","\n","    return new_entity_text, new_entity_pos\n","\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAH5RjECE32S","executionInfo":{"status":"ok","timestamp":1717425123606,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def fix_start_end_of_entity(jdata):\n","\n","    new_jdata = copy.deepcopy([])\n","\n","    tmpppent = []\n","\n","    for sentif in jdata:\n","\n","        # nếu bên dưới không bị thay đổi tức là không chứa \"kí tự thừa\" thì vẫn giống entity cũ\n","        # ngoài ra ta sẽ truyền vào hàm này j(train/dev)_data_v1 và thay đổi trên new_entity_1\n","        new_entity_1_text = copy.deepcopy(sentif['new_entity_1']['text'])\n","        new_entity_1_pos = copy.deepcopy(sentif['new_entity_1']['pos'])\n","\n","        if (not sentif['new_entity_1']['text'][0].isalnum()) or (not sentif['new_entity_1']['text'][-1].isalnum()):\n","            new_entity_1_text, new_entity_1_pos = remove_entity_non_alnum_start_end(sentif['sent_id'], sentif['new_sentence'], sentif['new_entity_1'])\n","\n","        # nếu bên dưới không bị thay đổi tức là không chứa \"kí tự thừa\" thì vẫn giống entity cũ\n","        # ngoài ra ta sẽ truyền vào hàm này j(train/dev)_data_v1 và thay đổi trên new_entity_2\n","        new_entity_2_text = copy.deepcopy(sentif['new_entity_2']['text'])\n","        new_entity_2_pos = copy.deepcopy(sentif['new_entity_2']['pos'])\n","\n","        if (not sentif['new_entity_2']['text'][0].isalnum()) or (not sentif['new_entity_2']['text'][-1].isalnum()):\n","            new_entity_2_text, new_entity_2_pos = remove_entity_non_alnum_start_end(sentif['sent_id'], sentif['new_sentence'], sentif['new_entity_2'])\n","\n","\n","\n","        new_sentif = copy.deepcopy(sentif)\n","\n","        new_entity_1 = {'text': copy.deepcopy(new_entity_1_text), 'pos': copy.deepcopy(new_entity_1_pos)}\n","        new_entity_2 = {'text': copy.deepcopy(new_entity_2_text), 'pos': copy.deepcopy(new_entity_2_pos)}\n","\n","        '''\n","        del new_sentif['new_entity_1']\n","        del new_sentif['new_entity_2']\n","        '''\n","\n","        new_sentif['new_entity_1'] = copy.deepcopy(new_entity_1)\n","        new_sentif['new_entity_2'] = copy.deepcopy(new_entity_2)\n","\n","\n","        new_jdata.append(copy.deepcopy(new_sentif))\n","\n","\n","\n","        # in kết quả\n","        if (new_jdata[-1]['new_entity_1'] != sentif['new_entity_1']) and (sentif['new_entity_1']['text'] not in tmpppent):\n","\n","            print('\\noriginal:      ', sentif['new_entity_1'])\n","            print('new_entity:    ', new_jdata[-1]['new_entity_1'])\n","\n","            tmpppent.append(sentif['new_entity_1']['text'])\n","\n","        if (new_jdata[-1]['new_entity_2'] != sentif['new_entity_2']) and (sentif['new_entity_2']['text'] not in tmpppent):\n","\n","            print('\\noriginal:      ', sentif['new_entity_2'])\n","            print('new_entity:    ', new_jdata[-1]['new_entity_2'])\n","\n","            tmpppent.append(sentif['new_entity_2']['text'])\n","\n","    return new_jdata\n","\n","\n","\n","\n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5F2EbtGIhZY_"},"source":["## Clean test"]},{"cell_type":"markdown","metadata":{"id":"aF7krGOHhZY_"},"source":["### Normalize test data"]},{"cell_type":"markdown","metadata":{"id":"eUyGGJYyhZY_"},"source":["#### check overlap"]},{"cell_type":"markdown","metadata":{"id":"JO9uqIffhZY_"},"source":["CHÚ Ý: Cần review data để xem có xảy ra overlap entity không vì code find_nth bên dưới dùng là cho không overlap.\n","\n","Ví dụ: overlap: ACACA\n","\n","https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string\n","\n","https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKRfSSVehZZA","outputId":"3e5cfc75-50be-450d-ffb0-6caf3e1ee79c","executionInfo":{"status":"ok","timestamp":1717425123606,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["tmpppsent = []\n","counttt = 0\n","\n","for sentif in jtest_data:\n","\n","    if (sentif['sentence'] != unicodedata.normalize(\"NFC\", sentif['sentence'])):\n","        counttt += 1\n","\n","        if (sentif['sentence'] not in tmpppsent):\n","            print(sentif['sent_id'])\n","            print(sentif['sentence'])\n","            tmpppsent.append(sentif['sentence'])\n","\n","print(counttt)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["8405\n","Người hâm mộ được khám phá chuyến hành trình trở về năm 1873 khi Heineken bắt đầu hành trình chinh phục thế giới với hương vị hoàn hảo, đồng thời du hành đến 192 quốc gia nơi Heineken được triệu triệu tín đồ yêu thích.\n","8406\n","Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n","8424\n","Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n","8428\n","Heineken luôn cam kết đem đến những trải nghiệm đỉnh cao, đẳng cấp nhằm kết nối mọi cuộc vui và mang đến những khoảnh khắc tuyệt vời nhất cho người tiêu dùng Việt Nam và sứ mệnh đó tiếp tục được khẳng định thông qua những câu chuyện được kể đầy cảm hứng này.\n","8\n"]}]},{"cell_type":"markdown","metadata":{"id":"EYqWH67fhZZD"},"source":["#### Normalize data"]},{"cell_type":"code","metadata":{"id":"rQvV6M2rhZZD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425125380,"user_tz":-420,"elapsed":1777,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}},"outputId":"623fcdda-9e0e-4e52-ea36-3236cf34dc7b"},"source":["jtest_data_v1 = copy.deepcopy(normalize_sentif(jtest_data))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","-----  1  - sent_id:  8405\n","Original sent:    Người hâm mộ được khám phá chuyến hành trình trở về năm 1873 khi Heineken bắt đầu hành trình chinh phục thế giới với hương vị hoàn hảo, đồng thời du hành đến 192 quốc gia nơi Heineken được triệu triệu tín đồ yêu thích.\n","Normalized sent:  Người hâm mộ được khám phá chuyến hành trình trở về năm 1873 khi Heineken bắt đầu hành trình chinh phục thế giới với hương vị hoàn hảo, đồng thời du hành đến 192 quốc gia nơi Heineken được triệu triệu tín đồ yêu thích.\n","Previous entity 1:    {'text': 'Heineken', 'pos': [66, 74]}\n","Normalized entity 1:  {'text': 'Heineken', 'pos': [65, 73]}\n","Previous entity 2:    {'text': 'Heineken', 'pos': [176, 184]}\n","Normalized entity 2:  {'text': 'Heineken', 'pos': [175, 183]}\n","\n","\n","-----  2  - sent_id:  8406\n","Original sent:    Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n","Normalized sent:  Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n","Previous entity 1:    {'text': 'Heineken', 'pos': [111, 119]}\n","Normalized entity 1:  {'text': 'Heineken', 'pos': [104, 112]}\n","Previous entity 2:    {'text': 'Willem vans Waesberghe', 'pos': [126, 148]}\n","Normalized entity 2:  {'text': 'Willem vans Waesberghe', 'pos': [119, 141]}\n","\n","\n","-----  3  - sent_id:  8407\n","Original sent:    Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n","Normalized sent:  Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n","Previous entity 1:    {'text': 'Heineken', 'pos': [111, 119]}\n","Normalized entity 1:  {'text': 'Heineken', 'pos': [104, 112]}\n","Previous entity 2:    {'text': 'Victor Vũ', 'pos': [182, 191]}\n","Normalized entity 2:  {'text': 'Victor Vũ', 'pos': [174, 183]}\n","\n","\n","-----  4  - sent_id:  8408\n","Original sent:    Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n","Normalized sent:  Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n","Previous entity 1:    {'text': 'Willem vans Waesberghe', 'pos': [126, 148]}\n","Normalized entity 1:  {'text': 'Willem vans Waesberghe', 'pos': [119, 141]}\n","Previous entity 2:    {'text': 'Victor Vũ', 'pos': [182, 191]}\n","Normalized entity 2:  {'text': 'Victor Vũ', 'pos': [174, 183]}\n","\n","\n","-----  5  - sent_id:  8424\n","Original sent:    Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n","Normalized sent:  Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n","Previous entity 1:    {'text': 'Victor Vũ', 'pos': [0, 9]}\n","Normalized entity 1:  {'text': 'Victor Vũ', 'pos': [0, 9]}\n","Previous entity 2:    {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n","Normalized entity 2:  {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n","\n","\n","-----  6  - sent_id:  8425\n","Original sent:    Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n","Normalized sent:  Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n","Previous entity 1:    {'text': 'Victor Vũ', 'pos': [0, 9]}\n","Normalized entity 1:  {'text': 'Victor Vũ', 'pos': [0, 9]}\n","Previous entity 2:    {'text': 'Heineken', 'pos': [266, 274]}\n","Normalized entity 2:  {'text': 'Heineken', 'pos': [265, 273]}\n","\n","\n","-----  7  - sent_id:  8426\n","Original sent:    Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n","Normalized sent:  Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n","Previous entity 1:    {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n","Normalized entity 1:  {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n","Previous entity 2:    {'text': 'Heineken', 'pos': [266, 274]}\n","Normalized entity 2:  {'text': 'Heineken', 'pos': [265, 273]}\n","\n","\n","-----  8  - sent_id:  8428\n","Original sent:    Heineken luôn cam kết đem đến những trải nghiệm đỉnh cao, đẳng cấp nhằm kết nối mọi cuộc vui và mang đến những khoảnh khắc tuyệt vời nhất cho người tiêu dùng Việt Nam và sứ mệnh đó tiếp tục được khẳng định thông qua những câu chuyện được kể đầy cảm hứng này.\n","Normalized sent:  Heineken luôn cam kết đem đến những trải nghiệm đỉnh cao, đẳng cấp nhằm kết nối mọi cuộc vui và mang đến những khoảnh khắc tuyệt vời nhất cho người tiêu dùng Việt Nam và sứ mệnh đó tiếp tục được khẳng định thông qua những câu chuyện được kể đầy cảm hứng này.\n","Previous entity 1:    {'text': 'Heineken', 'pos': [0, 8]}\n","Normalized entity 1:  {'text': 'Heineken', 'pos': [0, 8]}\n","Previous entity 2:    {'text': 'Việt Nam', 'pos': [158, 166]}\n","Normalized entity 2:  {'text': 'Việt Nam', 'pos': [158, 166]}\n"]}]},{"cell_type":"markdown","metadata":{"id":"ibDYFDo5hZZE"},"source":["### fix start end of entity in dev data"]},{"cell_type":"code","metadata":{"id":"fVKO5QHZhZZE","executionInfo":{"status":"ok","timestamp":1717425126375,"user_tz":-420,"elapsed":997,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["jtest_data_use = copy.deepcopy(jtest_data_v1)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cJJS0PLthZZE"},"source":["#### Check"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"du2XIqDChZZE","outputId":"73b4d6c9-eaa6-4417-bb07-03cf45f2da5e","executionInfo":{"status":"ok","timestamp":1717425127739,"user_tz":-420,"elapsed":1365,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["tmpppsent = []\n","allchar_lst = []\n","alnum_char_lst = []\n","not_alnum_char_lst = []\n","\n","for sentif in jtest_data_use:\n","    if sentif['sentence'] not in tmpppsent:\n","        for ch in sentif['sentence']:\n","            if ch not in allchar_lst:\n","                allchar_lst.append(ch)\n","\n","            if ch.isalnum() and (ch not in alnum_char_lst):\n","                alnum_char_lst.append(ch)\n","\n","            if (not ch.isalnum()) and (ch not in not_alnum_char_lst):\n","                not_alnum_char_lst.append(ch)\n","\n","        tmpppsent.append(sentif['sentence'])\n","\n","\n","print(len(allchar_lst))\n","for i in range(0, len(allchar_lst), 30):\n","    # Limit the end index so we don't go past the end of the list.\n","    end = min(i + 30, len(allchar_lst) + 1)\n","\n","    # Print out the tokens, separated by a space.\n","    print(repr(' '.join(allchar_lst[i:end])))\n","\n","\n","print('\\n', len(alnum_char_lst))\n","for i in range(0, len(alnum_char_lst), 20):\n","    # Limit the end index so we don't go past the end of the list.\n","    end = min(i + 20, len(alnum_char_lst) + 1)\n","\n","    # Print out the tokens, separated by a space.\n","    print(repr(' '.join(alnum_char_lst[i:end])))\n","\n","\n","print('\\n', len(not_alnum_char_lst))\n","for i in range(0, len(not_alnum_char_lst), 20):\n","    # Limit the end index so we don't go past the end of the list.\n","    end = min(i + 20, len(not_alnum_char_lst) + 1)\n","\n","    # Print out the tokens, separated by a space.\n","    print(repr(' '.join(not_alnum_char_lst[i:end])))\n"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["184\n","\"U 1 6   V i ệ t N a m d ộ ' ư g ô n v à o l ớ M C ổ K h ằ ự\"\n","'đ á , ã c ó ế ắ ễ r . ậ y ạ b ả I ò â u Á 2 0 8 A s ể T q ặ'\n","'p ù ị ỡ - ấ ờ ở ú ẫ ơ x 5 B ứ ủ ầ ý ề 4 / 9 ố ọ k ă ợ ê H 3'\n","'( 7 ) ỷ ừ ỗ ữ ụ é S L ũ ồ ẽ õ R í ì Đ ‘ ’ e ẻ ỏ z G Z J “ ”'\n","'ỉ D P | : O % ử – \" ẳ Q Ô ỹ ĩ ẩ \\xa0 X ? \\u200b ẵ ỳ Ả f E W F w Â ẹ'\n","'ỵ + j ; … & Ủ Y \\ufeff Ă Ð * è Ư ! Ấ Ở Ú Í Ó Ồ Ý Ệ ± ~ Ẩ • ö ü ́'\n","'̉ ̣ ̀ Ì'\n","\n"," 150\n","'U 1 6 V i ệ t N a m d ộ ư g ô n v à o l'\n","'ớ M C ổ K h ằ ự đ á ã c ó ế ắ ễ r ậ y ạ'\n","'b ả I ò â u Á 2 0 8 A s ể T q ặ p ù ị ỡ'\n","'ấ ờ ở ú ẫ ơ x 5 B ứ ủ ầ ý ề 4 9 ố ọ k ă'\n","'ợ ê H 3 7 ỷ ừ ỗ ữ ụ é S L ũ ồ ẽ õ R í ì'\n","'Đ e ẻ ỏ z G Z J ỉ D P O ử ẳ Q Ô ỹ ĩ ẩ X'\n","'ẵ ỳ Ả f E W F w Â ẹ ỵ j Ủ Y Ă Ð è Ư Ấ Ở'\n","'Ú Í Ó Ồ Ý Ệ Ẩ ö ü Ì'\n","\n"," 34\n","'  \\' , . - / ( ) ‘ ’ “ ” | : % – \" \\xa0 ? \\u200b'\n","'+ ; … & \\ufeff * ! ± ~ • ́ ̉ ̣ ̀'\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jMWWYbkhZZE","outputId":"761fb46b-8e6c-46bc-bf75-b57160313b6b","executionInfo":{"status":"ok","timestamp":1717425127740,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# review data\n","# có vẻ là nếu trong entity có kí tự bắt đầu hoặc kết thúc là số thì k phải lỗi.\n","\n","for sentif in jtest_data_use:\n","    if (sentif['entity_1']['text'][0].isnumeric()) or (sentif['entity_1']['text'][-1].isnumeric()):\n","        print(sentif['entity_1'])\n","\n","    if (sentif['entity_2']['text'][0].isnumeric()) or (sentif['entity_2']['text'][-1].isnumeric()):\n","        print(sentif['entity_2'])\n","\n"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': 'nhóm G7', 'pos': [33, 40]}\n","{'text': 'nhóm G7', 'pos': [33, 40]}\n","{'text': 'PC67', 'pos': [21, 25]}\n","{'text': 'PC67', 'pos': [57, 61]}\n","{'text': 'PC67', 'pos': [177, 181]}\n","{'text': 'PC67', 'pos': [37, 41]}\n","{'text': 'PC67', 'pos': [82, 86]}\n","{'text': 'quận 1', 'pos': [85, 91]}\n","{'text': 'quận 1', 'pos': [85, 91]}\n","{'text': 'quận 1', 'pos': [85, 91]}\n","{'text': 'quận 1', 'pos': [110, 116]}\n","{'text': 'quận 1', 'pos': [110, 116]}\n","{'text': 'quận 1', 'pos': [110, 116]}\n","{'text': 'quận 1', 'pos': [110, 116]}\n","{'text': 'Bệnh viện Quân y 175', 'pos': [87, 107]}\n","{'text': 'Bệnh viện Quân y 175', 'pos': [87, 107]}\n","{'text': 'BV Quân y 175', 'pos': [161, 174]}\n","{'text': 'BV Quân y 175', 'pos': [161, 174]}\n","{'text': 'Bệnh viện Quân y 175', 'pos': [34, 54]}\n","{'text': '(Quận 3', 'pos': [58, 65]}\n","{'text': '(Quận 3', 'pos': [58, 65]}\n","{'text': '(Quận 3', 'pos': [58, 65]}\n","{'text': 'thôn 7', 'pos': [226, 232]}\n","{'text': 'thôn 7', 'pos': [226, 232]}\n","{'text': 'thôn 7', 'pos': [226, 232]}\n","{'text': 'thôn 7', 'pos': [226, 232]}\n","{'text': 'thôn 7', 'pos': [226, 232]}\n","{'text': 'thôn 7', 'pos': [226, 232]}\n","{'text': 'thôn 7', 'pos': [226, 232]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': 'thôn 5', 'pos': [65, 71]}\n","{'text': '(quốc lộ 13', 'pos': [164, 175]}\n","{'text': '(quốc lộ 13', 'pos': [164, 175]}\n","{'text': '(quốc lộ 13', 'pos': [164, 175]}\n","{'text': '(quốc lộ 13', 'pos': [164, 175]}\n","{'text': 'ngõ 16', 'pos': [34, 40]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [43, 61]}\n","{'text': 'ngõ 16', 'pos': [34, 40]}\n","{'text': 'ngõ 16', 'pos': [34, 40]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [43, 61]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [43, 61]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'Ngõ 16', 'pos': [123, 129]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n","{'text': 'PC67', 'pos': [72, 76]}\n","{'text': 'PC67', 'pos': [72, 76]}\n","{'text': 'PC67', 'pos': [8, 12]}\n","{'text': 'PC 67', 'pos': [13, 18]}\n","{'text': 'Phường 1', 'pos': [0, 8]}\n","{'text': '(quận 10', 'pos': [9, 17]}\n","{'text': 'Phường 1', 'pos': [0, 8]}\n","{'text': '(quận 10', 'pos': [9, 17]}\n","{'text': '(hẻm 438', 'pos': [108, 116]}\n","{'text': 'phường 1', 'pos': [135, 143]}\n","{'text': 'quận 10', 'pos': [146, 153]}\n","{'text': '(hẻm 438', 'pos': [108, 116]}\n","{'text': 'phường 1', 'pos': [135, 143]}\n","{'text': 'quận 10', 'pos': [146, 153]}\n","{'text': '(hẻm 438', 'pos': [108, 116]}\n","{'text': '(hẻm 438', 'pos': [108, 116]}\n","{'text': 'phường 1', 'pos': [135, 143]}\n","{'text': '(hẻm 438', 'pos': [108, 116]}\n","{'text': 'quận 10', 'pos': [146, 153]}\n","{'text': 'phường 1', 'pos': [135, 143]}\n","{'text': 'quận 10', 'pos': [146, 153]}\n","{'text': 'phường 1', 'pos': [135, 143]}\n","{'text': 'quận 10', 'pos': [146, 153]}\n","{'text': '(quận 10', 'pos': [24, 32]}\n","{'text': '(quận 10', 'pos': [24, 32]}\n","{'text': '(quận 10', 'pos': [24, 32]}\n","{'text': '223 Trích Sài', 'pos': [65, 78]}\n","{'text': '223 Trích Sài', 'pos': [65, 78]}\n","{'text': 'khối 5', 'pos': [64, 70]}\n","{'text': 'khối 5', 'pos': [64, 70]}\n","{'text': 'khối 5', 'pos': [64, 70]}\n","{'text': 'khối 5', 'pos': [63, 69]}\n","{'text': 'khối 5', 'pos': [63, 69]}\n","{'text': 'khối 5', 'pos': [63, 69]}\n","{'text': 'khối 5', 'pos': [63, 69]}\n","{'text': 'quận 12', 'pos': [88, 95]}\n","{'text': 'quận 12', 'pos': [88, 95]}\n","{'text': 'quận 12', 'pos': [88, 95]}\n","{'text': 'quận 12', 'pos': [88, 95]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': 'thôn 3', 'pos': [296, 302]}\n","{'text': '(phường 10', 'pos': [69, 79]}\n","{'text': '(phường 10', 'pos': [69, 79]}\n","{'text': '(phường 10', 'pos': [69, 79]}\n","{'text': 'xóm 2', 'pos': [150, 155]}\n","{'text': 'xóm 2', 'pos': [150, 155]}\n","{'text': 'xóm 2', 'pos': [150, 155]}\n","{'text': 'xóm 2', 'pos': [150, 155]}\n","{'text': 'xóm 2', 'pos': [150, 155]}\n","{'text': 'xóm 2', 'pos': [150, 155]}\n","{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n","{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n","{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n","{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n","{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n","{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n","{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n","{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n","{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n","{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n","{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n","{'text': 'P.12', 'pos': [123, 127]}\n","{'text': 'Q.10', 'pos': [130, 134]}\n","{'text': 'P.12', 'pos': [123, 127]}\n","{'text': 'Q.10', 'pos': [130, 134]}\n","{'text': 'P.12', 'pos': [123, 127]}\n","{'text': 'Q.10', 'pos': [130, 134]}\n","{'text': 'P.12', 'pos': [123, 127]}\n","{'text': 'Q.10', 'pos': [130, 134]}\n","{'text': 'P.12', 'pos': [123, 127]}\n","{'text': 'Q.10', 'pos': [130, 134]}\n","{'text': 'P.12', 'pos': [123, 127]}\n","{'text': 'Q.10', 'pos': [130, 134]}\n","{'text': 'Công an quận 3', 'pos': [45, 59]}\n","{'text': 'Công an quận 3', 'pos': [45, 59]}\n","{'text': 'Công an quận 3', 'pos': [45, 59]}\n","{'text': 'phường 3', 'pos': [133, 141]}\n","{'text': 'quận 3', 'pos': [144, 150]}\n","{'text': 'phường 3', 'pos': [133, 141]}\n","{'text': 'quận 3', 'pos': [144, 150]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': 'PC45', 'pos': [113, 117]}\n","{'text': 'PC45', 'pos': [84, 88]}\n","{'text': 'PC45', 'pos': [84, 88]}\n","{'text': 'PC45', 'pos': [84, 88]}\n","{'text': 'PC45', 'pos': [84, 88]}\n","{'text': 'PC45', 'pos': [84, 88]}\n","{'text': 'PC45', 'pos': [84, 88]}\n","{'text': 'PC45', 'pos': [17, 21]}\n","{'text': 'PC45', 'pos': [17, 21]}\n","{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n","{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n","{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n","{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n","{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n","{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': '4Minute', 'pos': [176, 183]}\n","{'text': '4Minute', 'pos': [176, 183]}\n","{'text': '4Minute', 'pos': [176, 183]}\n","{'text': '4Minute', 'pos': [176, 183]}\n","{'text': 'Đội CSGT số 2', 'pos': [117, 130]}\n","{'text': 'Đội CSGT số 2', 'pos': [32, 45]}\n","{'text': 'Đội CSGT số 2', 'pos': [32, 45]}\n","{'text': 'Đội CSGT số 2', 'pos': [28, 41]}\n","{'text': 'Đội CSGT số 2', 'pos': [28, 41]}\n","{'text': 'Đội CSGT số 2', 'pos': [28, 41]}\n","{'text': 'Đội CSGT số 2', 'pos': [41, 54]}\n","{'text': 'phường 8', 'pos': [131, 139]}\n","{'text': 'phường 8', 'pos': [131, 139]}\n","{'text': 'phường 8', 'pos': [131, 139]}\n","{'text': 'Cảnh sát 113', 'pos': [18, 30]}\n","{'text': 'Cảnh sát 113', 'pos': [18, 30]}\n","{'text': 'G7', 'pos': [73, 75]}\n","{'text': 'G7', 'pos': [73, 75]}\n","{'text': 'G7', 'pos': [73, 75]}\n","{'text': 'G7', 'pos': [73, 75]}\n","{'text': '2017 SQ2', 'pos': [111, 119]}\n","{'text': '2017 SM2', 'pos': [122, 130]}\n","{'text': '2017 SR2', 'pos': [134, 142]}\n","{'text': '2017 SQ2', 'pos': [111, 119]}\n","{'text': '2017 SM2', 'pos': [122, 130]}\n","{'text': '2017 SQ2', 'pos': [111, 119]}\n","{'text': '2017 SR2', 'pos': [134, 142]}\n","{'text': '2017 SM2', 'pos': [122, 130]}\n","{'text': '2017 SR2', 'pos': [134, 142]}\n","{'text': '2017 SQ2', 'pos': [15, 23]}\n","{'text': '2017 SQ2', 'pos': [15, 23]}\n","{'text': '2017 SM2', 'pos': [30, 38]}\n","{'text': '2017 SR2', 'pos': [42, 50]}\n","{'text': '2017 SM2', 'pos': [30, 38]}\n","{'text': '2017 SR2', 'pos': [42, 50]}\n","{'text': '2017 SR2', 'pos': [46, 54]}\n","{'text': 'tiểu khu 556', 'pos': [92, 104]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'thôn 3', 'pos': [278, 284]}\n","{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n","{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n","{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n","{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n","{'text': 'CR7', 'pos': [21, 24]}\n","{'text': 'CR7', 'pos': [21, 24]}\n","{'text': 'sân Bet365', 'pos': [52, 62]}\n","{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n","{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n","{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n","{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n","{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n","{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n","{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n","{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '02/2011/TT-NHNN', 'pos': [281, 296]}\n","{'text': '02/2011/TT-NHNN', 'pos': [281, 296]}\n","{'text': '02/2011/TT-NHNN', 'pos': [281, 296]}\n","{'text': 'đội 6', 'pos': [51, 56]}\n","{'text': 'đội 6', 'pos': [51, 56]}\n","{'text': 'đội 6', 'pos': [51, 56]}\n","{'text': 'đội 6', 'pos': [51, 56]}\n","{'text': 'đội 6', 'pos': [51, 56]}\n","{'text': 'đội CSGT số 2', 'pos': [30, 43]}\n","{'text': 'đội CSGT số 2', 'pos': [55, 68]}\n","{'text': 'đội CSGT số 2', 'pos': [55, 68]}\n","{'text': 'đội CSGT số 2', 'pos': [55, 68]}\n","{'text': 'đội CSGT số 2', 'pos': [6, 19]}\n","{'text': 'khối 2', 'pos': [154, 160]}\n","{'text': 'khối 2', 'pos': [154, 160]}\n","{'text': 'khối 2', 'pos': [154, 160]}\n","{'text': 'khối 2', 'pos': [154, 160]}\n"]}]},{"cell_type":"code","metadata":{"id":"mIEWzlcthZZF","executionInfo":{"status":"ok","timestamp":1717425127740,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["for sentif in jtest_data_use:\n","    if ('½' in sentif['entity_1']['text']) or ('²' in sentif['entity_1']['text']) or ('ï' in sentif['entity_1']['text']):\n","        print(sentif['entity_1'])\n","\n","    if ('½' in sentif['entity_2']['text']) or ('²' in sentif['entity_2']['text']) or ('ï' in sentif['entity_2']['text']):\n","        print(sentif['entity_2'])"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQw7TkpyhZZF","outputId":"8029833f-f53f-419e-a7e2-0933f135e304","executionInfo":{"status":"ok","timestamp":1717425127740,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n","tmpppent = []\n","for sentif in jtest_data_use:\n","    if (not sentif['entity_1']['text'][0].isalnum()) or (not sentif['entity_1']['text'][-1].isalnum()):\n","        if sentif['entity_1']['text'] not in tmpppent:\n","            print(sentif['entity_1'])\n","            tmpppent.append(sentif['entity_1']['text'])\n","\n","            '''\n","            if '.' == sentif['entity_1']['text'][0]:\n","                print(sentif)\n","            '''\n","\n","    if (not sentif['entity_2']['text'][0].isalnum()) or (not sentif['entity_2']['text'][-1].isalnum()):\n","        if sentif['entity_2']['text'] not in tmpppent:\n","            print(sentif['entity_2'])\n","            tmpppent.append(sentif['entity_2']['text'])\n","\n","            '''\n","            if '.' == sentif['entity_2']['text'][0]:\n","                print(sentif)\n","            '''\n"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': '(Quảng Bình', 'pos': [219, 230]}\n","{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","{'text': '/Nikkei', 'pos': [10, 17]}\n","{'text': '(CNPC', 'pos': [168, 173]}\n","{'text': '/Reuters', 'pos': [10, 18]}\n","{'text': '\"Merkel', 'pos': [0, 7]}\n","{'text': '\"Trump', 'pos': [0, 6]}\n","{'text': '\"Hillary Clinton', 'pos': [0, 16]}\n","{'text': '(Cầu Giấy', 'pos': [45, 54]}\n","{'text': '“Joel Matip', 'pos': [0, 11]}\n","{'text': '“Cơ quan Cảnh sát điều tra', 'pos': [203, 229]}\n","{'text': '(NHNN', 'pos': [90, 95]}\n","{'text': '(quận Cầu Giấy', 'pos': [154, 168]}\n","{'text': '(số 45 Lý thường Kiệt', 'pos': [243, 264]}\n","{'text': '(VSP', 'pos': [129, 133]}\n","{'text': '(BSR', 'pos': [175, 179]}\n","{'text': '(PVEP', 'pos': [222, 227]}\n","{'text': '(HTS', 'pos': [252, 256]}\n","{'text': '(PC67-Công an TP.HCM', 'pos': [92, 112]}\n","{'text': '“Damascus', 'pos': [9, 18]}\n","{'text': '(Đắk Lắk', 'pos': [31, 39]}\n","{'text': '\\ufeffĐịch Lệ Nhiệt Ba', 'pos': [0, 17]}\n","{'text': \"'Lệ cơ\", 'pos': [86, 92]}\n","{'text': '(Phường Vĩnh Phúc', 'pos': [97, 114]}\n","{'text': '(thị xã Thuận An', 'pos': [131, 147]}\n","{'text': '(phường Phạm Ngũ Lão', 'pos': [87, 107]}\n","{'text': '(IS', 'pos': [26, 29]}\n","{'text': '(Thanh Hóa', 'pos': [64, 74]}\n","{'text': '(Đồng Nai', 'pos': [95, 104]}\n","{'text': '(Nam Định', 'pos': [121, 130]}\n","{'text': '(CLB Vũ Lê', 'pos': [54, 64]}\n","{'text': '(Củ Chi', 'pos': [88, 95]}\n","{'text': '(Quận 3', 'pos': [58, 65]}\n","{'text': '(Phú Nhuận', 'pos': [92, 102]}\n","{'text': '(TP.HCM', 'pos': [168, 175]}\n","{'text': '(tỉnh Đắk Nông', 'pos': [63, 77]}\n","{'text': '\"Real', 'pos': [133, 138]}\n","{'text': '\"Người ngoài hành tinh\"', 'pos': [40, 63]}\n","{'text': '(quốc lộ 13', 'pos': [164, 175]}\n","{'text': '),Vũ Thị Thùy Dương', 'pos': [151, 170]}\n","{'text': '(Sài Gòn', 'pos': [199, 207]}\n","{'text': '(Hải Dương', 'pos': [230, 240]}\n","{'text': '(Bình Dương', 'pos': [95, 106]}\n","{'text': '(Trung Quốc', 'pos': [74, 85]}\n","{'text': '-Trung', 'pos': [197, 203]}\n","{'text': 'Nguyễn Văn Q.', 'pos': [127, 140]}\n","{'text': '(OceanBank', 'pos': [184, 194]}\n","{'text': '(Hà Nội', 'pos': [290, 297]}\n","{'text': \"'MU\", 'pos': [0, 3]}\n","{'text': '(Dân Việt', 'pos': [25, 34]}\n","{'text': '/VOV', 'pos': [12, 16]}\n","{'text': '-ĐBSCL', 'pos': [17, 23]}\n","{'text': '(quận 10', 'pos': [9, 17]}\n","{'text': '(hẻm 438', 'pos': [108, 116]}\n","{'text': '(Bắc Ninh', 'pos': [110, 119]}\n","{'text': 'H.', 'pos': [104, 106]}\n","{'text': '\\xa0Thảo', 'pos': [40, 45]}\n","{'text': '(Hoàng Thị Hồng Tứ', 'pos': [84, 102]}\n","{'text': '(tỉnh TT-Huế', 'pos': [124, 136]}\n","{'text': '(huyện Phú Lộc', 'pos': [28, 42]}\n","{'text': 'Ro ‘Béo’', 'pos': [6, 14]}\n","{'text': '\\xa0Nguyễn Công Thành', 'pos': [103, 121]}\n","{'text': '(phường Đông Hưng Thuận', 'pos': [62, 85]}\n","{'text': 'T.N.H.', 'pos': [40, 46]}\n","{'text': '/TTXVN', 'pos': [4, 10]}\n","{'text': '(Anh', 'pos': [106, 110]}\n","{'text': '(Mỹ', 'pos': [215, 218]}\n","{'text': '(Pháp', 'pos': [258, 263]}\n","{'text': '\\xa0Fukushima', 'pos': [217, 227]}\n","{'text': '(Đông Đức', 'pos': [256, 265]}\n","{'text': '(KGB', 'pos': [184, 188]}\n","{'text': '\\xa0Helmut Kohl', 'pos': [64, 76]}\n","{'text': '(Quảng Ninh', 'pos': [108, 119]}\n","{'text': '\\xa0Shinawatra', 'pos': [156, 167]}\n","{'text': '(SPJD', 'pos': [138, 143]}\n","{'text': 'Trần Thị Trúc L.', 'pos': [70, 86]}\n","{'text': 'L.', 'pos': [24, 26]}\n","{'text': '(phường 10', 'pos': [69, 79]}\n","{'text': '(quận Bình Tân', 'pos': [75, 89]}\n","{'text': '(Oceanbank', 'pos': [101, 111]}\n","{'text': '(Sa Pa', 'pos': [164, 170]}\n","{'text': '(huyện Bắc Hà', 'pos': [46, 59]}\n","{'text': '(CMC Innovation Fund', 'pos': [190, 210]}\n","{'text': '“Ngân hàng Chính sách xã hội', 'pos': [189, 217]}\n","{'text': '(NHCSXH', 'pos': [331, 338]}\n","{'text': '\"Ngân hàng Chính sách xã hội', 'pos': [402, 430]}\n","{'text': \"'Hà\", 'pos': [15, 18]}\n","{'text': '(Chi cục Quản lý thị trường tỉnh Hà Tĩnh', 'pos': [58, 98]}\n","{'text': 'Đ.', 'pos': [48, 50]}\n","{'text': '(số 14/27 Hoàng Dư Khương', 'pos': [95, 120]}\n","{'text': '-Thái Bình Dương', 'pos': [59, 75]}\n","{'text': '(TTXVN', 'pos': [0, 6]}\n","{'text': '/Vietnam+', 'pos': [7, 16]}\n","{'text': '(AFC', 'pos': [25, 29]}\n","{'text': '(Vietnam+', 'pos': [10, 19]}\n","{'text': '(TP HCM', 'pos': [60, 67]}\n","{'text': 'Hoàng Thu H.', 'pos': [138, 150]}\n","{'text': '(FA', 'pos': [197, 200]}\n","{'text': 'Nguyễn Thị H.', 'pos': [25, 38]}\n","{'text': '(PC 45', 'pos': [208, 214]}\n","{'text': '(Bộ Tài nguyên và Môi trường', 'pos': [156, 184]}\n","{'text': '“Tỉnh Hải Dương', 'pos': [0, 15]}\n","{'text': '(Hải Phòng', 'pos': [73, 83]}\n","{'text': '-Cầu Giẽ', 'pos': [154, 162]}\n","{'text': '-Nga', 'pos': [3, 7]}\n","{'text': '(IAEA', 'pos': [275, 280]}\n","{'text': '(LHQ', 'pos': [418, 422]}\n","{'text': '(NATO', 'pos': [35, 40]}\n","{'text': \"'Biển chết\", 'pos': [0, 10]}\n","{'text': \"'biển Chết\", 'pos': [81, 91]}\n","{'text': '(huyện Cần Giuộc', 'pos': [63, 79]}\n","{'text': '(NAPAS', 'pos': [79, 85]}\n","{'text': '(Thượng Hóa', 'pos': [81, 92]}\n","{'text': '(Thái Lan', 'pos': [150, 159]}\n","{'text': '-đảng Xanh', 'pos': [290, 300]}\n","{'text': '(Phòng CSGT Thanh Hóa', 'pos': [131, 152]}\n","{'text': '(Indonesia', 'pos': [26, 36]}\n","{'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n","{'text': '(Bộ TT&TT', 'pos': [20, 29]}\n","{'text': '\\ufeffBảo Anh', 'pos': [0, 8]}\n","{'text': '(NCA', 'pos': [165, 169]}\n","{'text': '(Nghệ An', 'pos': [44, 52]}\n","{'text': 'Nguyễn Xuân Huân -', 'pos': [91, 109]}\n","{'text': '(TP Vinh', 'pos': [140, 148]}\n","{'text': '(CDU', 'pos': [93, 97]}\n","{'text': '/AP', 'pos': [8, 11]}\n","{'text': '(phường Trung Hòa', 'pos': [76, 93]}\n","{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n","{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n","{'text': '-Syria', 'pos': [45, 51]}\n","{'text': '(Al-Qaeda', 'pos': [120, 129]}\n","{'text': '–HTS', 'pos': [136, 140]}\n","{'text': '-Mỹ', 'pos': [163, 166]}\n","{'text': '“Ủy ban tiếp quản Deir Ezzor', 'pos': [25, 53]}\n","{'text': '-SDF', 'pos': [3, 7]}\n","{'text': '(VINASA', 'pos': [170, 177]}\n","{'text': '“tiểu Kompany”', 'pos': [32, 46]}\n","{'text': '(Quảng Nam', 'pos': [125, 135]}\n","{'text': '(TP Quy Nhơn', 'pos': [105, 117]}\n","{'text': '(huyện Bình Sơn', 'pos': [161, 176]}\n","{'text': '(Phú Yên', 'pos': [104, 112]}\n","{'text': \"'Bao Thanh Thiên\", 'pos': [0, 16]}\n","{'text': '\"Bao Thanh Thiên', 'pos': [9, 25]}\n","{'text': '(Viettel', 'pos': [130, 138]}\n","{'text': 'Lê Quý D.', 'pos': [86, 95]}\n","{'text': '-Liên Xô', 'pos': [43, 51]}\n","{'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n","{'text': '(Hà Văn Thắm', 'pos': [183, 195]}\n","{'text': '(DongA Bank', 'pos': [201, 212]}\n","{'text': '(Agribank', 'pos': [46, 55]}\n","{'text': '(HDBank', 'pos': [180, 187]}\n","{'text': '/Dân Việt', 'pos': [50, 59]}\n","{'text': '(Lào Cai', 'pos': [86, 94]}\n","{'text': 'Lương Văn T.', 'pos': [40, 52]}\n","{'text': '(xã Gia Phú', 'pos': [53, 64]}\n","{'text': '(VAS', 'pos': [75, 79]}\n","{'text': '(VietCham Singapore', 'pos': [120, 139]}\n","{'text': ',\\xa0Việt Nam', 'pos': [25, 35]}\n","{'text': '(Vietnammese Association in Singapore', 'pos': [58, 95]}\n","{'text': '(Jake Gyllenhaal', 'pos': [72, 88]}\n","{'text': '-Tây Nguyên', 'pos': [14, 25]}\n","{'text': '“Tevez', 'pos': [0, 6]}\n","{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n","{'text': '(sân\\xa0MFF Football Centre', 'pos': [46, 70]}\n","{'text': ',\\xa0Ulan Bator', 'pos': [71, 83]}\n","{'text': '(EU', 'pos': [112, 115]}\n","{'text': '(CSU', 'pos': [163, 167]}\n","{'text': '(SPD', 'pos': [291, 295]}\n","{'text': '/CSU', 'pos': [85, 89]}\n","{'text': '(FDP', 'pos': [53, 57]}\n","{'text': '(đảng Xanh', 'pos': [90, 100]}\n","{'text': '(AfD', 'pos': [48, 52]}\n","{'text': 'đảng “Vì tự do”', 'pos': [384, 399]}\n","{'text': '(PVV', 'pos': [400, 404]}\n","{'text': '(huyện Năm Căn', 'pos': [104, 118]}\n","{'text': '(Cà Mau', 'pos': [60, 67]}\n","{'text': '(VOV', 'pos': [0, 4]}\n","{'text': '(VnExpress', 'pos': [0, 10]}\n","{'text': '(Thanh niên', 'pos': [0, 11]}\n","{'text': \"'Đông Phương Bất Bại\", 'pos': [79, 99]}\n","{'text': '(Vĩnh Long', 'pos': [56, 66]}\n","{'text': '(Bản Yên Sơn', 'pos': [64, 76]}\n","{'text': '(tỉnh Thái Nguyên', 'pos': [52, 69]}\n","{'text': 'Cáp Trọng Th.', 'pos': [39, 52]}\n","{'text': 'Dương Thị T.', 'pos': [70, 82]}\n","{'text': 'Th.', 'pos': [56, 59]}\n","{'text': '(Hà Đông', 'pos': [20, 28]}\n","{'text': '(Đống Đa', 'pos': [6, 14]}\n","{'text': '(Australia', 'pos': [139, 149]}\n","{'text': '-\\xa0Nam', 'pos': [68, 73]}\n","{'text': '(IOM', 'pos': [164, 168]}\n","{'text': 'Vi Thị O.', 'pos': [21, 30]}\n","{'text': '(Hàn Quốc', 'pos': [38, 47]}\n","{'text': '(Hà Nội)', 'pos': [128, 136]}\n","{'text': '(Fed New York', 'pos': [170, 183]}\n","{'text': '-Việt Nam', 'pos': [247, 256]}\n","{'text': '(Bình Định', 'pos': [192, 202]}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZpC3s97hZZF","outputId":"9fbd4486-5507-4367-cf4b-7ad2bc8066c2","executionInfo":{"status":"ok","timestamp":1717425127740,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n","# tuy nhiên những entity bắt đầu hoặc kết thúc bằng kí tự '.' hoặc '+' thì không phải là lỗi\n","tmpppent = []\n","for sentif in jtest_data_use:\n","    if (sentif['entity_1']['text'][0] == '+') or (sentif['entity_1']['text'][-1] == '+') \\\n","    or (sentif['entity_1']['text'][0] == '.') or (sentif['entity_1']['text'][-1] == '.'):\n","        if sentif['entity_1']['text'] not in tmpppent:\n","            print(sentif['entity_1'])\n","            tmpppent.append(sentif['entity_1']['text'])\n","\n","            '''\n","            if '.' == sentif['entity_1']['text'][0]:\n","                print(sentif)\n","            '''\n","\n","    if (sentif['entity_2']['text'][0] == '+') or (sentif['entity_2']['text'][-1] == '.') \\\n","    or (sentif['entity_2']['text'][0] == '.') or (sentif['entity_2']['text'][-1] == '+'):\n","        if sentif['entity_2']['text'] not in tmpppent:\n","            print(sentif['entity_2'])\n","            tmpppent.append(sentif['entity_2']['text'])\n","\n","            '''\n","            if '.' == sentif['entity_2']['text'][0]:\n","                print(sentif)\n","            '''\n"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': 'Nguyễn Văn Q.', 'pos': [127, 140]}\n","{'text': 'H.', 'pos': [104, 106]}\n","{'text': 'T.N.H.', 'pos': [40, 46]}\n","{'text': 'Trần Thị Trúc L.', 'pos': [70, 86]}\n","{'text': 'L.', 'pos': [24, 26]}\n","{'text': 'Đ.', 'pos': [48, 50]}\n","{'text': '/Vietnam+', 'pos': [7, 16]}\n","{'text': '(Vietnam+', 'pos': [10, 19]}\n","{'text': 'Hoàng Thu H.', 'pos': [138, 150]}\n","{'text': 'Nguyễn Thị H.', 'pos': [25, 38]}\n","{'text': 'Lê Quý D.', 'pos': [86, 95]}\n","{'text': 'Lương Văn T.', 'pos': [40, 52]}\n","{'text': 'Cáp Trọng Th.', 'pos': [39, 52]}\n","{'text': 'Dương Thị T.', 'pos': [70, 82]}\n","{'text': 'Th.', 'pos': [56, 59]}\n","{'text': 'Vi Thị O.', 'pos': [21, 30]}\n"]}]},{"cell_type":"code","metadata":{"id":"xzMKF60qhZZF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425127740,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}},"outputId":"c8d193d7-df6c-4f83-a5a5-31ae9e297e2c"},"source":["# lỗi\n","tmpppent = []\n","for sentif in jtest_data_use:\n","    if (sentif['entity_1']['text'][0] == '\\xa0') or (sentif['entity_1']['text'][-1] == '\\xa0'):\n","        if sentif['entity_1']['text'] not in tmpppent:\n","            print(sentif['entity_1'])\n","            tmpppent.append(sentif['entity_1']['text'])\n","\n","            '''\n","            if '.' == sentif['entity_1']['text'][0]:\n","                print(sentif)\n","            '''\n","\n","    if (sentif['entity_2']['text'][0] == '\\xa0') or (sentif['entity_2']['text'][-1] == '\\xa0'):\n","        if sentif['entity_2']['text'] not in tmpppent:\n","            print(sentif['entity_2'])\n","            tmpppent.append(sentif['entity_2']['text'])\n","\n","            '''\n","            if '.' == sentif['entity_2']['text'][0]:\n","                print(sentif)\n","            '''\n"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': '\\xa0Thảo', 'pos': [40, 45]}\n","{'text': '\\xa0Nguyễn Công Thành', 'pos': [103, 121]}\n","{'text': '\\xa0Fukushima', 'pos': [217, 227]}\n","{'text': '\\xa0Helmut Kohl', 'pos': [64, 76]}\n","{'text': '\\xa0Shinawatra', 'pos': [156, 167]}\n","{'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n","{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcokotVKhZZF","outputId":"4123dbfa-85e1-4295-fd97-a30ac8a8d0aa","executionInfo":{"status":"ok","timestamp":1717425128576,"user_tz":-420,"elapsed":841,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n","tmpppent = []\n","for sentif in jtest_data_use:\n","\n","    if sentif['entity_1']['text'] not in tmpppent:\n","        for c in sentif['entity_1']['text'][1:-1]:\n","            if (not c.isalnum()) and (c != ' ') and (c != '.'):\n","                print(sentif['entity_1'])\n","\n","        tmpppent.append(sentif['entity_1']['text'])\n","\n","        '''\n","        if '- Huế' in sentif['entity_1']['text']:\n","            print(sentif)\n","        '''\n","\n","\n","    if sentif['entity_2']['text'] not in tmpppent:\n","        for c in sentif['entity_2']['text'][1:-1]:\n","            if (not c.isalnum()) and (c != ' ') and (c != '.'):\n","                print(sentif['entity_2'])\n","\n","        tmpppent.append(sentif['entity_2']['text'])\n","\n","        '''\n","        if '- Huế' in sentif['entity_2']['text']:\n","            print(sentif)\n","        '''\n","\n"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': 'Phong Nha – Kẻ Bàng', 'pos': [111, 130]}\n","{'text': 'Hạt Kiểm lâm Vườn quốc gia (VQG) Phong Nha – Kẻ Bàng', 'pos': [7, 59]}\n","{'text': 'Hạt Kiểm lâm Vườn quốc gia (VQG) Phong Nha – Kẻ Bàng', 'pos': [7, 59]}\n","{'text': 'Hạt Kiểm lâm Vườn quốc gia (VQG) Phong Nha – Kẻ Bàng', 'pos': [7, 59]}\n","{'text': 'VQG Phong Nha – Kẻ Bàng', 'pos': [57, 80]}\n","{'text': 'Ban quản lý VQG Phong Nha – Kẻ Bàng', 'pos': [29, 64]}\n","{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","{'text': 'Kim Jong-un', 'pos': [24, 35]}\n","{'text': 'Ả-rập Saudi', 'pos': [66, 77]}\n","{'text': 'và\\xa0Đinh Thanh Trung', 'pos': [54, 73]}\n","{'text': 'Hayat Tahrir al-Sham', 'pos': [231, 251]}\n","{'text': 'nguyênJabhat al-Nusra', 'pos': [259, 280]}\n","{'text': 'al-Qaeda', 'pos': [293, 301]}\n","{'text': 'Hayat Tahrlr al-Sham', 'pos': [295, 315]}\n","{'text': 'chị\\xa0Đào Thị Thơm', 'pos': [114, 130]}\n","{'text': 'Bộ TT&TT', 'pos': [89, 97]}\n","{'text': 'Sở TT&TT Gia Lai', 'pos': [65, 81]}\n","{'text': 'phòng CSGT đường bộ-đường sắt', 'pos': [62, 91]}\n","{'text': '(PC67-Công an TP.HCM', 'pos': [92, 112]}\n","{'text': 'Phòng CSGT đường bộ-đường sắt', 'pos': [15, 44]}\n","{'text': 'TAND huyện Cư M’gar', 'pos': [11, 30]}\n","{'text': 'H’A Byă', 'pos': [52, 59]}\n","{'text': 'huyện Cư M’gar', 'pos': [104, 118]}\n","{'text': 'H’M', 'pos': [94, 97]}\n","{'text': 'Dolce&Gabbana', 'pos': [51, 64]}\n","{'text': 'Phòng GD&ĐT Ba Đình', 'pos': [204, 223]}\n","{'text': 'KCN Việt Nam – Singapore', 'pos': [106, 130]}\n","{'text': 'Let’s Việt', 'pos': [259, 269]}\n","{'text': 'VKSND huyện Đắk R’Lấp', 'pos': [41, 62]}\n","{'text': 'huyện Đắk R’Lấp', 'pos': [248, 263]}\n","{'text': 'Đắk R’Lấp', 'pos': [161, 170]}\n","{'text': 'công an huyện Đắk R’Lấp', 'pos': [58, 81]}\n","{'text': 'Erdene-Orchir', 'pos': [78, 91]}\n","{'text': 'Ủy ban Kiểm tra (UBKT) Trung ương', 'pos': [55, 88]}\n","{'text': 'Ủy ban Kiểm tra (UBKT) Trung ương', 'pos': [55, 88]}\n","{'text': '),Vũ Thị Thùy Dương', 'pos': [151, 170]}\n","{'text': 'hội nạn nhân chất độc màu da cam/Dioxin Việt Nam', 'pos': [252, 300]}\n","{'text': 'Bộ GD-ĐT', 'pos': [176, 184]}\n","{'text': 'CSGT Đường bộ - Đường sắt', 'pos': [54, 79]}\n","{'text': 'AFP /TTXVN', 'pos': [0, 10]}\n","{'text': 'là\\xa0Nguyễn Thị Thảo', 'pos': [122, 140]}\n","{'text': 'tịch\\xa0tỉnh Quảng Nam', 'pos': [27, 46]}\n","{'text': 'Công an tỉnh TT-Huế', 'pos': [42, 61]}\n","{'text': '(tỉnh TT-Huế', 'pos': [124, 136]}\n","{'text': 'Ro ‘Béo’', 'pos': [6, 14]}\n","{'text': 'Hải đội 2 – Bộ đội Biên phòng tỉnh Quảng Ninh', 'pos': [114, 159]}\n","{'text': 'Nhật /Nhật', 'pos': [174, 184]}\n","{'text': 'Hiệp hội Phòng cháy chữa cháy (PCCC) Nhật Bản', 'pos': [75, 120]}\n","{'text': 'Hiệp hội Phòng cháy chữa cháy (PCCC) Nhật Bản', 'pos': [75, 120]}\n","{'text': 'Ri Yong-ho', 'pos': [52, 62]}\n","{'text': 'Kang Kyung-wha', 'pos': [56, 70]}\n","{'text': 'tỉnh Bà Rịa - Vũng Tàu', 'pos': [60, 82]}\n","{'text': 'Salman Bin Abdulaziz Al-Saud', 'pos': [285, 313]}\n","{'text': 'viên\\xa0Thanh Niên', 'pos': [58, 73]}\n","{'text': 'Bệnh viện (BV) phẫu thuật thẩm mỹ EMCSA', 'pos': [55, 94]}\n","{'text': 'Bệnh viện (BV) phẫu thuật thẩm mỹ EMCSA', 'pos': [55, 94]}\n","{'text': '(số 14/27 Hoàng Dư Khương', 'pos': [95, 120]}\n","{'text': 'cao tốc Pháp Vân-Cầu Giẽ', 'pos': [28, 52]}\n","{'text': 'đường cao tốc Pháp Vân-Cầu Giẽ', 'pos': [35, 65]}\n","{'text': 'nhóm P5+1', 'pos': [107, 116]}\n","{'text': 'Công ty Cổ phần du lịch – thương mại và đầu tư Thiên Trường', 'pos': [29, 88]}\n","{'text': 'tội,\\xa0Nguyễn Xuân Sơn', 'pos': [31, 51]}\n","{'text': 'tội,\\xa0Nguyễn Xuân Sơn', 'pos': [31, 51]}\n","{'text': 'trẻ,\\xa0Soobin Hoàng Sơn', 'pos': [80, 101]}\n","{'text': 'trẻ,\\xa0Soobin Hoàng Sơn', 'pos': [80, 101]}\n","{'text': 'do\\xa0Hoàng Touliver', 'pos': [131, 148]}\n","{'text': 'nhà máy dệt Kim Jong-suk', 'pos': [78, 102]}\n","{'text': 'Ri Sol-ju', 'pos': [36, 45]}\n","{'text': 'Paekhak-dong', 'pos': [98, 110]}\n","{'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n","{'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n","{'text': '(Bộ TT&TT', 'pos': [20, 29]}\n","{'text': 'Hiệp hội Chữ thập đỏ - Trăng lưỡi liềm đỏ quốc tế', 'pos': [33, 82]}\n","{'text': 'Hiệp Hội Chữ thập Đỏ - Trăng lưỡi liềm Đỏ quốc tế', 'pos': [77, 126]}\n","{'text': 'Hiệp hội Chữ thập Đỏ - Trăng lưỡi liềm Đỏ quốc tế', 'pos': [155, 204]}\n","{'text': 'Bộ thông tin - Truyền thông', 'pos': [69, 96]}\n","{'text': 'Plus/GĐVN', 'pos': [91, 100]}\n","{'text': 'Al-Qaeda', 'pos': [151, 159]}\n","{'text': 'tỉnh Deir al-Zour', 'pos': [157, 174]}\n","{'text': 'Như\\xa0Pháp Luật TP.HCM', 'pos': [0, 20]}\n","{'text': 'mất\\xa0Theo Hernandez', 'pos': [68, 86]}\n","{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n","{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n","{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n","{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n","{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n","{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n","{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n","{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n","{'text': 'Rô-lăng', 'pos': [94, 101]}\n","{'text': 'Or’-lan-đô', 'pos': [111, 121]}\n","{'text': 'Or’-lan-đô', 'pos': [111, 121]}\n","{'text': 'Or’-lan-đô', 'pos': [111, 121]}\n","{'text': 'Sở TN&MT Hà Nội', 'pos': [37, 52]}\n","{'text': 'Hay’at Tahrir Al-Sham', 'pos': [98, 119]}\n","{'text': 'Hay’at Tahrir Al-Sham', 'pos': [98, 119]}\n","{'text': '(Al-Qaeda', 'pos': [120, 129]}\n","{'text': 'Hải đội 2, BĐBP Quảng Ninh', 'pos': [100, 126]}\n","{'text': 'Phòng CSGT Đường bộ - Đường sắt', 'pos': [36, 67]}\n","{'text': 'Quỹ Tấm lòng Việt - Đài Truyền hình Việt Nam', 'pos': [46, 90]}\n","{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n","{'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n","{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n","{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n","{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n","{'text': 'EPA/TTXVN', 'pos': [0, 9]}\n","{'text': ',\\xa0Việt Nam', 'pos': [25, 35]}\n","{'text': 'của\\xa0Vũ Ngọc Nhạ', 'pos': [167, 182]}\n","{'text': \"L'Oreal\", 'pos': [37, 44]}\n","{'text': 'Bà\\xa0Liliane Bettencourt', 'pos': [53, 75]}\n","{'text': 'L’Oreal', 'pos': [5, 12]}\n","{'text': 'La Roche-Posay', 'pos': [88, 102]}\n","{'text': 'Jean-Paul Agon', 'pos': [177, 191]}\n","{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n","{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n","{'text': '(sân\\xa0MFF Football Centre', 'pos': [46, 70]}\n","{'text': ',\\xa0Ulan Bator', 'pos': [71, 83]}\n","{'text': 'đảng “Vì tự do”', 'pos': [384, 399]}\n","{'text': 'Rostov-on-Don', 'pos': [137, 150]}\n","{'text': 'Rostov-on-Don', 'pos': [137, 150]}\n","{'text': '-\\xa0Nam', 'pos': [68, 73]}\n","{'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n","{'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n","{'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n","{'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n","{'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n","{'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n","{'text': 'Sở LĐ-TB-XH Bình Định', 'pos': [0, 21]}\n","{'text': 'Sở LĐ-TB-XH Bình Định', 'pos': [0, 21]}\n"]}]},{"cell_type":"markdown","metadata":{"id":"RpCdj0TVhZZF"},"source":["#### fix start end of entity in data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3v80f4whZZF","outputId":"c74301cd-bf3c-46ca-acb7-93fb0e4e1665","executionInfo":{"status":"ok","timestamp":1717425130931,"user_tz":-420,"elapsed":2358,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["jtest_data_v2 = copy.deepcopy(fix_start_end_of_entity(jtest_data_use))"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","original:       {'text': '(Quảng Bình', 'pos': [219, 230]}\n","new_entity:     {'text': 'Quảng Bình', 'pos': [220, 230]}\n","\n","original:       {'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n","new_entity:     {'text': 'Triều Tiên', 'pos': [7, 17]}\n","\n","original:       {'text': '/Nikkei', 'pos': [10, 17]}\n","new_entity:     {'text': 'Nikkei', 'pos': [11, 17]}\n","\n","original:       {'text': '(CNPC', 'pos': [168, 173]}\n","new_entity:     {'text': 'CNPC', 'pos': [169, 173]}\n","\n","original:       {'text': '/Reuters', 'pos': [10, 18]}\n","new_entity:     {'text': 'Reuters', 'pos': [11, 18]}\n","\n","original:       {'text': '\"Merkel', 'pos': [0, 7]}\n","new_entity:     {'text': 'Merkel', 'pos': [1, 7]}\n","\n","original:       {'text': '\"Trump', 'pos': [0, 6]}\n","new_entity:     {'text': 'Trump', 'pos': [1, 6]}\n","\n","original:       {'text': '\"Hillary Clinton', 'pos': [0, 16]}\n","new_entity:     {'text': 'Hillary Clinton', 'pos': [1, 16]}\n","\n","original:       {'text': '(Cầu Giấy', 'pos': [45, 54]}\n","new_entity:     {'text': 'Cầu Giấy', 'pos': [46, 54]}\n","\n","original:       {'text': '“Joel Matip', 'pos': [0, 11]}\n","new_entity:     {'text': 'Joel Matip', 'pos': [1, 11]}\n","\n","original:       {'text': '“Cơ quan Cảnh sát điều tra', 'pos': [203, 229]}\n","new_entity:     {'text': 'Cơ quan Cảnh sát điều tra', 'pos': [204, 229]}\n","\n","original:       {'text': '(NHNN', 'pos': [90, 95]}\n","new_entity:     {'text': 'NHNN', 'pos': [91, 95]}\n","\n","original:       {'text': '(quận Cầu Giấy', 'pos': [154, 168]}\n","new_entity:     {'text': 'quận Cầu Giấy', 'pos': [155, 168]}\n","\n","original:       {'text': '(số 45 Lý thường Kiệt', 'pos': [243, 264]}\n","new_entity:     {'text': 'số 45 Lý thường Kiệt', 'pos': [244, 264]}\n","\n","original:       {'text': '(VSP', 'pos': [129, 133]}\n","new_entity:     {'text': 'VSP', 'pos': [130, 133]}\n","\n","original:       {'text': '(BSR', 'pos': [175, 179]}\n","new_entity:     {'text': 'BSR', 'pos': [176, 179]}\n","\n","original:       {'text': '(PVEP', 'pos': [222, 227]}\n","new_entity:     {'text': 'PVEP', 'pos': [223, 227]}\n","\n","original:       {'text': '(HTS', 'pos': [252, 256]}\n","new_entity:     {'text': 'HTS', 'pos': [253, 256]}\n","\n","original:       {'text': '(PC67-Công an TP.HCM', 'pos': [92, 112]}\n","new_entity:     {'text': 'PC67-Công an TP.HCM', 'pos': [93, 112]}\n","\n","original:       {'text': '“Damascus', 'pos': [9, 18]}\n","new_entity:     {'text': 'Damascus', 'pos': [10, 18]}\n","\n","original:       {'text': '(Đắk Lắk', 'pos': [31, 39]}\n","new_entity:     {'text': 'Đắk Lắk', 'pos': [32, 39]}\n","\n","original:       {'text': '\\ufeffĐịch Lệ Nhiệt Ba', 'pos': [0, 17]}\n","new_entity:     {'text': 'Địch Lệ Nhiệt Ba', 'pos': [1, 17]}\n","\n","original:       {'text': \"'Lệ cơ\", 'pos': [86, 92]}\n","new_entity:     {'text': 'Lệ cơ', 'pos': [87, 92]}\n","\n","original:       {'text': '(Phường Vĩnh Phúc', 'pos': [97, 114]}\n","new_entity:     {'text': 'Phường Vĩnh Phúc', 'pos': [98, 114]}\n","\n","original:       {'text': '(thị xã Thuận An', 'pos': [131, 147]}\n","new_entity:     {'text': 'thị xã Thuận An', 'pos': [132, 147]}\n","\n","original:       {'text': '(phường Phạm Ngũ Lão', 'pos': [87, 107]}\n","new_entity:     {'text': 'phường Phạm Ngũ Lão', 'pos': [88, 107]}\n","\n","original:       {'text': '(IS', 'pos': [26, 29]}\n","new_entity:     {'text': 'IS', 'pos': [27, 29]}\n","\n","original:       {'text': '(Thanh Hóa', 'pos': [64, 74]}\n","new_entity:     {'text': 'Thanh Hóa', 'pos': [65, 74]}\n","\n","original:       {'text': '(Đồng Nai', 'pos': [95, 104]}\n","new_entity:     {'text': 'Đồng Nai', 'pos': [96, 104]}\n","\n","original:       {'text': '(Nam Định', 'pos': [121, 130]}\n","new_entity:     {'text': 'Nam Định', 'pos': [122, 130]}\n","\n","original:       {'text': '(CLB Vũ Lê', 'pos': [54, 64]}\n","new_entity:     {'text': 'CLB Vũ Lê', 'pos': [55, 64]}\n","\n","original:       {'text': '(Củ Chi', 'pos': [88, 95]}\n","new_entity:     {'text': 'Củ Chi', 'pos': [89, 95]}\n","\n","original:       {'text': '(Quận 3', 'pos': [58, 65]}\n","new_entity:     {'text': 'Quận 3', 'pos': [59, 65]}\n","\n","original:       {'text': '(Phú Nhuận', 'pos': [92, 102]}\n","new_entity:     {'text': 'Phú Nhuận', 'pos': [93, 102]}\n","\n","original:       {'text': '(TP.HCM', 'pos': [168, 175]}\n","new_entity:     {'text': 'TP.HCM', 'pos': [169, 175]}\n","\n","original:       {'text': '(tỉnh Đắk Nông', 'pos': [63, 77]}\n","new_entity:     {'text': 'tỉnh Đắk Nông', 'pos': [64, 77]}\n","\n","original:       {'text': '\"Real', 'pos': [133, 138]}\n","new_entity:     {'text': 'Real', 'pos': [134, 138]}\n","\n","original:       {'text': '\"Người ngoài hành tinh\"', 'pos': [40, 63]}\n","new_entity:     {'text': 'Người ngoài hành tinh', 'pos': [41, 62]}\n","\n","original:       {'text': '(quốc lộ 13', 'pos': [164, 175]}\n","new_entity:     {'text': 'quốc lộ 13', 'pos': [165, 175]}\n","\n","original:       {'text': '),Vũ Thị Thùy Dương', 'pos': [151, 170]}\n","new_entity:     {'text': 'Vũ Thị Thùy Dương', 'pos': [153, 170]}\n","\n","original:       {'text': '(Sài Gòn', 'pos': [199, 207]}\n","new_entity:     {'text': 'Sài Gòn', 'pos': [200, 207]}\n","\n","original:       {'text': '(Hải Dương', 'pos': [230, 240]}\n","new_entity:     {'text': 'Hải Dương', 'pos': [231, 240]}\n","\n","original:       {'text': '(Bình Dương', 'pos': [95, 106]}\n","new_entity:     {'text': 'Bình Dương', 'pos': [96, 106]}\n","\n","original:       {'text': '(Trung Quốc', 'pos': [74, 85]}\n","new_entity:     {'text': 'Trung Quốc', 'pos': [75, 85]}\n","\n","original:       {'text': '-Trung', 'pos': [197, 203]}\n","new_entity:     {'text': 'Trung', 'pos': [198, 203]}\n","\n","original:       {'text': '(OceanBank', 'pos': [184, 194]}\n","new_entity:     {'text': 'OceanBank', 'pos': [185, 194]}\n","\n","original:       {'text': '(Hà Nội', 'pos': [290, 297]}\n","new_entity:     {'text': 'Hà Nội', 'pos': [291, 297]}\n","\n","original:       {'text': \"'MU\", 'pos': [0, 3]}\n","new_entity:     {'text': 'MU', 'pos': [1, 3]}\n","\n","original:       {'text': '(Dân Việt', 'pos': [25, 34]}\n","new_entity:     {'text': 'Dân Việt', 'pos': [26, 34]}\n","\n","original:       {'text': '/VOV', 'pos': [12, 16]}\n","new_entity:     {'text': 'VOV', 'pos': [13, 16]}\n","\n","original:       {'text': '-ĐBSCL', 'pos': [17, 23]}\n","new_entity:     {'text': 'ĐBSCL', 'pos': [18, 23]}\n","\n","original:       {'text': '(quận 10', 'pos': [9, 17]}\n","new_entity:     {'text': 'quận 10', 'pos': [10, 17]}\n","\n","original:       {'text': '(hẻm 438', 'pos': [108, 116]}\n","new_entity:     {'text': 'hẻm 438', 'pos': [109, 116]}\n","\n","original:       {'text': '(Bắc Ninh', 'pos': [110, 119]}\n","new_entity:     {'text': 'Bắc Ninh', 'pos': [111, 119]}\n","\n","original:       {'text': '\\xa0Thảo', 'pos': [40, 45]}\n","new_entity:     {'text': 'Thảo', 'pos': [41, 45]}\n","\n","original:       {'text': '(Hoàng Thị Hồng Tứ', 'pos': [84, 102]}\n","new_entity:     {'text': 'Hoàng Thị Hồng Tứ', 'pos': [85, 102]}\n","\n","original:       {'text': '(tỉnh TT-Huế', 'pos': [124, 136]}\n","new_entity:     {'text': 'tỉnh TT-Huế', 'pos': [125, 136]}\n","\n","original:       {'text': '(huyện Phú Lộc', 'pos': [28, 42]}\n","new_entity:     {'text': 'huyện Phú Lộc', 'pos': [29, 42]}\n","\n","original:       {'text': 'Ro ‘Béo’', 'pos': [6, 14]}\n","new_entity:     {'text': 'Ro ‘Béo', 'pos': [6, 13]}\n","\n","original:       {'text': '\\xa0Nguyễn Công Thành', 'pos': [103, 121]}\n","new_entity:     {'text': 'Nguyễn Công Thành', 'pos': [104, 121]}\n","\n","original:       {'text': '(phường Đông Hưng Thuận', 'pos': [62, 85]}\n","new_entity:     {'text': 'phường Đông Hưng Thuận', 'pos': [63, 85]}\n","\n","original:       {'text': '/TTXVN', 'pos': [4, 10]}\n","new_entity:     {'text': 'TTXVN', 'pos': [5, 10]}\n","\n","original:       {'text': '(Anh', 'pos': [106, 110]}\n","new_entity:     {'text': 'Anh', 'pos': [107, 110]}\n","\n","original:       {'text': '(Mỹ', 'pos': [215, 218]}\n","new_entity:     {'text': 'Mỹ', 'pos': [216, 218]}\n","\n","original:       {'text': '(Pháp', 'pos': [258, 263]}\n","new_entity:     {'text': 'Pháp', 'pos': [259, 263]}\n","\n","original:       {'text': '\\xa0Fukushima', 'pos': [217, 227]}\n","new_entity:     {'text': 'Fukushima', 'pos': [218, 227]}\n","\n","original:       {'text': '(Đông Đức', 'pos': [256, 265]}\n","new_entity:     {'text': 'Đông Đức', 'pos': [257, 265]}\n","\n","original:       {'text': '(KGB', 'pos': [184, 188]}\n","new_entity:     {'text': 'KGB', 'pos': [185, 188]}\n","\n","original:       {'text': '\\xa0Helmut Kohl', 'pos': [64, 76]}\n","new_entity:     {'text': 'Helmut Kohl', 'pos': [65, 76]}\n","\n","original:       {'text': '(Quảng Ninh', 'pos': [108, 119]}\n","new_entity:     {'text': 'Quảng Ninh', 'pos': [109, 119]}\n","\n","original:       {'text': '\\xa0Shinawatra', 'pos': [156, 167]}\n","new_entity:     {'text': 'Shinawatra', 'pos': [157, 167]}\n","\n","original:       {'text': '(SPJD', 'pos': [138, 143]}\n","new_entity:     {'text': 'SPJD', 'pos': [139, 143]}\n","\n","original:       {'text': '(phường 10', 'pos': [69, 79]}\n","new_entity:     {'text': 'phường 10', 'pos': [70, 79]}\n","\n","original:       {'text': '(quận Bình Tân', 'pos': [75, 89]}\n","new_entity:     {'text': 'quận Bình Tân', 'pos': [76, 89]}\n","\n","original:       {'text': '(Oceanbank', 'pos': [101, 111]}\n","new_entity:     {'text': 'Oceanbank', 'pos': [102, 111]}\n","\n","original:       {'text': '(Sa Pa', 'pos': [164, 170]}\n","new_entity:     {'text': 'Sa Pa', 'pos': [165, 170]}\n","\n","original:       {'text': '(huyện Bắc Hà', 'pos': [46, 59]}\n","new_entity:     {'text': 'huyện Bắc Hà', 'pos': [47, 59]}\n","\n","original:       {'text': '(CMC Innovation Fund', 'pos': [190, 210]}\n","new_entity:     {'text': 'CMC Innovation Fund', 'pos': [191, 210]}\n","\n","original:       {'text': '“Ngân hàng Chính sách xã hội', 'pos': [189, 217]}\n","new_entity:     {'text': 'Ngân hàng Chính sách xã hội', 'pos': [190, 217]}\n","\n","original:       {'text': '(NHCSXH', 'pos': [331, 338]}\n","new_entity:     {'text': 'NHCSXH', 'pos': [332, 338]}\n","\n","original:       {'text': '\"Ngân hàng Chính sách xã hội', 'pos': [402, 430]}\n","new_entity:     {'text': 'Ngân hàng Chính sách xã hội', 'pos': [403, 430]}\n","\n","original:       {'text': \"'Hà\", 'pos': [15, 18]}\n","new_entity:     {'text': 'Hà', 'pos': [16, 18]}\n","\n","original:       {'text': '(Chi cục Quản lý thị trường tỉnh Hà Tĩnh', 'pos': [58, 98]}\n","new_entity:     {'text': 'Chi cục Quản lý thị trường tỉnh Hà Tĩnh', 'pos': [59, 98]}\n","\n","original:       {'text': '(số 14/27 Hoàng Dư Khương', 'pos': [95, 120]}\n","new_entity:     {'text': 'số 14/27 Hoàng Dư Khương', 'pos': [96, 120]}\n","\n","original:       {'text': '-Thái Bình Dương', 'pos': [59, 75]}\n","new_entity:     {'text': 'Thái Bình Dương', 'pos': [60, 75]}\n","\n","original:       {'text': '(TTXVN', 'pos': [0, 6]}\n","new_entity:     {'text': 'TTXVN', 'pos': [1, 6]}\n","\n","original:       {'text': '/Vietnam+', 'pos': [7, 16]}\n","new_entity:     {'text': 'Vietnam+', 'pos': [8, 16]}\n","\n","original:       {'text': '(AFC', 'pos': [25, 29]}\n","new_entity:     {'text': 'AFC', 'pos': [26, 29]}\n","\n","original:       {'text': '(Vietnam+', 'pos': [10, 19]}\n","new_entity:     {'text': 'Vietnam+', 'pos': [11, 19]}\n","\n","original:       {'text': '(TP HCM', 'pos': [60, 67]}\n","new_entity:     {'text': 'TP HCM', 'pos': [61, 67]}\n","\n","original:       {'text': '(FA', 'pos': [197, 200]}\n","new_entity:     {'text': 'FA', 'pos': [198, 200]}\n","\n","original:       {'text': '(PC 45', 'pos': [208, 214]}\n","new_entity:     {'text': 'PC 45', 'pos': [209, 214]}\n","\n","original:       {'text': '(Bộ Tài nguyên và Môi trường', 'pos': [156, 184]}\n","new_entity:     {'text': 'Bộ Tài nguyên và Môi trường', 'pos': [157, 184]}\n","\n","original:       {'text': '“Tỉnh Hải Dương', 'pos': [0, 15]}\n","new_entity:     {'text': 'Tỉnh Hải Dương', 'pos': [1, 15]}\n","\n","original:       {'text': '(Hải Phòng', 'pos': [73, 83]}\n","new_entity:     {'text': 'Hải Phòng', 'pos': [74, 83]}\n","\n","original:       {'text': '-Cầu Giẽ', 'pos': [154, 162]}\n","new_entity:     {'text': 'Cầu Giẽ', 'pos': [155, 162]}\n","\n","original:       {'text': '-Nga', 'pos': [3, 7]}\n","new_entity:     {'text': 'Nga', 'pos': [4, 7]}\n","\n","original:       {'text': '(IAEA', 'pos': [275, 280]}\n","new_entity:     {'text': 'IAEA', 'pos': [276, 280]}\n","\n","original:       {'text': '(LHQ', 'pos': [418, 422]}\n","new_entity:     {'text': 'LHQ', 'pos': [419, 422]}\n","\n","original:       {'text': '(NATO', 'pos': [35, 40]}\n","new_entity:     {'text': 'NATO', 'pos': [36, 40]}\n","\n","original:       {'text': \"'Biển chết\", 'pos': [0, 10]}\n","new_entity:     {'text': 'Biển chết', 'pos': [1, 10]}\n","\n","original:       {'text': \"'biển Chết\", 'pos': [81, 91]}\n","new_entity:     {'text': 'biển Chết', 'pos': [82, 91]}\n","\n","original:       {'text': '(huyện Cần Giuộc', 'pos': [63, 79]}\n","new_entity:     {'text': 'huyện Cần Giuộc', 'pos': [64, 79]}\n","\n","original:       {'text': '(NAPAS', 'pos': [79, 85]}\n","new_entity:     {'text': 'NAPAS', 'pos': [80, 85]}\n","\n","original:       {'text': '(Thượng Hóa', 'pos': [81, 92]}\n","new_entity:     {'text': 'Thượng Hóa', 'pos': [82, 92]}\n","\n","original:       {'text': '(Thái Lan', 'pos': [150, 159]}\n","new_entity:     {'text': 'Thái Lan', 'pos': [151, 159]}\n","\n","original:       {'text': '-đảng Xanh', 'pos': [290, 300]}\n","new_entity:     {'text': 'đảng Xanh', 'pos': [291, 300]}\n","\n","original:       {'text': '(Phòng CSGT Thanh Hóa', 'pos': [131, 152]}\n","new_entity:     {'text': 'Phòng CSGT Thanh Hóa', 'pos': [132, 152]}\n","\n","original:       {'text': '(Indonesia', 'pos': [26, 36]}\n","new_entity:     {'text': 'Indonesia', 'pos': [27, 36]}\n","\n","original:       {'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n","new_entity:     {'text': 'Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [84, 148]}\n","\n","original:       {'text': '(Bộ TT&TT', 'pos': [20, 29]}\n","new_entity:     {'text': 'Bộ TT&TT', 'pos': [21, 29]}\n","\n","original:       {'text': '\\ufeffBảo Anh', 'pos': [0, 8]}\n","new_entity:     {'text': 'Bảo Anh', 'pos': [1, 8]}\n","\n","original:       {'text': '(NCA', 'pos': [165, 169]}\n","new_entity:     {'text': 'NCA', 'pos': [166, 169]}\n","\n","original:       {'text': '(Nghệ An', 'pos': [44, 52]}\n","new_entity:     {'text': 'Nghệ An', 'pos': [45, 52]}\n","\n","original:       {'text': 'Nguyễn Xuân Huân -', 'pos': [91, 109]}\n","new_entity:     {'text': 'Nguyễn Xuân Huân', 'pos': [91, 107]}\n","\n","original:       {'text': '(TP Vinh', 'pos': [140, 148]}\n","new_entity:     {'text': 'TP Vinh', 'pos': [141, 148]}\n","\n","original:       {'text': '(CDU', 'pos': [93, 97]}\n","new_entity:     {'text': 'CDU', 'pos': [94, 97]}\n","\n","original:       {'text': '/AP', 'pos': [8, 11]}\n","new_entity:     {'text': 'AP', 'pos': [9, 11]}\n","\n","original:       {'text': '(phường Trung Hòa', 'pos': [76, 93]}\n","new_entity:     {'text': 'phường Trung Hòa', 'pos': [77, 93]}\n","\n","original:       {'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n","new_entity:     {'text': 'A-ri-ô-xtô', 'pos': [18, 28]}\n","\n","original:       {'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n","new_entity:     {'text': 'Charlemagne (Sar’-lơ-ma-nhơ', 'pos': [9, 36]}\n","\n","original:       {'text': '-Syria', 'pos': [45, 51]}\n","new_entity:     {'text': 'Syria', 'pos': [46, 51]}\n","\n","original:       {'text': '(Al-Qaeda', 'pos': [120, 129]}\n","new_entity:     {'text': 'Al-Qaeda', 'pos': [121, 129]}\n","\n","original:       {'text': '–HTS', 'pos': [136, 140]}\n","new_entity:     {'text': 'HTS', 'pos': [137, 140]}\n","\n","original:       {'text': '-Mỹ', 'pos': [163, 166]}\n","new_entity:     {'text': 'Mỹ', 'pos': [164, 166]}\n","\n","original:       {'text': '“Ủy ban tiếp quản Deir Ezzor', 'pos': [25, 53]}\n","new_entity:     {'text': 'Ủy ban tiếp quản Deir Ezzor', 'pos': [26, 53]}\n","\n","original:       {'text': '-SDF', 'pos': [3, 7]}\n","new_entity:     {'text': 'SDF', 'pos': [4, 7]}\n","\n","original:       {'text': '(VINASA', 'pos': [170, 177]}\n","new_entity:     {'text': 'VINASA', 'pos': [171, 177]}\n","\n","original:       {'text': '“tiểu Kompany”', 'pos': [32, 46]}\n","new_entity:     {'text': 'tiểu Kompany', 'pos': [33, 45]}\n","\n","original:       {'text': '(Quảng Nam', 'pos': [125, 135]}\n","new_entity:     {'text': 'Quảng Nam', 'pos': [126, 135]}\n","\n","original:       {'text': '(TP Quy Nhơn', 'pos': [105, 117]}\n","new_entity:     {'text': 'TP Quy Nhơn', 'pos': [106, 117]}\n","\n","original:       {'text': '(huyện Bình Sơn', 'pos': [161, 176]}\n","new_entity:     {'text': 'huyện Bình Sơn', 'pos': [162, 176]}\n","\n","original:       {'text': '(Phú Yên', 'pos': [104, 112]}\n","new_entity:     {'text': 'Phú Yên', 'pos': [105, 112]}\n","\n","original:       {'text': \"'Bao Thanh Thiên\", 'pos': [0, 16]}\n","new_entity:     {'text': 'Bao Thanh Thiên', 'pos': [1, 16]}\n","\n","original:       {'text': '\"Bao Thanh Thiên', 'pos': [9, 25]}\n","new_entity:     {'text': 'Bao Thanh Thiên', 'pos': [10, 25]}\n","\n","original:       {'text': '(Viettel', 'pos': [130, 138]}\n","new_entity:     {'text': 'Viettel', 'pos': [131, 138]}\n","\n","original:       {'text': '-Liên Xô', 'pos': [43, 51]}\n","new_entity:     {'text': 'Liên Xô', 'pos': [44, 51]}\n","\n","original:       {'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n","new_entity:     {'text': 'khách sạn Pierre & Vacances', 'pos': [57, 84]}\n","\n","original:       {'text': '(Hà Văn Thắm', 'pos': [183, 195]}\n","new_entity:     {'text': 'Hà Văn Thắm', 'pos': [184, 195]}\n","\n","original:       {'text': '(DongA Bank', 'pos': [201, 212]}\n","new_entity:     {'text': 'DongA Bank', 'pos': [202, 212]}\n","\n","original:       {'text': '(Agribank', 'pos': [46, 55]}\n","new_entity:     {'text': 'Agribank', 'pos': [47, 55]}\n","\n","original:       {'text': '(HDBank', 'pos': [180, 187]}\n","new_entity:     {'text': 'HDBank', 'pos': [181, 187]}\n","\n","original:       {'text': '/Dân Việt', 'pos': [50, 59]}\n","new_entity:     {'text': 'Dân Việt', 'pos': [51, 59]}\n","\n","original:       {'text': '(Lào Cai', 'pos': [86, 94]}\n","new_entity:     {'text': 'Lào Cai', 'pos': [87, 94]}\n","\n","original:       {'text': '(xã Gia Phú', 'pos': [53, 64]}\n","new_entity:     {'text': 'xã Gia Phú', 'pos': [54, 64]}\n","\n","original:       {'text': '(VAS', 'pos': [75, 79]}\n","new_entity:     {'text': 'VAS', 'pos': [76, 79]}\n","\n","original:       {'text': '(VietCham Singapore', 'pos': [120, 139]}\n","new_entity:     {'text': 'VietCham Singapore', 'pos': [121, 139]}\n","\n","original:       {'text': ',\\xa0Việt Nam', 'pos': [25, 35]}\n","new_entity:     {'text': 'Việt Nam', 'pos': [27, 35]}\n","\n","original:       {'text': '(Vietnammese Association in Singapore', 'pos': [58, 95]}\n","new_entity:     {'text': 'Vietnammese Association in Singapore', 'pos': [59, 95]}\n","\n","original:       {'text': '(Jake Gyllenhaal', 'pos': [72, 88]}\n","new_entity:     {'text': 'Jake Gyllenhaal', 'pos': [73, 88]}\n","\n","original:       {'text': '-Tây Nguyên', 'pos': [14, 25]}\n","new_entity:     {'text': 'Tây Nguyên', 'pos': [15, 25]}\n","\n","original:       {'text': '“Tevez', 'pos': [0, 6]}\n","new_entity:     {'text': 'Tevez', 'pos': [1, 6]}\n","\n","original:       {'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n","new_entity:     {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n","\n","original:       {'text': '(sân\\xa0MFF Football Centre', 'pos': [46, 70]}\n","new_entity:     {'text': 'sân\\xa0MFF Football Centre', 'pos': [47, 70]}\n","\n","original:       {'text': ',\\xa0Ulan Bator', 'pos': [71, 83]}\n","new_entity:     {'text': 'Ulan Bator', 'pos': [73, 83]}\n","\n","original:       {'text': '(EU', 'pos': [112, 115]}\n","new_entity:     {'text': 'EU', 'pos': [113, 115]}\n","\n","original:       {'text': '(CSU', 'pos': [163, 167]}\n","new_entity:     {'text': 'CSU', 'pos': [164, 167]}\n","\n","original:       {'text': '(SPD', 'pos': [291, 295]}\n","new_entity:     {'text': 'SPD', 'pos': [292, 295]}\n","\n","original:       {'text': '/CSU', 'pos': [85, 89]}\n","new_entity:     {'text': 'CSU', 'pos': [86, 89]}\n","\n","original:       {'text': '(FDP', 'pos': [53, 57]}\n","new_entity:     {'text': 'FDP', 'pos': [54, 57]}\n","\n","original:       {'text': '(đảng Xanh', 'pos': [90, 100]}\n","new_entity:     {'text': 'đảng Xanh', 'pos': [91, 100]}\n","\n","original:       {'text': '(AfD', 'pos': [48, 52]}\n","new_entity:     {'text': 'AfD', 'pos': [49, 52]}\n","\n","original:       {'text': 'đảng “Vì tự do”', 'pos': [384, 399]}\n","new_entity:     {'text': 'đảng “Vì tự do', 'pos': [384, 398]}\n","\n","original:       {'text': '(PVV', 'pos': [400, 404]}\n","new_entity:     {'text': 'PVV', 'pos': [401, 404]}\n","\n","original:       {'text': '(huyện Năm Căn', 'pos': [104, 118]}\n","new_entity:     {'text': 'huyện Năm Căn', 'pos': [105, 118]}\n","\n","original:       {'text': '(Cà Mau', 'pos': [60, 67]}\n","new_entity:     {'text': 'Cà Mau', 'pos': [61, 67]}\n","\n","original:       {'text': '(VOV', 'pos': [0, 4]}\n","new_entity:     {'text': 'VOV', 'pos': [1, 4]}\n","\n","original:       {'text': '(VnExpress', 'pos': [0, 10]}\n","new_entity:     {'text': 'VnExpress', 'pos': [1, 10]}\n","\n","original:       {'text': '(Thanh niên', 'pos': [0, 11]}\n","new_entity:     {'text': 'Thanh niên', 'pos': [1, 11]}\n","\n","original:       {'text': \"'Đông Phương Bất Bại\", 'pos': [79, 99]}\n","new_entity:     {'text': 'Đông Phương Bất Bại', 'pos': [80, 99]}\n","\n","original:       {'text': '(Vĩnh Long', 'pos': [56, 66]}\n","new_entity:     {'text': 'Vĩnh Long', 'pos': [57, 66]}\n","\n","original:       {'text': '(Bản Yên Sơn', 'pos': [64, 76]}\n","new_entity:     {'text': 'Bản Yên Sơn', 'pos': [65, 76]}\n","\n","original:       {'text': '(tỉnh Thái Nguyên', 'pos': [52, 69]}\n","new_entity:     {'text': 'tỉnh Thái Nguyên', 'pos': [53, 69]}\n","\n","original:       {'text': '(Hà Đông', 'pos': [20, 28]}\n","new_entity:     {'text': 'Hà Đông', 'pos': [21, 28]}\n","\n","original:       {'text': '(Đống Đa', 'pos': [6, 14]}\n","new_entity:     {'text': 'Đống Đa', 'pos': [7, 14]}\n","\n","original:       {'text': '(Australia', 'pos': [139, 149]}\n","new_entity:     {'text': 'Australia', 'pos': [140, 149]}\n","\n","original:       {'text': '-\\xa0Nam', 'pos': [68, 73]}\n","new_entity:     {'text': 'Nam', 'pos': [70, 73]}\n","\n","original:       {'text': '(IOM', 'pos': [164, 168]}\n","new_entity:     {'text': 'IOM', 'pos': [165, 168]}\n","\n","original:       {'text': '(Hàn Quốc', 'pos': [38, 47]}\n","new_entity:     {'text': 'Hàn Quốc', 'pos': [39, 47]}\n","\n","original:       {'text': '(Hà Nội)', 'pos': [128, 136]}\n","new_entity:     {'text': 'Hà Nội', 'pos': [129, 135]}\n","\n","original:       {'text': '(Fed New York', 'pos': [170, 183]}\n","new_entity:     {'text': 'Fed New York', 'pos': [171, 183]}\n","\n","original:       {'text': '-Việt Nam', 'pos': [247, 256]}\n","new_entity:     {'text': 'Việt Nam', 'pos': [248, 256]}\n","\n","original:       {'text': '(Bình Định', 'pos': [192, 202]}\n","new_entity:     {'text': 'Bình Định', 'pos': [193, 202]}\n"]}]},{"cell_type":"markdown","metadata":{"id":"JcwMQApng86X"},"source":["# Install Pytorch/XLA for using TPU"]},{"cell_type":"code","metadata":{"id":"44bbgzl_g_2h","executionInfo":{"status":"ok","timestamp":1717425130931,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["###import os\n","###assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"NnJK-U0OhCJg","executionInfo":{"status":"ok","timestamp":1717425130931,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["###!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhLi-foUnFyS","executionInfo":{"status":"ok","timestamp":1717425130931,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["###os.environ['XLA_USE_BF16'] = \"1\""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"DrfoTuISvWoh","executionInfo":{"status":"ok","timestamp":1717425130931,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["###!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","###!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"wQ5JPjBUvq1g","executionInfo":{"status":"ok","timestamp":1717425130931,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["###os.environ['XLA_USE_BF16'] = \"1\""],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uYgSRt5lcdsA"},"source":["# Build model"]},{"cell_type":"markdown","metadata":{"id":"7COIdSRHZww2"},"source":["## Config"]},{"cell_type":"code","metadata":{"id":"bPco5igPEJfC","executionInfo":{"status":"ok","timestamp":1717425130931,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["\"\"\" All model config \"\"\"\n","\n","flags = {\n","\n","    'vnlib': 'underthesea',  # underthesea, vncorenlp (code bên dưới chỉ dùng được cho underthesea, thư viện này có vẻ tốt hơn vncorenlp)\n","\n","\t'model_save_folder': 'rec_save_model',\n","\n","    'use_phobert': True,   # True, False   (có dùng phobert hay không)\n","    'phobert_model': 'phobert_base', # phobert_base, phobert_large\n","    'pb_entity_handle_type': 'average_pooling',       # max_pooling, average_pooling, sum, random.  lấy max hay average pooling, ... word_piece\n","    'pb_emb_layer_lst': [2,3,4,5,6,7,8,9,10,11,12,13],             # danh sách các layer mà ta sẽ lấy embedding. từ 1 -> 13 cho phobert_base, 1 -> 25 cho phobert_large.\n","                                          # layer số 1 là initial embedding\n","    'pb_emb_layer_handle_type': 'sum',   # sum, concat, max_pooling, average_pooling. cách ta xử lý các layer mà ta lấy embedding.\n","                                          # như concat hay lấy sum 4 layer cuối của 1 word_piece\n","    'pb_combine_ents_rule': ['ent_1', 'ent_2', 'mul', 'add', 'abs_sub'], # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n","                                                                         # curent not implemented, just use case above.\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # nếu sau này đổi mà khiến số lượng element của list thay đổi (khác 5)\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # thì cần phải cập nhật chiều dài trong calculate_len_sent_embedding\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # sent_emb_len = entity_emb_len * 5\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # đổi 5 thành chiều dài mới của list.\n","\n","\n","\n","    'use_xlmr': False,   # True, False   (có dùng XLM-RoBERTa hay không)\n","    'xlmr_model': 'xlmr_large', # xlmr_base, xlmr_large\n","    'xlmr_entity_handle_type': 'average_pooling',       # max_pooling, average_pooling, sum, random.  lấy max hay average pooling, ... word_piece\n","    'xlmr_emb_layer_lst': [22,23,24,25],             # danh sách các layer mà ta sẽ lấy embedding. từ 1 -> 13 cho xlmr_base, 1 -> 25 cho xlmr_large.\n","                                            # layer số 1 là initial embedding\n","    'xlmr_emb_layer_handle_type': 'sum',   # sum, concat, max_pooling, average_pooling. cách ta xử lý các layer mà ta lấy embedding.\n","                                            # như concat hay lấy sum 4 layer cuối của 1 word_piece\n","    'xlmr_combine_ents_rule': ['ent_1', 'ent_2', 'mul', 'add', 'abs_sub'], # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n","                                                                           # curent not implemented, just use case above.\n","\n","\n","\n","\n","\n","\n","\n","    'total_epochs': 100,       #\n","\n","\t# we will huggingface adamw as optimizer for phobert and xlmr\n","    'phobert_num_epochs': 4,    # num epoch of fintune phobert. after this epoch, we will freeze phobert layer. 0 mean no finetune.\n","    'phobert_lr': 0.001,\n","\n","\t# chắc k chỉnh mấy cái dưới cơ mà cứ thêm để có gì chỉnh đỡ phải sửa vào code\n","\t'phobert_weight_decay': 0,\n","\t'phobert_betas': (0.9, 0.999),\n","\t'phobert_eps': 1e-6,\n","\n","\n","\n","\t'xlmr_num_epochs': 0,    # num epoch of fintune xlmr. after this epoch, we will freeze xlmr layer. 0 mean no finetune.\n","    'xlmr_lr': 0.001,\n","\n","\t# chắc k chỉnh mấy cái dưới cơ mà cứ thêm để có gì chỉnh đỡ phải sửa vào code\n","\t'xlmr_weight_decay': 0,\n","\t'xlmr_betas': (0.9, 0.999),\n","\t'xlmr_eps': 1e-6,\n","\n","\n","\n","\t'batch_size': 32,        # 8, 16, 64\n","\n","\t'dropout1_rate': 0.65,\n","\t'out_linear1': 1024,\n","\t'dropout2_rate': 0.25,\n","\n","\t'clip_grad_norm_rate': 5.5,\n","\n","\t# linear\n","\t'linear_lr': 0.00001,\n","\t'linear_lr_schedule_epoch': 5,\n","\t'linear_lr_schedule_rate': 0.9,\n","\n","\t# chắc k chỉnh mấy cái dưới cơ mà cứ thêm để có gì chỉnh đỡ phải sửa vào code\n","\t'linear_weight_decay': 0.5,\n","\t'linear_betas': (0.9, 0.999),\n","\t'linear_eps': 1e-6,\n","\n","\n","    'seed': 6,\n","\t'log_batch': 30,\n","\n","\n","\n","    'num_workers': 8         # Number of tpu core. Colab has TPU V2-8 which have 8 cores.\n","\n","\n","\n","}"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tb5kMJ-VC2Iz"},"source":["## Import, turn on TPU"]},{"cell_type":"code","metadata":{"id":"rLGpzWTJMY7y","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"ea51100a-7719-4975-ce1c-f5770b60d70d","executionInfo":{"status":"ok","timestamp":1717425136412,"user_tz":-420,"elapsed":5483,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["import os, time\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, Sampler, TensorDataset, random_split\n","\n","from transformers import AutoModel, AutoTokenizer, XLMRobertaModel, XLMRobertaTokenizer, AdamW\n","\n","'''\n","# TPU\n","# imports the torch_xla package\n","import torch\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","\n","import torch_xla.distributed.parallel_loader as pl\n","'''"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# TPU\\n# imports the torch_xla package\\nimport torch\\nimport torch_xla\\nimport torch_xla.core.xla_model as xm\\nimport torch_xla.distributed.xla_multiprocessing as xmp\\n\\nimport torch_xla.distributed.parallel_loader as pl\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"1OWIkCz9aYyV"},"source":["## Generate model and tokenier"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["db2490257a1f4c3987221f328a5fe50b","cc784e410ea846d6a93ad44276558dce","c76a14f7f1f04fafb5ddea23df1b0f14","8ef9915c5f3c4894a638db21165de2ae","7720382dbb90415299464ec071d86010","d8a1900375f94d348175a67f60441331","1663ebc6776b4be69a89470f259a38f8","82ede0c8ddd7495a9087f001efb8b847","6e53a721a37c4ac89ea08ba0ade154b4","ad78a146179a4a84a4ed04f6afb18d05","97e9667ba90b4605af0f3db4a718f798","cd991df19d054a95bc797f8512b9a843","515d452cfb614ac68bcd85e90833689f","2b8da848464b4944a297559caa73b1b6","bc819b39848d49ceb6ce1d9bfe6f61c0","cc48aab445ce4779b88030779526ab0c","b1065b961d3044719d483eb5b3591f43","18737bb3284d491da82b681700560010","fb73d971096b4da0a33f122fc53b94ba","30146bfd162146c18d30726deac25276","fd01e6796a94411c94138e4aaa790561","c0b609489b6945e59838c4593e143f81","9515a031c6ad4e798b695b595b1afae4","3442301c928642528be3ac1ae1eeeb12","d2de6a3922494e5bb42a3adcdd271fdc","bce71def893149e4b7dd30ce3e0f23f3","fbea91a6a780458c959177f3074e07f8","d33b75c9c6ab4f90bd62f086be566be4","9d6f15bbc36349949e38badef3fb7e7f","f2d5c31fd6c447ddaf775ba4acf26918","8a577488c7fc4564be73ad31fd60b173","e89ec46a4a434fcabc515301a672ad61","8eb7b03a42464d25aab6f9fbadbfe27f","157307f9b64f4e1289296c724232a89d","65e3541be15e40ada4a3aefad5d446e8","40edc72976034beeb53efb24db1848a0","003afa1110b14256a721f0e6d1ea76c3","f95c57f4ae64433fbbe407e32d4b295f","a27a5544e805455ca7be5ef5b844601f","e9f8ca3d59274eddba53f463f6253a6e","a9dbbec7a8d0466d9013fe753e523d96","972f2e403c1c4dd9b4393cadcbee1933","5a8d67377e6246fa8cec09096ba39175","c7640e7b918241b89473eecce9b718d7","d2c2c87be7b54207b4aa2d80e2c85031","db66da187baa4a86b5ce568fba46eeef","908f9971a60e4e9bacfd33b9dacb4f0e","eb7fcc35052a494ca795dc69de48992c","2bb5c47550884936ac20601c71fc8836","936f5967caa7465fa698348d98cb6f39","3f4bae5074f541cbaa4f90dec8fae6d2","47e9a3e5cca84537b871d1a3f1a34de3","06dc0ac2437d42e0811e16bb6e71ce73","fdf44127480247dda5498dc2cc708919","0d887999f962471e8f8f1ad30241d32c","9faf786b6b12481a9f0053a1379b61b8","4bc10d1dc34f473085711fe97bb7702b","460e68ae0df445a5bc59af15c2255a44","911a290f767f45c58f0d225b820d0f01","d1058877cef84901941dcaaf9a302faa","dd033c47510846cf8d16e8ba933da003","21525531c8724178a3a236829e2ee085","ec142c0397b342bba4ad840835a774ab","05cfe5ce0ac24f62a152c630f6fc038d","39b197e78dea4c9d97fbec70f4aeef22","d991c6803cb248b4aaee52c48cbf0e73","40ad02638b174e7fa4890ab9ef992001","88c1d2d6383a47fa800b059fb6a873fd","7c9dd791dd4d47f5b9af957bae334f79","f63bff3c862d4a9783adbeff352d838b","3fabc18e4564481c9345cec0aa73c0bf","bf47f8efd86d489bb116bab1cd091f9d","4bf39bc437fa46d6ab4d7a294fe3609c","8b615cbacc594dab94688158b2ced87f","24be0f87fdd04b2f8da8aa13a13a76af","689e1083c1d64022a8c399b755802d5f","f8e1757f1e524baea9917f5b9b1606c5","352559c3b5f746ec8a231768e3493818","0c9fcf3ae099415d9a03d69ff6e60809","b5e304ea085f4614875a1baf29375442","af315ad357484d93a4b0fd37745b3524","034cfc0b8589446cad48d20405d1c55b","f413df97da3e44f0abed098a4ef35363","af63673e3aa34a57af83b71a74adf194","0ad5e1dce0544dcf86fb9ade999986b3","c41eefb0d41546dbb162d704e4c3757b","a448589abb1c4a7191235990a630914f","4195a8bb7ba74cebb8f674bf26239c93","bfa6b2c4846d4ed18b58c0fafff59883","ebedbeb711714718bc103551b27b1898","d107fa4dd0414b048ce042dd350ad37e","17153b4cb847435bbe5b8a577fc4279b","cdcb5a0aa062457086ff75a9acacb982","1a98b337efbf4c5fbdd1009ee059ff14","4309dca5fbef404785f93d8b78013702","6141883516e7482ab67f96ddbff61796","30d263de09c04ab3b0bb5d8202302bf1","b39d76f833524a7c86152798870ce4d9","9de7716bc26d4c6eba078eb1e041619f","9f8fbccbf80d4879b9c01172b0f0b07c","22085ef061da4cde8cfdacf432aa0e1f","a180af7667914d64bef82827a8404d05","d92d0fddb44347d985a4c6f87930a481","96eb8c4d95bc4a0cb3dc7146a9e2e96b","fef610bf4a5a4e7eaf725daf988463e8","989bcb5bad464ab2833ec8c7cffa189d","a3d5a4a48ded4300b41e442368fd140f","9513e81b1db14731979ac125c54b8d33","b99414edac014d68860690afa198ed83","416ad08d91174ace95ccd048cf277c3a","1fe4e95222364ce49315b30690434060","c69a17e4965d44c7a18fc85803111841","7c10c61c7f52412b944150b07201ec49","b8cf99ad2b2a4c7f854178837434abdb","4d90e4e8d33f44ed8c51206e2c34be99","4079f6743b6f47ffa0ab5396249dfe6b","c40484c17ea14588bc568c0895591e6e","b42b2806e9094203af8d7796f65e723a","3bd13a768f6d40dd964cda589f21de10","e0d2acabf3ce4901acf1e255a2dddbeb","ae23e80e0fdb488c8dc08240ccb66508","e12e084d9490418fa4b6097f3b2d23c7","d1d2bf7b147d4e96b09719fbd58c3ab1","3daf23f10f2d4c2f8672bea34baec6c3","b2a70ee9e05f430da5cfb3970cd23570","fd04dd2a96fd4f229f36fb0bbf121993","844eb6e2e34c457f8f859522d266b842","6f6476e1a95d4f1d988d5b26d74bd89d","748fe039ee0847ef83b36acc37f4efef","dd8e99fb82cf46cb9a8179451da59c9d","72f59b531bac41e2b62b9383cedced1c","9eaa04a8988a4c0f84328fd16d1f3c80","53444fe889174f79a26cda68a6478dfe","75b18326b4fb428daa311d35069f6bee","e8318e7a10634a0b90368843f892aca7","a917bbe12cb84cd38d41d7ccc117b5d3","68bcca7aab2b4a2aa29a85d61c3ec423","d8e10a3f0537423fa995682e790325e8","e17cb1dabce045a7bdf040b3a4339ff1","a4817be7d0c343959d866f368ae308e8","f905098202c242b1adcb163229dde08c","93f6b27f3e654af8b9da176f80d7f906","2b821f2c59024041bfef2706213620ee","2f7bd6f631264a48b03054ef6566c9c7","35526c78c698493585376c52d4b7f68c","efdadd624f4f48b0ab7f54ff8a205639","db55de1fe8c84ebf8b85debb83123403","1f94dbe1bc9a471ca81d9b20d77435c4","1e9ae9e7a6414ddaa4bb24e79ddd131c","7bfbf827e4b64a38aeaad15c20f8b0b6","4e1d669bb6df409aa75c8d45a5678368","608be1953ff448f0b71803fcc95c1f3a","aea8268213e84badbbdd928cd6a228e4","602192a9fa96415f9c92ea18553ef46d","39c428138a5b4377bf64483e09f563ac","3a61c918696e48c986298f008fbf3b3e","5c12dbe3a5d24111b10e41bd9a9b8077","a419934029ee49af9d23142545f8b9ad","70ccd0a7e13940fd9a9cbddf481b4393","2d66a68732b044739cea603db9dc0d1c","e033bfaf5db348b89c6f1983cccd2d97","91b4d7997fb3456e87177d6d98a531dc","45e5c095a29b4d93b4a74edd1a11718b","b5dba4d83ee54468b309d1ba33188bc9","d20a167a5c214d06811636f303d6b692","bf90bf113cb74d39812efe68cb285372","b28aed0a641844fe8df6a2f7c357f24c","bcc9bd832ae94af1bc302d3bbc3fd68b","a85ca344ca264b30af21c2d6d048c452","1654c4191e1c4c5694e36c931a89e9e6","be282a816b8c4932a2ed1993d330564f","bd69cca9c4f8448cb9c20d7e84196783","1598ef5c8589408f838c683ec00a9b96","3c250d90c8f840d299e31313c25a638c","faebc45024d94675a09324ce14a39aae","a395d5aa58954d799903a96ab792dbff"],"height":688},"id":"bozPQIurTSii","outputId":"61238e1d-9bd1-432c-ea58-33d4a35b653a","executionInfo":{"status":"ok","timestamp":1717425165218,"user_tz":-420,"elapsed":28810,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["#pb_base_model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","pb_base_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","#pb_large_model = AutoModel.from_pretrained(\"vinai/phobert-large\")\n","pb_large_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\")\n","\n","#xlmr_base_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n","xlmr_base_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n","\n","#xlmr_large_model = XLMRobertaModel.from_pretrained('xlm-roberta-large')\n","xlmr_large_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db2490257a1f4c3987221f328a5fe50b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd991df19d054a95bc797f8512b9a843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9515a031c6ad4e798b695b595b1afae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"157307f9b64f4e1289296c724232a89d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2c2c87be7b54207b4aa2d80e2c85031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9faf786b6b12481a9f0053a1379b61b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ad02638b174e7fa4890ab9ef992001"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"352559c3b5f746ec8a231768e3493818"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfa6b2c4846d4ed18b58c0fafff59883"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8fbccbf80d4879b9c01172b0f0b07c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fe4e95222364ce49315b30690434060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e12e084d9490418fa4b6097f3b2d23c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53444fe889174f79a26cda68a6478dfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f7bd6f631264a48b03054ef6566c9c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39c428138a5b4377bf64483e09f563ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf90bf113cb74d39812efe68cb285372"}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"M5gepmeCzx1H","outputId":"e3ba1f84-5536-4d33-a03a-7056c1bd61d9","executionInfo":{"status":"ok","timestamp":1717425165218,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["'''\n","if flags['use_phobert'] == True:\n","    if flags['phobert_model'] == 'phobert_base':\n","        print('Using phobert_base.')\n","        pb_model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","        pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","    elif flags['phobert_model'] == 'phobert_large':\n","        print('Using phobert_large.')\n","        pb_model = AutoModel.from_pretrained(\"vinai/phobert-large\")\n","        pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\")\n","\n","    else:\n","        assert False, str('Unknown phobert model: ' + flags['phobert_model'] + '. Allowed: phobert_base and phobert_large')\n","\n","if flags['use_xlmr'] == True:\n","    if flags['xlmr_model'] == 'xlmr_base':\n","        print('Using xlmr_base.')\n","        xlmr_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n","        xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n","\n","    elif flags['xlmr_model'] == 'xlmr_large':\n","        print('Using xlmr_large.')\n","        xlmr_model = XLMRobertaModel.from_pretrained('xlm-roberta-large')\n","        xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n","\n","    else:\n","        assert False, str('Unknown phobert model: ' + flags['xlmr_model'] + '. Allowed: xlmr_base and xlmr_large')\n","'''"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nif flags[\\'use_phobert\\'] == True:\\n    if flags[\\'phobert_model\\'] == \\'phobert_base\\':\\n        print(\\'Using phobert_base.\\')\\n        pb_model = AutoModel.from_pretrained(\"vinai/phobert-base\")\\n        pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\\n\\n    elif flags[\\'phobert_model\\'] == \\'phobert_large\\':\\n        print(\\'Using phobert_large.\\')\\n        pb_model = AutoModel.from_pretrained(\"vinai/phobert-large\")\\n        pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\")\\n\\n    else:\\n        assert False, str(\\'Unknown phobert model: \\' + flags[\\'phobert_model\\'] + \\'. Allowed: phobert_base and phobert_large\\')\\n\\nif flags[\\'use_xlmr\\'] == True:\\n    if flags[\\'xlmr_model\\'] == \\'xlmr_base\\':\\n        print(\\'Using xlmr_base.\\')\\n        xlmr_model = XLMRobertaModel.from_pretrained(\\'xlm-roberta-base\\')\\n        xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained(\\'xlm-roberta-base\\')\\n\\n    elif flags[\\'xlmr_model\\'] == \\'xlmr_large\\':\\n        print(\\'Using xlmr_large.\\')\\n        xlmr_model = XLMRobertaModel.from_pretrained(\\'xlm-roberta-large\\')\\n        xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained(\\'xlm-roberta-large\\')\\n\\n    else:\\n        assert False, str(\\'Unknown phobert model: \\' + flags[\\'xlmr_model\\'] + \\'. Allowed: xlmr_base and xlmr_large\\')\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"uMsPwfmbCx_v"},"source":["## GPU"]},{"cell_type":"code","metadata":{"id":"Ia9OejTRI52-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dde3620f-9895-4439-bffb-0a369a1acdb3","executionInfo":{"status":"ok","timestamp":1717425165218,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["\n","# GPU\n","# If there's a GPU available...\n","if torch.cuda.is_available():\n","    # Tell PyTorch to use the GPU.\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"markdown","metadata":{"id":"IADdZhElb4D4"},"source":["## Create model input"]},{"cell_type":"markdown","metadata":{"id":"3DVZCoLqGFNh"},"source":["Một điểm cần chú ý:\n","- PhoBERT cần câu input được word tokenize sẵn (dùng VNCoreNLP hoặc Underthesea). Có vẻ là để tạo N-gram\n","- XLMR thì không cần, ta cứ truyền trực tiếp câu thô vào làm input.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Fc2MsmAt4zDF"},"source":["### Get entity's word_tokenize index (PhoBERT need this)"]},{"cell_type":"markdown","metadata":{"id":"OWb98FjG46cV"},"source":["#### Readme"]},{"cell_type":"markdown","metadata":{"id":"YyVtt9BSy2ji"},"source":["Một entity có thể có nhiều từ, và các từ này lại được tokenize thành nhiều word_piece. Nên một entity có thể có rất nhiều vector word_piece. Ta có thể chọn đại diện 1 vector để làm đại diện cho entity, hoặc là pooling các vector word_piece để ra 1 vector đại diện duy nhất cho entity.\n","\n","Để có thể pooling thì ta cần biết các word_piece nào thuộc entity. hay nói cách khác là ta cần lấy được index của các entity word_piece trong danh sách word_piece của cả câu.\n","\n","\n","**Với Phobert**:\n","- Do đầu vào cần là câu được Underthesea nên xảy ra vấn đề là word_tokenize của Underthesea cho ra kết quả không khớp với NER của entity trong dữ liệu. Ví dụ:\n","  + \"Hôm nay, là ngày Quốc Tế Lao Động.\"\n","  + entity: \"Quốc Tế Lao Động\"\n","  + word_tokenize: [\"Hôm nay\", \"là\", \"ngày Quốc Tế\", \"Lao Động\"]\n","  + tức là entity lại word_tokenize ra kết quả không trùng với entity. Nếu mà ra là: [\"Hôm nay\", \"là\", \"ngày\", \"Quốc Tế\", \"Lao Động\"] thì đẹp.\n","  + Trên chỉ là một ví dụ, còn nhiều trường hợp Underthesea ra xấu hơn và phi lý vô cùng khi đọc.\n","  + entity: B C D\n","  + nhưng underthesea có thể ra là: [..., 'A B C D E F', ...], [..., 'A B', 'C', 'D', ...], [..., 'A B', 'C', 'D E F K'], ...\n","- Nhưng tổng quát vấn đề này có các khả năng:\n","  + Đầu entity trùng đầu 1 token. [..., 'B C', 'D E F',...]\n","  + Đầu entity là cuối 1 token:  [..., 'A B C', 'D',...]\n","  \n","  + Cuối entity trùng cuối 1 token. [..., 'A B C', 'D',...]\n","  + Cuối entity là đầu 1 token:  [..., 'B C', 'D E F',...]\n","\n","\n","- Ý tưởng: biến [\"Hôm nay\", \"là\", \"ngày Quốc Tế\", \"Lao Động\"] thành [\"Hôm nay\", \"là\", \"ngày\", \"Quốc Tế\", \"Lao Động\"]. Tức là nếu đầu hay cuối entity bị lẫn, là một phần con trong một token thì ta sẽ cắt token đấy ra. Tức là ta sẽ tạo ra phiên bản word_tokenize mới dựa trên word_tokenize của Underthesea\n","- Nên để lấy index của PhoBERT cần qua 2 bước:\n","  + tạo word_tokenize mới và lấy index token trong entity trong word_tokenize này\n","  + lấy index của word_piece các token trong câu word_tokenize mới.\n","  + entity -> token -> word_piece : index_word_piece -> token <-> index token -> entity\n","- ta bắt buộc phải trải qua 2 bước trên vì ta không thể tách token dựa trên word_piece của phobert được.ta phải tách trước thì word_piece của Phobert mới đẹp theo.\n","\n","\n","Với **XLMR BERT**:\n","- thì mọi thứ đơn giản hơn, ta chỉ việc fed câu gốc vào mà không cần qua Underthesea nên dễ dàng hơn không cần sửa trước như trên.\n","- Nên để lấy index của XLMR thì ta chỉ việc từ index word_piece ra thẳng entity mà thôi."]},{"cell_type":"markdown","metadata":{"id":"hKLlYYYY4-r4"},"source":["#### Func"]},{"cell_type":"code","metadata":{"id":"anngy6FArdp1","executionInfo":{"status":"ok","timestamp":1717425165218,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def my_word_tokenize(word_tokenize_lst, tokens_non_space_pos_lst, split_token_index, split_pos, sentence):\n","\n","    '''\n","    word_tokenize_lst: word_tokenize_lst cần được sửa\n","    tokens_non_space_pos_lst: vị trí pos indice của mọi token trong word_tokenize_lst đối với câu không có space\n","    split_token_index: index của token cần được tách trong word_tokenize_lst\n","    sentence: sentence gốc có space\n","    split_pos: vị trí (NON SPACE) đối với câu (tại vị trí này ta sẽ tách token cần tách thành 2 phần, từ đầu token tới vị trí này,\n","    và từ vị trí này đến hết token)\n","    vị trí này sẽ nằm giữa đầu vs cuối của token)\n","    ..... vitri_dau_token  vitri_tach_token   vitri_cuoi_token ...\n","    '''\n","\n","    new_word_tokenize_lst = []\n","    new_tokens_non_space_pos_lst = []\n","\n","    for itk, tk in enumerate(word_tokenize_lst):\n","\n","        # nếu không phải token cần tách thì cứ thêm vào list word_tokenize mới\n","        if itk != split_token_index:\n","            # in 'else' part below, I create same (duplicate) variable (name) for debugging easier\n","            sent_non_space = ''.join(sentence.split())   # remove all space from original sentence\n","            token_non_space = ''.join(tk.split())  # remove all space from current tk\n","            token_non_space_pos = tokens_non_space_pos_lst[itk]\n","\n","            # assert (sent_non_space[token_non_space_pos[0]:token_non_space_pos[1]] == token_non_space), \\\n","            # str('Token_non_space not match with non_space_pos.')\n","\n","\n","            new_word_tokenize_lst.append(tk)  # tk with space\n","            new_tokens_non_space_pos_lst.append(copy.deepcopy(tokens_non_space_pos_lst[itk]))  # non space pos\n","\n","\n","\n","        else:   # token cần tách\n","            # token: [A B C D] [E F], entity: C D E F\n","            # ...      C D   E F  ...\n","            # ... [A B C D] [E F] ...\n","\n","            #     C D E F\n","            # A B C D E F\n","\n","            #   CDEF\n","            # ABCDEF\n","\n","            token_space = copy.deepcopy(word_tokenize_lst[split_token_index])   # A B C D\n","\n","            sent_non_space = ''.join(sentence.split())   # ...ABCDEF...\n","            token_non_space = ''.join(token_space.split())  # ABCD\n","\n","            token_non_space_pos = tokens_non_space_pos_lst[split_token_index]  # <----- pos trong sent_non_space\n","                                                                               # pos ABCD trong ...ABCDEF...\n","\n","            # just a check\n","            # assert (sent_non_space[token_non_space_pos[0]:token_non_space_pos[1]] == token_non_space), \\\n","            # str('Token non space not match with token non space pos.')\n","\n","\n","            token_head_non_space = sent_non_space[token_non_space_pos[0]:split_pos]   # AB\n","            token_tail_non_space = sent_non_space[split_pos:token_non_space_pos[1]]   # CD\n","\n","            # just check even no necessary: AB+CD = ABCD\n","            # assert ((token_head_non_space + token_tail_non_space) == token_non_space), \\\n","            # str('AB+CD != ABCD')  # -.- so tired\n","\n","\n","            subtoken_lst = token_space.split() # ['A', 'B', 'C', 'D']\n","\n","\n","            num_space_in_token_space = 0\n","            for ctk in token_space:\n","                if ctk.isspace():\n","                    num_space_in_token_space += 1\n","\n","\n","            # 'A B C D'  ->  4 - 1 = 3 space\n","            # Note: Nếu mà không bằng chính tỏ là giữa hai từ đơn trong một token (cụm từ) không chỉ có 1 dấu cách\n","            # lúc này thì có thể tạo ra một list chứ số dấu cách trong token.\n","            # 'A  B C   D'  ->  [2, 1, 3]\n","            # giữa 'A  B' có 2 dấu cách. giữa 'B C' có 1 dấu cách. giữa 'C   D' có 3 cách.\n","            assert (len(subtoken_lst) == (num_space_in_token_space + 1)), \\\n","            str('Seem that underthesea word tokenize does not contain only one space between words')\n","\n","\n","\n","            sub_token_head_lst = []\n","\n","            for subtoken in subtoken_lst:\n","                sub_token_head_lst.append(subtoken)  # iter:  0        1\n","                                                     #        ['A'] -> ['A', 'B']\n","\n","                if ''.join(sub_token_head_lst) == token_head_non_space:    # ''.join['A', 'B'] == 'AB'\n","                    break\n","\n","            # # [A, B] < [A, B, C, D]   (nếu có LỖI tức là k chạy vào break ở vòng for trên thì sub_token_head_lst sẽ giống hệt subtoken_lst)\n","            # assert (len(sub_token_head_lst) < len(subtoken_lst)), str('[A, B] not < [A, B, C, D]')\n","\n","            # [A, B, C, D] - [A, B] = [C, D]\n","            sub_token_tail_lst = subtoken_lst[len(sub_token_head_lst):]   # [C, D]\n","\n","            # # ''.join(['C', 'D']) == 'CD'\n","            # assert (''.join(sub_token_tail_lst) == token_tail_non_space), str(\"''.join(['C', 'D']) != 'CD'\")\n","\n","            # # just anotherrrrr checkkkkkkkkkkkkkkkkkkkkkkkk\n","            # # chỉ đúng nếu giữa các từ trong một token có đúng 1 dấu cách. nếu có nhiều hơn 1 thì phải dùng lst space như NOTE bên trên\n","            # assert (str(' '.join(sub_token_head_lst) + ' ' + ' '.join(sub_token_tail_lst)) == token_space), \\\n","            # str(\"' '.join(['A', 'B']) + ' ' + ' '.join(['C', 'D']) != 'A B C D'\")\n","\n","            # append 'A B'\n","            new_word_tokenize_lst.append(' '.join(sub_token_head_lst))\n","\n","            token_head_non_space_pos_start = token_non_space_pos[0]\n","            token_head_non_space_pos_end = token_head_non_space_pos_start + sum([len(tmp) for tmp in sub_token_head_lst])\n","\n","            # # just check even maybe not necessary\n","            # assert (token_head_non_space_pos_end == split_pos), str('token_head end pos not equal to split pos.')\n","            # assert (sent_non_space[token_head_non_space_pos_start:token_head_non_space_pos_end] == token_head_non_space), \\\n","            # str('token_head_non_space not match with pos found in sent_no_space.')\n","\n","            new_tokens_non_space_pos_lst.append([token_head_non_space_pos_start, token_head_non_space_pos_end])\n","\n","\n","            # append 'C D'\n","            new_word_tokenize_lst.append(' '.join(sub_token_tail_lst))\n","\n","            token_tail_non_space_pos_start = split_pos\n","            token_tail_non_space_pos_end = token_tail_non_space_pos_start + sum([len(tmp) for tmp in sub_token_tail_lst]) # = token_non_space_pos[1]\n","\n","            # # just check even maybe not necessary\n","            # assert (token_tail_non_space_pos_end == token_non_space_pos[1]), str('token_tail end pos not equal to originial token_non_space end pos.')\n","            # assert (sent_non_space[token_tail_non_space_pos_start:token_tail_non_space_pos_end] == token_tail_non_space), \\\n","            # str('token_tail_non_space not match with pos found in sent_no_space.')\n","\n","            new_tokens_non_space_pos_lst.append([token_tail_non_space_pos_start, token_tail_non_space_pos_end])\n","\n","\n","    return new_word_tokenize_lst, new_tokens_non_space_pos_lst\n","\n","\n"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCBFXtDOcytv","executionInfo":{"status":"ok","timestamp":1717425165218,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def get_entity_index_in_underthesea_word_tokenize(sent_id, sentence, word_tokenize_lst, entity):\n","\n","    entity_text = entity['text']\n","    entity_pos = entity['pos']\n","\n","    ##### CHECK\n","\n","    assert (sentence[entity_pos[0]:entity_pos[1]] == entity_text), str('\\nEntity_pos not match entity. Entity: ' + entity + '\\nsent-id: ' + str(sent_id))\n","\n","    assert (type(word_tokenize_lst) is list), str('word_tokenize_lst must be a list. Use Underthesea\\'s word_tokenize with out format=\"text\" option.')\n","\n","    # vì ta sẽ không tính đến dấu cách nên nếu kí tự đầu hoặc cuối entity là khoảng cách thì sẽ có vấn đề\n","    # tức là vì không tính đến khoảng cách nên nếu mà start pos hay end pos của entity là vị trí khoảng trắng thừa thì sẽ không bao giờ match được\n","    # bên trên trong phần clean data đã loại bỏ rồi nhưng cứ check lại cho chắc\n","    if (entity_text[0].isspace()) or (entity_text[-1].isspace()):\n","        assert False, str('\\nFirst or last character in entity is space. Entity: ' + repr(entity) + '\\nsent-id: ' + str(sent_id))\n","        #print(str('\\nFirst or last character in entity is space. Entity: ' + repr(entity) + '\\nsent-id: ' + str(sent_id)))\n","\n","    ##### END CHECK\n","\n","\n","    # đếm khoảng trắng từ đầu câu đến entity start_pos\n","    count_to_estart = 0\n","    for c in sentence[:entity_pos[0]]:\n","        if c.isspace():\n","            count_to_estart += 1\n","    new_estart_pos = entity_pos[0] - count_to_estart\n","\n","    # đếm khoảng trắng từ đầu câu đến entity end_pos\n","    count_to_eend = 0\n","    for c in sentence[:entity_pos[1]]:\n","        if c.isspace():\n","            count_to_eend += 1\n","    new_eend_pos = entity_pos[1] - count_to_eend\n","\n","    # đếm khoảng trắng trong entity\n","    '''\n","    count_in_e = 0\n","    for i in entity:\n","        if i.isspace():\n","            count_in_e += 1\n","    '''\n","\n","    sent_no_space = ''.join(sentence.split())\n","    entity_text_no_space = ''.join(entity_text.split())\n","\n","    assert (sent_no_space[new_estart_pos:new_eend_pos] == entity_text_no_space), \\\n","    str('\\nEntity_text without space not match entity_pos without space. ' + sent_no_space + ' ' + entity_text_no_space)\n","\n","    #\n","    pre_tkend_pos = 0\n","\n","    found_start = False\n","    found_end = False\n","\n","    start_index = None\n","    end_index = None\n","\n","\n","    sent_non_space = ''.join(sentence.split())   # <----- câu không có khoảng trắng\n","\n","    tokens_non_space_pos_lst = []   # <----- pos token không khoảng trắng trong câu không có khoảng trắng\n","\n","\n","    for itk, tk in enumerate(word_tokenize_lst):\n","        # tìm pos của từng token trong câu segment\n","        tkstart_pos = pre_tkend_pos   # do không tính khoảng trắng nên end của 1 token sẽ là start của token ngay sau nó (nếu có)\n","        tkend_pos = tkstart_pos + sum([len(tmp) for tmp in tk.split()])\n","\n","        token_non_space = ''.join(tk.split())\n","\n","        # assert (sent_non_space[tkstart_pos:tkend_pos] == token_non_space), \\\n","        # str('Token non space not match with token non space pos.')\n","\n","\n","        tokens_non_space_pos_lst.append([tkstart_pos, tkend_pos])\n","\n","        # cập nhật pre_tkend_pos\n","        pre_tkend_pos = tkend_pos\n","\n","\n","        if tkstart_pos == new_estart_pos:\n","            found_start = True\n","            start_index = copy.deepcopy(itk)\n","\n","        if tkend_pos == new_eend_pos:\n","            found_end = True\n","            end_index = copy.deepcopy(itk)\n","\n","        #  token này sẽ phải chứa đoạn đầu của entity\n","        #  ví dụ:\n","        #  token: ... trưởng_phòng Cảnh_sát   ...\n","        # entity:     ...    phòng Cảnh sát   ...\n","        if (tkstart_pos < new_estart_pos) and (new_estart_pos < tkend_pos):\n","            start_index = copy.deepcopy(itk)    # <----- có start_index nhưng found_start vẫn là false\n","\n","\n","        #  token này sẽ phải chứa đoạn đầu của entity\n","        #  ví dụ:\n","        #  token: ... Nguyễn_Hiền_đỗ ...   <-----   lỗi có thật khi dùng underthesea word_tokenize\n","        # entity: ... Nguyễn Hiền    ...\n","        if (tkstart_pos < new_eend_pos) and (new_eend_pos < tkend_pos):\n","            end_index = copy.deepcopy(itk)    # <----- có end_index nhưng found_end vẫn là false\n","\n","\n","    entity_eids_lst = []\n","    new_word_tokenize_lst = []\n","    new_tokens_non_space_pos_lst = []\n","\n","    if (found_start == True):\n","        new_word_tokenize_lst = copy.deepcopy(word_tokenize_lst)\n","        new_tokens_non_space_pos_lst = copy.deepcopy(tokens_non_space_pos_lst)\n","\n","    if found_start == False:\n","\n","        # ta sẽ cắt token chứa phần đầu entity ra thành 2 token\n","        #  token: ... [trưởng phòng] [Cảnh sát]   ...\n","        # entity:     ...     phòng Cảnh sát   ...\n","        #  token: ... [trưởng] [phòng] [Cảnh sát]   ...\n","        # entity:     ...       phòng Cảnh sát   ...\n","\n","\n","        # Vì found_start = False nên phần đầu entity (một từ hoặc một vài từ đầu trong entity) sẽ nằm trong token tại vị trí start_index\n","        # và phần đầu entity sẽ là phần cuối token này. và phần đầu token này (một, hay vài từ khác) sẽ phải được ngăn cách với\n","        # phần đầu entity bằng dấu cách.\n","        #  token:     |          |\n","        #  token: ... trưởng phòng Cảnh sát   ...\n","        # entity:     ...    phòng Cảnh sát   ...\n","        #             |    | |   |\n","        # nếu mà không có dấu cách trong token nghĩa là kiểu lỗi: token (phòng) entity (òng Cảng Sát)\n","\n","        token_space = word_tokenize_lst[start_index]\n","\n","        num_space_in_token_space = 0\n","        for ctk in token_space:\n","            if ctk.isspace():\n","                num_space_in_token_space += 1\n","\n","        assert (num_space_in_token_space > 0), \\\n","        str('Found start FALSE. Token at start_index does not has space. token: ' + word_tokenize_lst[start_index] + ' entity: ' + entity_text)\n","\n","        new_word_tokenize_lst, new_tokens_non_space_pos_lst = \\\n","        my_word_tokenize(word_tokenize_lst, tokens_non_space_pos_lst, start_index, new_estart_pos, sentence)\n","\n","        # old_start_index: osi\n","        #      osi      osi+1\n","        # ... [A B C D] [E F]\n","\n","        # sau khi tách:\n","        #      osi  osi+1 osi+2\n","        # ... [A B] [C D] [E F]\n","\n","        start_index = start_index + 1  # osi + 1\n","        end_index = end_index + 1\n","\n","\n","\n","    if found_end == True:\n","        # no need run two below commented line because we dont change anything\n","        # new_word_tokenize_lst = copy.deepcopy(new_word_tokenize_lst)\n","        # new_tokens_non_space_pos_lst = copy.deepcopy(new_tokens_non_space_pos_lst)\n","\n","        entity_eids_lst = list(range(start_index, (end_index+1)))\n","\n","\n","    if found_end == False:\n","\n","        new_word_tokenize_lst, new_tokens_non_space_pos_lst = \\\n","        my_word_tokenize(copy.deepcopy(new_word_tokenize_lst), copy.deepcopy(new_tokens_non_space_pos_lst), end_index, new_eend_pos, sentence)\n","\n","        entity_eids_lst = list(range(start_index, (end_index+1)))\n","\n","\n","\n","    entity_text_no_space = ''.join(entity_text.split()) # <- tren co roi nhung ke cu tao lai cho de theo doi\n","    entity_subtoken_lst = new_word_tokenize_lst[entity_eids_lst[0]:(entity_eids_lst[-1]+1)]\n","\n","    entity_singleword_lst = []\n","    for entity_subtoken in entity_subtoken_lst:\n","        entity_singleword_lst.extend(entity_subtoken.split())\n","\n","    # assert (entity_text_no_space == ''.join(entity_singleword_lst)), \\\n","    # str('FOUND ENTITY INDEX NOT MATCH WITH ENTITY TEXT')\n","\n","    '''\n","    # k check cai nay. vi split co the khac do co dau cau nhu / hay ,\n","    # DOUBLE CHECKKKKKKKKKK\n","    assert (entity_singleword_lst == entity_text.split()), \\\n","    str('FOUND ENTITY INDEX NOT MATCH WITH ENTITY TEXT')\n","    '''\n","\n","    # assert (sent_non_space == ''.join([itm.replace(' ', '') for itm in new_word_tokenize_lst])), \\\n","    # str('sent_non_space not match new_word_tokenize_lst')\n","\n","    # assert (new_tokens_non_space_pos_lst[entity_eids_lst[0]][0] == new_estart_pos) \\\n","    # and (new_tokens_non_space_pos_lst[entity_eids_lst[-1]][1] == new_eend_pos), \\\n","    # str('TWO ENITY NON SPACE POS NOT MATCH.')\n","\n","    entity_pos_no_space = [new_estart_pos, new_eend_pos]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    return new_word_tokenize_lst, entity_eids_lst, entity_pos_no_space\n","\n","\n","\n","\n","\n"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2CuCMaFHwNuV"},"source":["#### Add entity index and word_tokenize to data"]},{"cell_type":"code","metadata":{"id":"G6LFPE13ceDo","executionInfo":{"status":"ok","timestamp":1717425165219,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# def add_word_tokenize_and_entity_index(jdata, train_or_dev, print_output='True'):\n","\n","#     new_jdata = []\n","\n","#     for sentif in jdata:\n","\n","#         word_tokenize_lst = word_tokenize(sentif['new_sentence'])\n","\n","#         # Có duy nhất 1 câu trong tập train, chứa token bên dưới, tức là có 1 trường hợp duy nhất mà 2 từ trong 1 token nối với nhau bằng - thay vì khoảng trắng\n","#         # và 'Tập' là một từ trong entity\n","#         # có thể code để chạy được cho trường hợp dấu - này, tuy nhiên, chỉ có 1 câu duy nhất bị. và còn chưa biết các khả năng có thể xảy khi từ\n","#         # được ngăn bởi dấu - thay vì khoảng trắng. nhỡ một phần entity lại là ẹ-Tập thay vì Tập thì sao\n","#         # nên để hiểu rõ hơn về dữ liệu chỉ sửa tạm như dưới, có nhiều hơn 1 thì mới tính đến thêm vào func bên trên\n","#         # bên dưới ta tạo word_tokenize_lst mới bằng tay để code trong func không lỗi\n","#         if ('mẹ-Tập' in word_tokenize_lst) and (train_or_dev == 'train'):\n","#             specia_index = word_tokenize_lst.index('mẹ-Tập')\n","#             word_tokenize_lst.insert((specia_index+1), 'Tập')\n","#             word_tokenize_lst[specia_index] = 'mẹ-'\n","\n","\n","\n","#         new_word_tokenize_lst_1, entity_1_eids_lst, entity_1_pos_no_space = \\\n","#         get_entity_index_in_underthesea_word_tokenize(sentif['sent_id'], sentif['new_sentence'], word_tokenize_lst, sentif['new_entity_1'])\n","\n","#         new_word_tokenize_lst_2, entity_2_eids_lst, entity_2_pos_no_space = \\\n","#         get_entity_index_in_underthesea_word_tokenize(sentif['sent_id'], sentif['new_sentence'], copy.deepcopy(new_word_tokenize_lst_1), sentif['new_entity_2'])\n","\n","\n","#         ######## HOT FIX\n","#         # trong câu có sent_id là 1216 , có cụm từ 'CĐ Sư phạm Mỹ thuật'\n","#         # trong new_word_tokenize_lst_2 thì sẽ là: 'CĐ Sư phạm', 'Mỹ thuật'\n","#         # có vẻ ổn, nhìn vào thì thấy k có vấn đề gì nhưng khi fed vào phobert thì CĐ_Sư_phạm phobert word piece thành 'CĐ', '_S', 'ư_phạm'\n","#         # dẫn tới việc 'ư_phạm' k có trong vocab và bị thành <UNK> và k tìm được index word piece cho entity này\n","#         # nên ta cần sửa lại trong new_word_tokenize_lst_2, biến 'CĐ Sư phạm' thành 'CĐ', 'Sư phạm' thì k bị lỗi nữa\n","#         # và cũng cần đổi entity wtk_index.\n","#         # chỉ duy nhất 1 câu bị lỗi này trong tập train nên ta chỉ cần tách thủ công\n","\n","#         if (sentif['sent_id'] in list(range(4466, 4481))) and (train_or_dev == 'test'):\n","#             nfix_tk_id = new_word_tokenize_lst_2.index('Bành Sơn')\n","\n","#             new_word_tokenize_lst_2.insert((nfix_tk_id+1), unicodedata.normalize(\"NFC\", 'Sơn'))\n","#             new_word_tokenize_lst_2[nfix_tk_id] = copy.deepcopy(unicodedata.normalize(\"NFC\", 'Bành'))\n","\n","#             # chi co entity_2_eids_lst bi anh huong boi viec tach tren\n","#             entity_2_eids_lst.append(entity_2_eids_lst[-1] + 1)\n","\n","#         if (sentif['sent_id'] in list(range(4635, 4650))) and (train_or_dev == 'test'):\n","#             nfix_tk_id = new_word_tokenize_lst_2.index('Ma túy')\n","\n","#             new_word_tokenize_lst_2.insert((nfix_tk_id+1), unicodedata.normalize(\"NFC\", 'túy'))\n","#             new_word_tokenize_lst_2[nfix_tk_id] = copy.deepcopy(unicodedata.normalize(\"NFC\", 'Ma'))\n","\n","#             # chi co entity_2_eids_lst bi anh huong boi viec tach tren\n","#             entity_2_eids_lst.append(entity_2_eids_lst[-1] + 1)\n","\n","#         ########\n","\n","\n","\n","#         new_sentif = copy.deepcopy(sentif)\n","\n","#         # from underthesea: https://github.com/undertheseanlp/underthesea/blob/master/underthesea/word_tokenize/__init__.py#L45\n","#         # new_sentif['word_tokenize_sentence'] = copy.deepcopy(u\" \".join([item.replace(\" \", \"_\") for item in new_word_tokenize_lst_2]))\n","#         new_sentif['word_tokenize_lst'] = copy.deepcopy(new_word_tokenize_lst_2)\n","\n","#         new_sentif['new_entity_1']['wtk_index_lst'] = copy.deepcopy(entity_1_eids_lst)\n","#         new_sentif['new_entity_2']['wtk_index_lst'] = copy.deepcopy(entity_2_eids_lst)\n","\n","#         new_sentif['new_entity_1']['pos_no_space'] = copy.deepcopy(entity_1_pos_no_space)\n","#         new_sentif['new_entity_2']['pos_no_space'] = copy.deepcopy(entity_2_pos_no_space)\n","\n","\n","#         new_jdata.append(copy.deepcopy(new_sentif))\n","\n","#         # phần cũ vẫn phải y nguyên. bên trên chỉ thêm 'word_tokenize_sentence', và thêm 'wtk_index_lst' vào 'new_entity_1' và 'new_entity_2'\n","#         assert (new_jdata[-1]['sent_id'] == sentif['sent_id']), str('FAILED TO COPY sent_id. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['doc_id'] == sentif['doc_id']), str('FAILED TO COPY doc_id. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['sentence'] == sentif['sentence']), str('FAILED TO COPY sentence. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['entity_1'] == sentif['entity_1']), str('FAILED TO COPY entity_1. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['entity_2'] == sentif['entity_2']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['label'] == sentif['label']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['spos'] == sentif['spos']), str('FAILED TO COPY spos. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['new_sentence'] == sentif['new_sentence']), str('FAILED TO COPY new_sentence. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['new_entity_1']['text'] == sentif['new_entity_1']['text']), str('FAILED TO COPY new_entity_1 text. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['new_entity_2']['text'] == sentif['new_entity_2']['text']), str('FAILED TO COPY new_entity_2 text. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['new_entity_1']['pos'] == sentif['new_entity_1']['pos']), str('FAILED TO COPY new_entity_1 pos. sent_id: ' + sentif['sent_id'])\n","#         assert (new_jdata[-1]['new_entity_2']['pos'] == sentif['new_entity_2']['pos']), str('FAILED TO COPY new_entity_2 pos. sent_id: ' + sentif['sent_id'])\n","\n","\n","#         assert (new_jdata[-1]['new_entity_1']['wtk_index_lst'] == entity_1_eids_lst), str('Fail to copy or add entity_1_eids_lst')\n","#         assert (new_jdata[-1]['new_entity_2']['wtk_index_lst'] == entity_2_eids_lst), str('Fail to copy or add entity_2_eids_lst')\n","\n","#         if print_output == True:\n","#             if (new_word_tokenize_lst_1 != word_tokenize_lst) or (new_word_tokenize_lst_2 != word_tokenize_lst):\n","\n","#                 print('\\n\\n---------- sent_id: ', sentif['sent_id'])\n","#                 print('sentence: ', sentif['sentence'])\n","\n","#                 if (new_word_tokenize_lst_1 != word_tokenize_lst):\n","#                     print('\\nentity: ', sentif['new_entity_1'])\n","#                     print('entity index list: ', entity_1_eids_lst)\n","#                     print(new_word_tokenize_lst_1[entity_1_eids_lst[0]:(entity_1_eids_lst[-1]+1)])\n","#                     print(entity_1_pos_no_space)\n","#                     print('Underthesea word_tokenize: ', word_tokenize_lst)\n","#                     print('My word_tokenize 1:        ', new_word_tokenize_lst_1)\n","\n","#                 if (new_word_tokenize_lst_2 != new_word_tokenize_lst_1):\n","#                     print('\\nentity: ', sentif['new_entity_2'])\n","#                     print('entity index list: ', entity_2_eids_lst)\n","#                     print(entity_2_pos_no_space)\n","#                     print(new_word_tokenize_lst_2[entity_2_eids_lst[0]:(entity_2_eids_lst[-1]+1)])\n","#                     print('My word_tokenize 1:        ', new_word_tokenize_lst_1)\n","#                     print('My word_tokenize 2:        ', new_word_tokenize_lst_2)\n","\n","\n","\n","\n","\n","#     print('Done adding new_word_tokenize_lst and entity eids in new_word_tokenize_lst to jdata.')\n","\n","#     return new_jdata\n"],"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def add_word_tokenize_and_entity_index(jdata, train_or_dev, print_output='True'):\n","\n","    new_jdata = []\n","\n","    for sentif in jdata:\n","\n","        word_tokenize_lst = word_tokenize(sentif['new_sentence'])\n","\n","        # Có duy nhất 1 câu trong tập train, chứa token bên dưới, tức là có 1 trường hợp duy nhất mà 2 từ trong 1 token nối với nhau bằng - thay vì khoảng trắng\n","        # và 'Tập' là một từ trong entity\n","        # có thể code để chạy được cho trường hợp dấu - này, tuy nhiên, chỉ có 1 câu duy nhất bị. và còn chưa biết các khả năng có thể xảy khi từ\n","        # được ngăn bởi dấu - thay vì khoảng trắng. nhỡ một phần entity lại là ẹ-Tập thay vì Tập thì sao\n","        # nên để hiểu rõ hơn về dữ liệu chỉ sửa tạm như dưới, có nhiều hơn 1 thì mới tính đến thêm vào func bên trên\n","        # bên dưới ta tạo word_tokenize_lst mới bằng tay để code trong func không lỗi\n","        if ('mẹ-Tập' in word_tokenize_lst) and (train_or_dev == 'train'):\n","            specia_index = word_tokenize_lst.index('mẹ-Tập')\n","            word_tokenize_lst.insert((specia_index+1), 'Tập')\n","            word_tokenize_lst[specia_index] = 'mẹ-'\n","\n","\n","\n","        new_word_tokenize_lst_1, entity_1_eids_lst, entity_1_pos_no_space = \\\n","        get_entity_index_in_underthesea_word_tokenize(sentif['sent_id'], sentif['new_sentence'], word_tokenize_lst, sentif['new_entity_1'])\n","\n","        new_word_tokenize_lst_2, entity_2_eids_lst, entity_2_pos_no_space = \\\n","        get_entity_index_in_underthesea_word_tokenize(sentif['sent_id'], sentif['new_sentence'], copy.deepcopy(new_word_tokenize_lst_1), sentif['new_entity_2'])\n","\n","\n","        ######## HOT FIX\n","        # trong câu có sent_id là 1216 , có cụm từ 'CĐ Sư phạm Mỹ thuật'\n","        # trong new_word_tokenize_lst_2 thì sẽ là: 'CĐ Sư phạm', 'Mỹ thuật'\n","        # có vẻ ổn, nhìn vào thì thấy k có vấn đề gì nhưng khi fed vào phobert thì CĐ_Sư_phạm phobert word piece thành 'CĐ', '_S', 'ư_phạm'\n","        # dẫn tới việc 'ư_phạm' k có trong vocab và bị thành <UNK> và k tìm được index word piece cho entity này\n","        # nên ta cần sửa lại trong new_word_tokenize_lst_2, biến 'CĐ Sư phạm' thành 'CĐ', 'Sư phạm' thì k bị lỗi nữa\n","        # và cũng cần đổi entity wtk_index.\n","        # chỉ duy nhất 1 câu bị lỗi này trong tập train nên ta chỉ cần tách thủ công\n","\n","        # if (sentif['sent_id'] == 1216) and (train_or_dev == 'train'):\n","        #     nfix_tk_id = new_word_tokenize_lst_2.index('CĐ Sư phạm')\n","\n","        #     new_word_tokenize_lst_2.insert((nfix_tk_id+1), unicodedata.normalize(\"NFC\", 'Sư phạm'))\n","        #     new_word_tokenize_lst_2[nfix_tk_id] = copy.deepcopy(unicodedata.normalize(\"NFC\", 'CĐ'))\n","\n","        #     # chi co entity_2_eids_lst bi anh huong boi viec tach tren\n","        #     entity_2_eids_lst.append(entity_2_eids_lst[-1] + 1)\n","\n","        ########\n","\n","\n","\n","        new_sentif = copy.deepcopy(sentif)\n","\n","        # from underthesea: https://github.com/undertheseanlp/underthesea/blob/master/underthesea/word_tokenize/__init__.py#L45\n","        # new_sentif['word_tokenize_sentence'] = copy.deepcopy(u\" \".join([item.replace(\" \", \"_\") for item in new_word_tokenize_lst_2]))\n","        new_sentif['word_tokenize_lst'] = copy.deepcopy(new_word_tokenize_lst_2)\n","\n","        new_sentif['new_entity_1']['wtk_index_lst'] = copy.deepcopy(entity_1_eids_lst)\n","        new_sentif['new_entity_2']['wtk_index_lst'] = copy.deepcopy(entity_2_eids_lst)\n","\n","        new_sentif['new_entity_1']['pos_no_space'] = copy.deepcopy(entity_1_pos_no_space)\n","        new_sentif['new_entity_2']['pos_no_space'] = copy.deepcopy(entity_2_pos_no_space)\n","\n","\n","        new_jdata.append(copy.deepcopy(new_sentif))\n","\n","        # phần cũ vẫn phải y nguyên. bên trên chỉ thêm 'word_tokenize_sentence', và thêm 'wtk_index_lst' vào 'new_entity_1' và 'new_entity_2'\n","        assert (new_jdata[-1]['sent_id'] == sentif['sent_id']), str('FAILED TO COPY sent_id. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['doc_id'] == sentif['doc_id']), str('FAILED TO COPY doc_id. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['sentence'] == sentif['sentence']), str('FAILED TO COPY sentence. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['entity_1'] == sentif['entity_1']), str('FAILED TO COPY entity_1. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['entity_2'] == sentif['entity_2']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['label'] == sentif['label']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['spos'] == sentif['spos']), str('FAILED TO COPY spos. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['new_sentence'] == sentif['new_sentence']), str('FAILED TO COPY new_sentence. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['new_entity_1']['text'] == sentif['new_entity_1']['text']), str('FAILED TO COPY new_entity_1 text. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['new_entity_2']['text'] == sentif['new_entity_2']['text']), str('FAILED TO COPY new_entity_2 text. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['new_entity_1']['pos'] == sentif['new_entity_1']['pos']), str('FAILED TO COPY new_entity_1 pos. sent_id: ' + sentif['sent_id'])\n","        assert (new_jdata[-1]['new_entity_2']['pos'] == sentif['new_entity_2']['pos']), str('FAILED TO COPY new_entity_2 pos. sent_id: ' + sentif['sent_id'])\n","\n","\n","        assert (new_jdata[-1]['new_entity_1']['wtk_index_lst'] == entity_1_eids_lst), str('Fail to copy or add entity_1_eids_lst')\n","        assert (new_jdata[-1]['new_entity_2']['wtk_index_lst'] == entity_2_eids_lst), str('Fail to copy or add entity_2_eids_lst')\n","\n","        if print_output == True:\n","            if (new_word_tokenize_lst_1 != word_tokenize_lst) or (new_word_tokenize_lst_2 != word_tokenize_lst):\n","\n","                print('\\n\\n---------- sent_id: ', sentif['sent_id'])\n","                print('sentence: ', sentif['sentence'])\n","\n","                if (new_word_tokenize_lst_1 != word_tokenize_lst):\n","                    print('\\nentity: ', sentif['new_entity_1'])\n","                    print('entity index list: ', entity_1_eids_lst)\n","                    print(new_word_tokenize_lst_1[entity_1_eids_lst[0]:(entity_1_eids_lst[-1]+1)])\n","                    print(entity_1_pos_no_space)\n","                    print('Underthesea word_tokenize: ', word_tokenize_lst)\n","                    print('My word_tokenize 1:        ', new_word_tokenize_lst_1)\n","\n","                if (new_word_tokenize_lst_2 != new_word_tokenize_lst_1):\n","                    print('\\nentity: ', sentif['new_entity_2'])\n","                    print('entity index list: ', entity_2_eids_lst)\n","                    print(entity_2_pos_no_space)\n","                    print(new_word_tokenize_lst_2[entity_2_eids_lst[0]:(entity_2_eids_lst[-1]+1)])\n","                    print('My word_tokenize 1:        ', new_word_tokenize_lst_1)\n","                    print('My word_tokenize 2:        ', new_word_tokenize_lst_2)\n","\n","\n","\n","\n","\n","    print('Done adding new_word_tokenize_lst and entity eids in new_word_tokenize_lst to jdata.')\n","\n","    return new_jdata\n"],"metadata":{"id":"HpW66Sdygd4v","executionInfo":{"status":"ok","timestamp":1717425165219,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pQSd9DT2nAR"},"source":["### Get entity's wordpice index"]},{"cell_type":"code","metadata":{"id":"MRwH8NmK2tRp","executionInfo":{"status":"ok","timestamp":1717425165219,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def get_entity_word_piece_index(sent_id, bert_tokenize_lst, entity, sentence, model_name, input_ids, train_or_dev):\n","\n","    '''\n","    bert_tokenize_lst là list thu đuọc từ tokenizer.tokenize(sentence)\n","    tức là chưa có special_token. nên start, end index sẽ phải +1 vì sau này khi encode sẽ có thêm 1 special token ở đầu\n","\n","    '''\n","\n","    entity_pos_no_space = entity['pos_no_space']\n","\n","    sent_non_space = ''.join(sentence.split())\n","\n","    found_start, found_end = None, None\n","    start_index, end_index = None, None\n","\n","    pre_wpiend_pos = 0\n","\n","    # có 1 vài câu có là kí tự bắt đầu câu, nhưng xlmr tokenize sẽ bỏ nó đi, k coi n là 1 token\n","    # nên token đầu tiên trong xlmr tokenize là từ thứ 2 trong câu và bắt đầu từ pos là 1.\n","    # phobert k bỏ cái này nên k cần sửa\n","    if ('\\ufeff' in sent_non_space) and (model_name == 'xlmr_base') and (train_or_dev == 'test'):\n","        assert ('\\ufeff' == sent_non_space[0]), str('\\\\ufeff in sentence but not the first character of sentence.')\n","\n","        pre_wpiend_pos = 1\n","\n","    if ('\\ufeff' in sent_non_space) and (model_name == 'xlmr_large') and (train_or_dev == 'test'):\n","        assert ('\\ufeff' == sent_non_space[0]), str('\\\\ufeff in sentence but not the first character of sentence.')\n","\n","        pre_wpiend_pos = 1\n","\n","\n","    if ('\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b' in sent_non_space) and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n","        assert (sent_non_space.count('\\u200b') == 7), str('sent_non_space count \\\\u200b not equal 7.')\n","\n","        pre_wpiend_pos = 7\n","\n","    if ('\\ufeff' in sent_non_space) and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n","        assert ('\\ufeff' == sent_non_space[0]), str('\\\\ufeff in sentence but not the first character of sentence.')\n","\n","        pre_wpiend_pos = 1\n","\n","\n","    for iwpi, wpi in enumerate(bert_tokenize_lst):\n","\n","        assert ((' ' not in wpi) and ('\\xa0' not in wpi)), str(' there is space in word piece.')\n","\n","        # phobert\n","        clean_wpi = wpi.replace('_', '')\n","        clean_wpi = clean_wpi.replace('@@', '')\n","        # xlmr\n","        clean_wpi = clean_wpi.replace('▁', '')\n","\n","        wpi_start_pos = copy.deepcopy(pre_wpiend_pos)\n","        wpi_end_pos = wpi_start_pos + len(clean_wpi)\n","\n","        pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n","\n","        #assert (sent_non_space[wpi_start_pos:wpi_end_pos] == clean_wpi), str('Word_piece not match with non space pos.')\n","\n","        if sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi:\n","\n","            # xlmr biến … thành ... khi tokenize nên cần sửa lại wpi_start_pos, wpi_end_pos\n","            # và với cái wpi này thì chấp nhận sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi\n","            # tương tự với ½ thành 1⁄2\n","            if (clean_wpi == '...') and (sent_non_space[wpi_start_pos] == '…') and (model_name == 'xlmr_base') and (train_or_dev == 'test'):\n","                wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n","                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n","\n","            elif (clean_wpi == '...') and (sent_non_space[wpi_start_pos] == '…') and (model_name == 'xlmr_large') and (train_or_dev == 'test'):\n","                wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n","                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n","\n","            elif (clean_wpi == '1⁄2') and (sent_non_space[wpi_start_pos] == '½') and (model_name == 'xlmr') and (train_or_dev == 'train'):\n","                wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n","                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n","\n","            # trường hợp bên dưới thì chỉ đơn giản là so sánh thì k giống nhau nhưng pos k đổi nên k k cần làm gì hết\n","            elif (clean_wpi == '2') and (sent_non_space[wpi_start_pos] == '²') and (model_name == 'xlmr') and (train_or_dev == 'train'):\n","                #wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n","                #pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n","                pass\n","\n","\n","            elif (clean_wpi == '...') and (sent_non_space[wpi_start_pos] == '…') and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n","                wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n","                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n","\n","            elif (clean_wpi == 'một') and (sent_non_space[wpi_start_pos] == '\\u200b') and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n","                wpi_start_pos = copy.deepcopy(wpi_start_pos + 1)\n","                wpi_end_pos = copy.deepcopy(wpi_start_pos + len(clean_wpi))\n","                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n","\n","                assert (sent_non_space[wpi_start_pos:wpi_end_pos] == clean_wpi), str('AFTER FIX: Word_piece not match with non space pos.')\n","\n","\n","\n","            else:\n","                print('-----sent_id: ', str(sent_id))\n","                print('sentence:       ', repr(sentence))\n","                print('sent_non_space: ', repr(sent_non_space))\n","                print('cut from sent_non_space: ', repr(sent_non_space[wpi_start_pos:wpi_end_pos]))\n","                print('wpi: ', repr(wpi))\n","                print('clean_wpi: ', repr(clean_wpi))\n","                print('wpi_start_pos: ', wpi_start_pos)\n","                print('wpi_end_pos: ', wpi_end_pos)\n","                print(bert_tokenize_lst)\n","\n","                # assert False, str('Word_piece not match with non space pos.')\n","\n","\n","\n","\n","        if wpi_start_pos == entity_pos_no_space[0]:\n","            start_index = iwpi\n","            found_start = True\n","\n","        if wpi_end_pos == entity_pos_no_space[1]:\n","            end_index = iwpi\n","            found_end = True\n","            break # k duoc xoa break, vi trong xlmr co truong hop wpi la '▁' ngay sau entity nen bi lan vao entity\n","\n","\n","    # check\n","    #assert ((found_start == True) and (found_end == True)), str('No word piece non space pos match with entity non space pos.')\n","\n","    found_entity_text = ''.join(bert_tokenize_lst[start_index:(end_index+1)])\n","    found_entity_text = found_entity_text.replace('_', '')\n","    found_entity_text = found_entity_text.replace('@@', '')\n","    found_entity_text = found_entity_text.replace('▁', '')\n","\n","\n","    entity_text_no_space = ''.join(entity['text'].split())\n","\n","    #assert (found_entity_text == entity_text_no_space), str('found entity text not match entity text.' + found_entity_text + ' ' + entity_text_no_space)\n","\n","    # start_index, end_index đều được tăng lên 1 vì sau này sẽ có thêm 1 special token ở đầu input_ids\n","    if start_index is None:\n","      start_index = 0\n","    if end_index is None:\n","      end_index = 0\n","    entity_wpi_ids_lst = list(range((start_index+1), (end_index+2)))\n","\n","\n","    tmp_ent_txt = ''\n","\n","    for entity_wpi_id in entity_wpi_ids_lst:\n","        if model_name == 'phobert_base':\n","            tmp_ent_txt += pb_base_tokenizer.decode([input_ids[entity_wpi_id]])\n","        elif model_name == 'xlmr_base':\n","            tmp_ent_txt += xlmr_base_tokenizer.decode([input_ids[entity_wpi_id]])\n","\n","        elif model_name == 'phobert_large':\n","            tmp_ent_txt += pb_large_tokenizer.decode([input_ids[entity_wpi_id]])\n","        elif model_name == 'xlmr_large':\n","            tmp_ent_txt += xlmr_large_tokenizer.decode([input_ids[entity_wpi_id]])\n","\n","        else:\n","            assert False, str('Unknown model_name. Alow: phobert, xlmr')\n","\n","    tmp_ent_txt = tmp_ent_txt.replace(' ', '')\n","    tmp_ent_txt = tmp_ent_txt.replace('_', '')\n","    tmp_ent_txt = tmp_ent_txt.replace('@@', '')\n","    tmp_ent_txt = tmp_ent_txt.replace('▁', '')\n","\n","    #assert (tmp_ent_txt == entity_text_no_space), str('entity text decode not match entity text. ' + str(sent_id) + ' ' + tmp_ent_txt + ' ' + entity_text_no_space)\n","\n","\n","    return entity_wpi_ids_lst\n"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EAeHqITIgWdI"},"source":["### Encode label"]},{"cell_type":"code","metadata":{"id":"vspAwSYXgeuB","executionInfo":{"status":"ok","timestamp":1717425165219,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def encode_label(sentence_label):\n","    label = -1\n","    if sentence_label == \"LOCATED\":\n","        label = 0\n","    elif sentence_label == \"PART_WHOLE\":\n","        label = 1\n","    elif sentence_label == \"PERSONAL_SOCIAL\":\n","        label = 2\n","    elif sentence_label == \"AFFILIATION\":\n","        label = 3\n","    elif sentence_label == \"IS_LOCATED\":\n","        label = 4\n","    elif sentence_label == \"WHOLE_PART\":\n","        label = 5\n","    elif sentence_label == \"AFFILIATION_TO\":\n","        label = 6\n","    elif sentence_label == \"OTHERS\":\n","        label = 7\n","    else:\n","        assert False, \"UNKNOWN LABEL\"\n","\n","    return label\n"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nFiNJVV5DTf"},"source":["### test"]},{"cell_type":"markdown","metadata":{"id":"-0Pwkh5W6wZ4"},"source":["##### Add entity index and word_tokenize to traindata"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Howkrjf35HV5","outputId":"0fb1d7e4-c43a-47b1-83bf-55b275179ecc","executionInfo":{"status":"ok","timestamp":1717425207272,"user_tz":-420,"elapsed":42058,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# sẽ in ra việc những câu mà underthesea word_tokenize bị thay đổi cho đúng với entity_text\n","jdev_data_v3 = copy.deepcopy(add_word_tokenize_and_entity_index(jtest_data_v2, 'test', print_output=False))"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Done adding new_word_tokenize_lst and entity eids in new_word_tokenize_lst to jdata.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDOao2awGe9L","outputId":"30304e7b-b88e-4147-eb2f-c4beb57727b7","executionInfo":{"status":"ok","timestamp":1717425207272,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["print(*jdev_data_v3[0:20], sep='\\n')"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["{'doc_id': '23351996', 'sent_id': 1, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12], 'wtk_index_lst': [0, 1], 'pos_no_space': [0, 10]}, 'new_entity_2': {'text': 'Mông Cổ', 'pos': [36, 43], 'wtk_index_lst': [9], 'pos_no_space': [28, 34]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 2, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12], 'wtk_index_lst': [0, 1], 'pos_no_space': [0, 10]}, 'new_entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81], 'wtk_index_lst': [15, 16], 'pos_no_space': [54, 64]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 3, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12], 'wtk_index_lst': [0, 1], 'pos_no_space': [0, 10]}, 'new_entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125], 'wtk_index_lst': [22, 23], 'pos_no_space': [89, 98]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 4, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'Mông Cổ', 'pos': [36, 43], 'wtk_index_lst': [9], 'pos_no_space': [28, 34]}, 'new_entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81], 'wtk_index_lst': [15, 16], 'pos_no_space': [54, 64]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 5, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'Mông Cổ', 'pos': [36, 43], 'wtk_index_lst': [9], 'pos_no_space': [28, 34]}, 'new_entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125], 'wtk_index_lst': [22, 23], 'pos_no_space': [89, 98]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 6, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [69, 81], 'wtk_index_lst': [15, 16], 'pos_no_space': [54, 64]}, 'new_entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125], 'wtk_index_lst': [22, 23], 'pos_no_space': [89, 98]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 7, 'sentence': 'Như vậy tại bảng I vòng loại U16 châu Á 2018 , U16 Việt Nam và U16 Australia tạm bằng điểm nhau.', 'spos': [153, 249], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [47, 59]}, 'entity_2': {'text': 'U16 Australia', 'pos': [63, 76]}, 'label': 'OTHERS', 'new_sentence': 'Như vậy tại bảng I vòng loại U16 châu Á 2018 , U16 Việt Nam và U16 Australia tạm bằng điểm nhau.', 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [47, 59], 'wtk_index_lst': [10, 11], 'pos_no_space': [35, 45]}, 'new_entity_2': {'text': 'U16 Australia', 'pos': [63, 76], 'wtk_index_lst': [13], 'pos_no_space': [47, 59]}, 'word_tokenize_lst': ['Như vậy', 'tại', 'bảng', 'I', 'vòng', 'loại', 'U16', 'châu Á', '2018', ',', 'U16', 'Việt Nam', 'và', 'U16 Australia', 'tạm', 'bằng', 'điểm', 'nhau', '.']}\n","{'doc_id': '23351996', 'sent_id': 8, 'sentence': 'U16 Việt Nam thắng dễ U16 Mông Cổ .', 'spos': [316, 351], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [22, 33]}, 'label': 'OTHERS', 'new_sentence': 'U16 Việt Nam thắng dễ U16 Mông Cổ .', 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12], 'wtk_index_lst': [0, 1], 'pos_no_space': [0, 10]}, 'new_entity_2': {'text': 'U16 Mông Cổ', 'pos': [22, 33], 'wtk_index_lst': [4, 5], 'pos_no_space': [17, 26]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'thắng', 'dễ', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 9, 'sentence': 'Trong trận ra quân tại bảng I vòng loại U16 châu Á 2018 gặp U16 Campuchia , dù bị gỡ hòa 1-1 và bị mất người ở phút 20, nhưng U16 Việt Nam vẫn chơi xuất sắc để có chiến thắng chung cuộc 5-2.', 'spos': [352, 542], 'entity_1': {'text': 'U16 Campuchia', 'pos': [60, 73]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [126, 138]}, 'label': 'OTHERS', 'new_sentence': 'Trong trận ra quân tại bảng I vòng loại U16 châu Á 2018 gặp U16 Campuchia , dù bị gỡ hòa 1-1 và bị mất người ở phút 20, nhưng U16 Việt Nam vẫn chơi xuất sắc để có chiến thắng chung cuộc 5-2.', 'new_entity_1': {'text': 'U16 Campuchia', 'pos': [60, 73], 'wtk_index_lst': [12, 13], 'pos_no_space': [46, 58]}, 'new_entity_2': {'text': 'U16 Việt Nam', 'pos': [126, 138], 'wtk_index_lst': [28, 29], 'pos_no_space': [96, 106]}, 'word_tokenize_lst': ['Trong', 'trận', 'ra quân', 'tại', 'bảng', 'I', 'vòng', 'loại', 'U16', 'châu Á', '2018', 'gặp', 'U16', 'Campuchia', ',', 'dù', 'bị', 'gỡ', 'hòa 1-1', 'và', 'bị', 'mất', 'người', 'ở', 'phút', '20', ',', 'nhưng', 'U16', 'Việt Nam', 'vẫn', 'chơi', 'xuất sắc', 'để', 'có', 'chiến thắng', 'chung', 'cuộc', '5-2', '.']}\n","{'doc_id': '23351996', 'sent_id': 10, 'sentence': 'Bước vào trận thứ 2 gặp chủ nhà U16 Mông Cổ , U16 Việt Nam tràn đầy tự tin hướng tới một chiến thắng đậm nhằm tạo đà tâm lý trước cuộc quyết đấu với U16 Australia vào chiều ngày 24/9 tới.', 'spos': [543, 730], 'entity_1': {'text': 'U16 Mông Cổ', 'pos': [32, 43]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [46, 58]}, 'label': 'OTHERS', 'new_sentence': 'Bước vào trận thứ 2 gặp chủ nhà U16 Mông Cổ , U16 Việt Nam tràn đầy tự tin hướng tới một chiến thắng đậm nhằm tạo đà tâm lý trước cuộc quyết đấu với U16 Australia vào chiều ngày 24/9 tới.', 'new_entity_1': {'text': 'U16 Mông Cổ', 'pos': [32, 43], 'wtk_index_lst': [8, 9], 'pos_no_space': [24, 33]}, 'new_entity_2': {'text': 'U16 Việt Nam', 'pos': [46, 58], 'wtk_index_lst': [11, 12], 'pos_no_space': [34, 44]}, 'word_tokenize_lst': ['Bước', 'vào', 'trận', 'thứ', '2', 'gặp', 'chủ', 'nhà', 'U16', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'tràn đầy', 'tự tin', 'hướng', 'tới', 'một', 'chiến thắng', 'đậm', 'nhằm', 'tạo', 'đà tâm lý', 'trước', 'cuộc', 'quyết đấu', 'với', 'U16 Australia', 'vào', 'chiều', 'ngày', '24/9', 'tới', '.']}\n","{'doc_id': '23351996', 'sent_id': 11, 'sentence': 'Bước vào trận thứ 2 gặp chủ nhà U16 Mông Cổ , U16 Việt Nam tràn đầy tự tin hướng tới một chiến thắng đậm nhằm tạo đà tâm lý trước cuộc quyết đấu với U16 Australia vào chiều ngày 24/9 tới.', 'spos': [543, 730], 'entity_1': {'text': 'U16 Mông Cổ', 'pos': [32, 43]}, 'entity_2': {'text': 'U16 Australia', 'pos': [149, 162]}, 'label': 'OTHERS', 'new_sentence': 'Bước vào trận thứ 2 gặp chủ nhà U16 Mông Cổ , U16 Việt Nam tràn đầy tự tin hướng tới một chiến thắng đậm nhằm tạo đà tâm lý trước cuộc quyết đấu với U16 Australia vào chiều ngày 24/9 tới.', 'new_entity_1': {'text': 'U16 Mông Cổ', 'pos': [32, 43], 'wtk_index_lst': [8, 9], 'pos_no_space': [24, 33]}, 'new_entity_2': {'text': 'U16 Australia', 'pos': [149, 162], 'wtk_index_lst': [27], 'pos_no_space': [114, 126]}, 'word_tokenize_lst': ['Bước', 'vào', 'trận', 'thứ', '2', 'gặp', 'chủ', 'nhà', 'U16', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'tràn đầy', 'tự tin', 'hướng', 'tới', 'một', 'chiến thắng', 'đậm', 'nhằm', 'tạo', 'đà tâm lý', 'trước', 'cuộc', 'quyết đấu', 'với', 'U16 Australia', 'vào', 'chiều', 'ngày', '24/9', 'tới', '.']}\n","{'doc_id': '23351996', 'sent_id': 12, 'sentence': 'Bước vào trận thứ 2 gặp chủ nhà U16 Mông Cổ , U16 Việt Nam tràn đầy tự tin hướng tới một chiến thắng đậm nhằm tạo đà tâm lý trước cuộc quyết đấu với U16 Australia vào chiều ngày 24/9 tới.', 'spos': [543, 730], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [46, 58]}, 'entity_2': {'text': 'U16 Australia', 'pos': [149, 162]}, 'label': 'OTHERS', 'new_sentence': 'Bước vào trận thứ 2 gặp chủ nhà U16 Mông Cổ , U16 Việt Nam tràn đầy tự tin hướng tới một chiến thắng đậm nhằm tạo đà tâm lý trước cuộc quyết đấu với U16 Australia vào chiều ngày 24/9 tới.', 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [46, 58], 'wtk_index_lst': [11, 12], 'pos_no_space': [34, 44]}, 'new_entity_2': {'text': 'U16 Australia', 'pos': [149, 162], 'wtk_index_lst': [27], 'pos_no_space': [114, 126]}, 'word_tokenize_lst': ['Bước', 'vào', 'trận', 'thứ', '2', 'gặp', 'chủ', 'nhà', 'U16', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'tràn đầy', 'tự tin', 'hướng', 'tới', 'một', 'chiến thắng', 'đậm', 'nhằm', 'tạo', 'đà tâm lý', 'trước', 'cuộc', 'quyết đấu', 'với', 'U16 Australia', 'vào', 'chiều', 'ngày', '24/9', 'tới', '.']}\n","{'doc_id': '23351996', 'sent_id': 13, 'sentence': 'Trước một đối thủ bị đánh giá thấp hơn về mọi mặt, U16 Việt Nam không gặp nhiều khó khăn để làm chủ cuộc chơi và nhanh chóng có bàn vượt lên dẫn trước do công của Nguyên Hoàng ngay phút thứ 13.', 'spos': [731, 924], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [51, 63]}, 'entity_2': {'text': 'Nguyên Hoàng', 'pos': [163, 175]}, 'label': 'AFFILIATION_TO', 'new_sentence': 'Trước một đối thủ bị đánh giá thấp hơn về mọi mặt, U16 Việt Nam không gặp nhiều khó khăn để làm chủ cuộc chơi và nhanh chóng có bàn vượt lên dẫn trước do công của Nguyên Hoàng ngay phút thứ 13.', 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [51, 63], 'wtk_index_lst': [11, 12], 'pos_no_space': [39, 49]}, 'new_entity_2': {'text': 'Nguyên Hoàng', 'pos': [163, 175], 'wtk_index_lst': [31], 'pos_no_space': [126, 137]}, 'word_tokenize_lst': ['Trước', 'một', 'đối thủ', 'bị', 'đánh giá', 'thấp', 'hơn', 'về', 'mọi', 'mặt', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'làm chủ', 'cuộc chơi', 'và', 'nhanh chóng', 'có', 'bàn', 'vượt', 'lên', 'dẫn', 'trước', 'do', 'công', 'của', 'Nguyên Hoàng', 'ngay', 'phút', 'thứ', '13', '.']}\n","{'doc_id': '23351996', 'sent_id': 14, 'sentence': '10 phút sau, Thanh Trung (số 7) nâng tỷ số lên 2-0 từ chấm phạt đền sau khi thủ môn đối phương phạm lỗi với Nguyên Hoàng trong vòng cấm.', 'spos': [925, 1061], 'entity_1': {'text': 'Thanh Trung', 'pos': [13, 24]}, 'entity_2': {'text': 'Nguyên Hoàng', 'pos': [108, 120]}, 'label': 'OTHERS', 'new_sentence': '10 phút sau, Thanh Trung (số 7) nâng tỷ số lên 2-0 từ chấm phạt đền sau khi thủ môn đối phương phạm lỗi với Nguyên Hoàng trong vòng cấm.', 'new_entity_1': {'text': 'Thanh Trung', 'pos': [13, 24], 'wtk_index_lst': [4], 'pos_no_space': [10, 20]}, 'new_entity_2': {'text': 'Nguyên Hoàng', 'pos': [108, 120], 'wtk_index_lst': [23], 'pos_no_space': [83, 94]}, 'word_tokenize_lst': ['10', 'phút', 'sau', ',', 'Thanh Trung', '(', 'số', '7', ')', 'nâng', 'tỷ', 'số', 'lên', '2-0', 'từ', 'chấm', 'phạt đền', 'sau', 'khi', 'thủ môn', 'đối phương phạm', 'lỗi', 'với', 'Nguyên Hoàng', 'trong', 'vòng', 'cấm', '.']}\n","{'doc_id': '23351996', 'sent_id': 15, 'sentence': 'Những phút còn lại của hiệp 1, U16 Việt Nam tiếp tục tạo ra một sức ép cực lớn lên phần sân của U16 Mông Cổ .', 'spos': [1062, 1171], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [31, 43]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [96, 107]}, 'label': 'OTHERS', 'new_sentence': 'Những phút còn lại của hiệp 1, U16 Việt Nam tiếp tục tạo ra một sức ép cực lớn lên phần sân của U16 Mông Cổ .', 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [31, 43], 'wtk_index_lst': [8, 9], 'pos_no_space': [24, 34]}, 'new_entity_2': {'text': 'U16 Mông Cổ', 'pos': [96, 107], 'wtk_index_lst': [21, 22], 'pos_no_space': [73, 82]}, 'word_tokenize_lst': ['Những', 'phút', 'còn', 'lại', 'của', 'hiệp', '1', ',', 'U16', 'Việt Nam', 'tiếp tục', 'tạo', 'ra', 'một', 'sức ép', 'cực', 'lớn', 'lên', 'phần', 'sân', 'của', 'U16', 'Mông Cổ', '.']}\n","{'doc_id': '23351996', 'sent_id': 16, 'sentence': 'Sang hiệp 2, HLV Vũ Hồng Việt yêu cầu các học trò tấn công mạnh mẽ hơn nữa, trong khi U16 Mông Cổ có dấu hiệu xuống sức rõ rệt.', 'spos': [1265, 1392], 'entity_1': {'text': 'Vũ Hồng Việt', 'pos': [17, 29]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [86, 97]}, 'label': 'OTHERS', 'new_sentence': 'Sang hiệp 2, HLV Vũ Hồng Việt yêu cầu các học trò tấn công mạnh mẽ hơn nữa, trong khi U16 Mông Cổ có dấu hiệu xuống sức rõ rệt.', 'new_entity_1': {'text': 'Vũ Hồng Việt', 'pos': [17, 29], 'wtk_index_lst': [5], 'pos_no_space': [13, 23]}, 'new_entity_2': {'text': 'U16 Mông Cổ', 'pos': [86, 97], 'wtk_index_lst': [15, 16], 'pos_no_space': [66, 75]}, 'word_tokenize_lst': ['Sang', 'hiệp', '2', ',', 'HLV', 'Vũ Hồng Việt', 'yêu cầu', 'các', 'học trò', 'tấn công', 'mạnh mẽ', 'hơn nữa', ',', 'trong', 'khi', 'U16', 'Mông Cổ', 'có', 'dấu hiệu', 'xuống', 'sức', 'rõ rệt', '.']}\n","{'doc_id': '23351996', 'sent_id': 17, 'sentence': 'Riêng ở hiệp đấu này, Chí Bảo đã ghi tới 4 bàn thắng, giúp U16 Việt Nam thắng chung cuộc 9-0.', 'spos': [1430, 1523], 'entity_1': {'text': 'Chí Bảo', 'pos': [22, 29]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [59, 71]}, 'label': 'AFFILIATION', 'new_sentence': 'Riêng ở hiệp đấu này, Chí Bảo đã ghi tới 4 bàn thắng, giúp U16 Việt Nam thắng chung cuộc 9-0.', 'new_entity_1': {'text': 'Chí Bảo', 'pos': [22, 29], 'wtk_index_lst': [5], 'pos_no_space': [17, 23]}, 'new_entity_2': {'text': 'U16 Việt Nam', 'pos': [59, 71], 'wtk_index_lst': [14, 15], 'pos_no_space': [45, 55]}, 'word_tokenize_lst': ['Riêng', 'ở', 'hiệp đấu', 'này', ',', 'Chí Bảo', 'đã', 'ghi', 'tới', '4', 'bàn', 'thắng', ',', 'giúp', 'U16', 'Việt Nam', 'thắng', 'chung', 'cuộc', '9-0', '.']}\n","{'doc_id': '23351996', 'sent_id': 18, 'sentence': 'Tại bảng I lúc này, thầy trò Vũ Hồng Việt có cùng điểm số như U16 Australia nhưng xếp dưới vì kém hiệu số bàn thắng bại.', 'spos': [1636, 1756], 'entity_1': {'text': 'Vũ Hồng Việt', 'pos': [29, 41]}, 'entity_2': {'text': 'U16 Australia', 'pos': [62, 75]}, 'label': 'OTHERS', 'new_sentence': 'Tại bảng I lúc này, thầy trò Vũ Hồng Việt có cùng điểm số như U16 Australia nhưng xếp dưới vì kém hiệu số bàn thắng bại.', 'new_entity_1': {'text': 'Vũ Hồng Việt', 'pos': [29, 41], 'wtk_index_lst': [7], 'pos_no_space': [22, 32]}, 'new_entity_2': {'text': 'U16 Australia', 'pos': [62, 75], 'wtk_index_lst': [12], 'pos_no_space': [47, 59]}, 'word_tokenize_lst': ['Tại', 'bảng', 'I', 'lúc', 'này', ',', 'thầy trò', 'Vũ Hồng Việt', 'có', 'cùng', 'điểm số', 'như', 'U16 Australia', 'nhưng', 'xếp', 'dưới', 'vì', 'kém hiệu', 'số', 'bàn', 'thắng bại', '.']}\n","{'doc_id': '23351997', 'sent_id': 19, 'sentence': 'Đặc biệt là trận thua ‘sốc’ trước đội bóng nhược tiểu Real Betis đã khiến khoảng cách giữa Los Blancos và Barcelona bị nới rộng lên thành 7 điểm.', 'spos': [222, 367], 'entity_1': {'text': 'Real Betis', 'pos': [54, 64]}, 'entity_2': {'text': 'Barcelona', 'pos': [106, 115]}, 'label': 'OTHERS', 'new_sentence': 'Đặc biệt là trận thua ‘sốc’ trước đội bóng nhược tiểu Real Betis đã khiến khoảng cách giữa Los Blancos và Barcelona bị nới rộng lên thành 7 điểm.', 'new_entity_1': {'text': 'Real Betis', 'pos': [54, 64], 'wtk_index_lst': [10, 11], 'pos_no_space': [43, 52]}, 'new_entity_2': {'text': 'Barcelona', 'pos': [106, 115], 'wtk_index_lst': [18], 'pos_no_space': [85, 94]}, 'word_tokenize_lst': ['Đặc biệt', 'là', 'trận', 'thua', '‘ sốc', '’', 'trước', 'đội', 'bóng', 'nhược tiểu', 'Real', 'Betis', 'đã', 'khiến', 'khoảng cách', 'giữa', 'Los Blancos', 'và', 'Barcelona', 'bị', 'nới', 'rộng', 'lên', 'thành', '7', 'điểm', '.']}\n","{'doc_id': '23351997', 'sent_id': 20, 'sentence': 'Từ đầu mùa giải, đội bóng Hoàng gia đã gặp khó khăn về mặt lực lượng khi các trụ cột như Ronaldo , Ramos , Marcelo thay nhau lãnh thẻ đỏ.', 'spos': [368, 505], 'entity_1': {'text': 'Ronaldo', 'pos': [89, 96]}, 'entity_2': {'text': 'Ramos', 'pos': [99, 104]}, 'label': 'OTHERS', 'new_sentence': 'Từ đầu mùa giải, đội bóng Hoàng gia đã gặp khó khăn về mặt lực lượng khi các trụ cột như Ronaldo , Ramos , Marcelo thay nhau lãnh thẻ đỏ.', 'new_entity_1': {'text': 'Ronaldo', 'pos': [89, 96], 'wtk_index_lst': [18], 'pos_no_space': [68, 75]}, 'new_entity_2': {'text': 'Ramos', 'pos': [99, 104], 'wtk_index_lst': [20], 'pos_no_space': [76, 81]}, 'word_tokenize_lst': ['Từ', 'đầu', 'mùa', 'giải', ',', 'đội', 'bóng', 'Hoàng gia', 'đã', 'gặp', 'khó khăn', 'về', 'mặt', 'lực lượng', 'khi', 'các', 'trụ cột', 'như', 'Ronaldo', ',', 'Ramos', ',', 'Marcelo', 'thay', 'nhau', 'lãnh thẻ', 'đỏ', '.']}\n"]}]},{"cell_type":"markdown","metadata":{"id":"yoKdd-zY66Jc"},"source":["##### Create test input"]},{"cell_type":"markdown","metadata":{"id":"5xfu-7oPFyIA"},"source":["###### max len"]},{"cell_type":"code","metadata":{"id":"SzFYaBbn5N80","colab":{"base_uri":"https://localhost:8080/"},"outputId":"225f298f-b014-4c5a-c92a-0b8dd629733e","executionInfo":{"status":"ok","timestamp":1717425207272,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["print(jdev_data_v3[0])"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["{'doc_id': '23351996', 'sent_id': 1, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12], 'wtk_index_lst': [0, 1], 'pos_no_space': [0, 10]}, 'new_entity_2': {'text': 'Mông Cổ', 'pos': [36, 43], 'wtk_index_lst': [9], 'pos_no_space': [28, 34]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n"]}]},{"cell_type":"code","source":["pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"],"metadata":{"id":"6uwYar57Cj9Y","executionInfo":{"status":"ok","timestamp":1717425208870,"user_tz":-420,"elapsed":1601,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["pb_sent_maxlen = 0\n","xlmr_sent_maxlen = 0\n","\n","pb_sent_len_lst = []\n","xlmr_sent_len_lst = []\n","\n","for sentif in jdev_data_v3:\n","\n","    # assert (sentif['new_sentence'] == unicodedata.normalize(\"NFC\", sentif['new_sentence'])), str('sentence not seem to be normalized.')\n","    # assert (''.join(sentif['new_sentence'].split()) == u''.join([tk.replace(\" \", \"\") for tk in sentif['word_tokenize_lst']])), \\\n","    # str('word_tokenize_lst not match new_sentence.')\n","\n","    # phobert\n","    pb_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n","    pb_sent_tokenize = pb_tokenizer.tokenize(pb_sent)\n","\n","    pb_sent_maxlen = max(pb_sent_maxlen, len(pb_sent_tokenize))\n","\n","    pb_sent_len_lst.append(len(pb_sent_tokenize))\n","\n","    # xlmr\n","    # xlmr_sent = u\" \".join(copy.deepcopy(sentif['word_tokenize_lst']))\n","    # xlmr_sent_tokenize = xlmr_tokenizer.tokenize(xlmr_sent)\n","\n","    # xlmr_sent_maxlen = max(xlmr_sent_maxlen, len(xlmr_sent_tokenize))\n","    # xlmr_sent_len_lst.append(len(xlmr_sent_tokenize))\n","\n","\n","print('pb_sent_maxlen: ', pb_sent_maxlen)\n","#print('xlmr_sent_maxlen: ', xlmr_sent_maxlen)\n","\n","\n"],"metadata":{"id":"J3TjE-RnB9XY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425213818,"user_tz":-420,"elapsed":4953,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}},"outputId":"6af73e22-04e5-46e1-b444-4cb80fef89ce"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["pb_sent_maxlen:  138\n"]}]},{"cell_type":"code","source":["\n","import pandas as pd\n","from collections import Counter\n","\n","# phobert\n","print('--phobert')\n","print(pd.Series(pb_sent_len_lst).describe())\n","most_common_len = Counter(pb_sent_len_lst).most_common(1)[0]\n","print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n","# # xlmr\n","# print('\\n--XLM-RoBERTa')\n","# print(pd.Series(xlmr_sent_len_lst).describe())\n","# most_common_len = Counter(xlmr_sent_len_lst).most_common(1)[0]\n","# print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n"],"metadata":{"id":"H1FDIMw5B-pD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425213818,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}},"outputId":"24bc93f7-171b-4777-965e-926a8faaccf5"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["--phobert\n","count    9235.000000\n","mean       46.846021\n","std        21.728016\n","min         3.000000\n","25%        31.000000\n","50%        43.000000\n","75%        59.000000\n","max       138.000000\n","dtype: float64\n","most common sentence len:  47  appear  269  times.\n"]}]},{"cell_type":"code","source":["for sentif in jdev_data_v3:\n","    if 'Hotspur' in sentif['new_sentence']:\n","        print(sentif)"],"metadata":{"id":"b_YG2I0wCBNk","executionInfo":{"status":"ok","timestamp":1717425213819,"user_tz":-420,"elapsed":11,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["if flags['use_phobert'] == True:\n","    dev_pb_input_ids = []\n","    dev_pb_attention_masks = []\n","    dev_pb_entity_1_eids = []\n","    dev_pb_entity_2_eids = []\n","    #dev_pb_labels = []\n","\n","if flags['use_xlmr'] == True:\n","    dev_xlmr_input_ids = []\n","    dev_xlmr_attention_masks = []\n","    dev_xlmr_entity_1_eids = []\n","    dev_xlmr_entity_2_eids = []\n","    #dev_xlmr_labels = []\n","\n","dev_labels = []\n","\n","# Do entity_eids của các entity trong các câu không cùng chiều dài nên ta cần chuyển về cùng chiều dài thì mới biến thành tensor được\n","# để chuyển về cùng chiều dài ta sẽ pad các eids ngắn hơn bằng -2.\n","# vì eids phải >= 1 nên để số < 0 sẽ không sợ nhầm và ta chỉ thêm vào bên phải.\n","# >= 1 vì lúc tìm eids đã tính <s> nên đã +1 sẵn nên min = 1\n","# giả sử 1 entity_eids chỉ có chiều dài max là 30\n","pad_ent_eid = -2\n","max_len_ent_eid = 30\n","\n","assert (pad_ent_eid < 0), str('pad_ent_eid must < 0')\n","\n","jdev_data_use = copy.deepcopy(jdev_data_v3)\n","\n","for isentif, sentif in enumerate(jdev_data_use):\n","\n","    # if flags['use_xlmr'] == True:\n","    #     # xlmr\n","    #     # xlmr biến … thành ... khi tokenize nên cần sửa lại wpi_start_pos, wpi_end_pos\n","    #             # và với cái wpi này thì chấp nhận sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi\n","    #             # tương tự với ½ thành 1⁄2\n","\n","    #     # Lưu ý: XLM-R có một số kí tự như … bị biến thành ..., ½ thành 1⁄2 dẫn tới việc check, kiểm tra so sánh chuỗi bị khác\n","    #     # và dù trong câu lẫn word_tokenize_lst có kí tự \\ufeff nhưng khi XLM-R lại loại bỏ khi toknenize nên kí tự cũng bị thay đổi vị trí\n","    #     # các vấn đề này được fix trong hàm: get_entity_word_piece_index()\n","\n","    #     #xlmr_input_sent = sentif['new_sentence']\n","    #     xlmr_input_sent = u\" \".join(sentif['word_tokenize_lst'])\n","\n","    #     xlmr_encode_dict = xlmr_tokenizer(xlmr_input_sent, add_special_tokens=True, padding='max_length', max_length=224)\n","\n","    #     xlmr_tokenize_lst = xlmr_tokenizer.tokenize(xlmr_input_sent)\n","    #     assert ((len(xlmr_tokenize_lst) + 2) <= 224), str('len xlmr_tokenize_lst > 224')\n","\n","\n","    #     xlmr_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'xlmr', xlmr_encode_dict['input_ids'], 'dev')\n","    #     xlmr_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'xlmr', xlmr_encode_dict['input_ids'], 'dev')\n","\n","    #     # pad\n","    #     assert ((len(xlmr_entity_1_eids) <= max_len_ent_eid) and (len(xlmr_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n","\n","    #     xlmr_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_entity_1_eids))\n","    #     xlmr_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_entity_2_eids))\n","\n","\n","    #     if isentif < 10:\n","    #         print('\\n')\n","    #         print(xlmr_tokenize_lst)\n","    #         print(sentif['new_entity_1']['text'])\n","    #         print(xlmr_entity_1_eids)\n","    #         print(sentif['new_entity_2']['text'])\n","    #         print(xlmr_entity_2_eids)\n","\n","\n","    #     dev_xlmr_input_ids.append(copy.deepcopy(xlmr_encode_dict['input_ids']))\n","    #     dev_xlmr_attention_masks.append(copy.deepcopy(xlmr_encode_dict['attention_mask']))\n","    #     dev_xlmr_entity_1_eids.append(copy.deepcopy(xlmr_entity_1_eids))\n","    #     dev_xlmr_entity_2_eids.append(copy.deepcopy(xlmr_entity_2_eids))\n","    #     #dev_xlmr_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","\n","\n","\n","    if flags['use_phobert'] == True:\n","        # phobert\n","        # lưu ý: phải để phobert ở bên dưới xlmr để những thay đổi bên dưới chỉ ảnh hưởng tới phobert chứ không ảnh hưởng tới XLM-R\n","        # trong các câu chứa các cụm dưới, chả hiểu sao trong phobert '’' khi đứng 1 mình thì encode là 1 wpi bthg\n","        # nhưng đứng trong cụm dưới dưới thì lại thành <unk>\n","        # ta sẽ đổi ’ thành ' thì sẽ k bị lỗi nữa\n","\n","        if ('Cư M’gar' in sentif['word_tokenize_lst']) or ('L’Oreal' in sentif['word_tokenize_lst']) or ('Hay’at Tahrir Al-Sham' in sentif['word_tokenize_lst']) \\\n","        or ('Đắk R’Lấp' in sentif['word_tokenize_lst']) or ('Let’s Việt' in sentif['word_tokenize_lst']) or ('H’M' in sentif['word_tokenize_lst']) \\\n","        or ('H’A Byă' in sentif['word_tokenize_lst']):\n","\n","\n","            for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n","                if '’' in wtk_item:\n","                    sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","\n","\n","            sentif['new_sentence'] = sentif['new_sentence'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","            sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","            sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","\n","\n","        if ('Eugène Schueller' in sentif['new_sentence']):\n","\n","\n","            for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n","                if 'Eugène Schueller' in wtk_item:\n","                    sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n","\n","\n","            sentif['new_sentence'] = sentif['new_sentence'].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n","            sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n","            sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n","\n","\n","\n","        pb_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n","\n","        pb_encode_dict = pb_tokenizer(pb_input_sent, add_special_tokens=True, padding='max_length', max_length=160)\n","\n","        pb_tokenize_lst = pb_tokenizer.tokenize(pb_input_sent)\n","        assert ((len(pb_tokenize_lst) + 2) <= 160), str('len pb_tokenize_lst > 160')\n","\n","        pb_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], pb_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'phobert', pb_encode_dict['input_ids'], 'dev')\n","        pb_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], pb_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'phobert', pb_encode_dict['input_ids'], 'dev')\n","\n","        # pad\n","        assert ((len(pb_entity_1_eids) <= max_len_ent_eid) and (len(pb_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n","\n","        pb_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_1_eids))\n","        pb_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_2_eids))\n","\n","\n","\n","        if isentif < 10:\n","            print('\\n')\n","            print(pb_tokenize_lst)\n","            print(sentif['new_entity_1']['text'])\n","            print(pb_entity_1_eids)\n","            print(sentif['new_entity_2']['text'])\n","            print(pb_entity_2_eids)\n","\n","\n","\n","        dev_pb_input_ids.append(copy.deepcopy(pb_encode_dict['input_ids']))\n","        dev_pb_attention_masks.append(copy.deepcopy(pb_encode_dict['attention_mask']))\n","        dev_pb_entity_1_eids.append(copy.deepcopy(pb_entity_1_eids))\n","        dev_pb_entity_2_eids.append(copy.deepcopy(pb_entity_2_eids))\n","        #dev_pb_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","\n","\n","    dev_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","\n","\n"],"metadata":{"id":"BnWS-aX6CC_2","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1717425279841,"user_tz":-420,"elapsed":1786,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}},"outputId":"42a41872-a27c-41a1-c98c-0eee6c6dbd47"},"execution_count":52,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Unknown model_name. Alow: phobert, xlmr","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-d6da045b3213>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpb_tokenize_lst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'len pb_tokenize_lst > 160'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mpb_entity_1_eids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_entity_word_piece_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentif\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_tokenize_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentif\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_entity_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentif\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'phobert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_encode_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mpb_entity_2_eids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_entity_word_piece_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentif\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_tokenize_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentif\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_entity_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentif\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'phobert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_encode_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-569d16fe0025>\u001b[0m in \u001b[0;36mget_entity_word_piece_index\u001b[0;34m(sent_id, bert_tokenize_lst, entity, sentence, model_name, input_ids, train_or_dev)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown model_name. Alow: phobert, xlmr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mtmp_ent_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_ent_txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Unknown model_name. Alow: phobert, xlmr"]}]},{"cell_type":"code","metadata":{"id":"rOCfi8DmzHDO","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# pb_base_sent_maxlen = 0\n","# #xlmr_base_sent_maxlen = 0\n","\n","# # pb_large_sent_maxlen = 0\n","# # #xlmr_large_sent_maxlen = 0\n","\n","# pb_base_sent_len_lst = []\n","# # xlmr_base_sent_len_lst = []\n","\n","# # pb_large_sent_len_lst = []\n","# # xlmr_large_sent_len_lst = []\n","\n","# for sentif in jtest_data_v3:\n","\n","#     # assert (sentif['new_sentence'] == unicodedata.normalize(\"NFC\", sentif['new_sentence'])), str('sentence not seem to be normalized.')\n","#     # assert (''.join(sentif['new_sentence'].split()) == u''.join([tk.replace(\" \", \"\") for tk in sentif['word_tokenize_lst']])), \\\n","#     # str('word_tokenize_lst not match new_sentence.')\n","\n","\n","\n","#     pb_base_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n","#     pb_base_sent_tokenize = pb_base_tokenizer.tokenize(pb_base_sent)\n","\n","#     pb_base_sent_maxlen = max(pb_base_sent_maxlen, len(pb_base_sent_tokenize))\n","\n","#     pb_base_sent_len_lst.append(len(pb_base_sent_tokenize))\n","\n","\n","#     # xlmr_base_sent = u\" \".join(copy.deepcopy(sentif['word_tokenize_lst']))\n","#     # xlmr_base_sent_tokenize = xlmr_base_tokenizer.tokenize(xlmr_base_sent)\n","\n","#     # xlmr_base_sent_maxlen = max(xlmr_base_sent_maxlen, len(xlmr_base_sent_tokenize))\n","#     # xlmr_base_sent_len_lst.append(len(xlmr_base_sent_tokenize))\n","\n","\n","\n","#     # pb_large_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n","#     # pb_large_sent_tokenize = pb_large_tokenizer.tokenize(pb_large_sent)\n","\n","#     # pb_large_sent_maxlen = max(pb_large_sent_maxlen, len(pb_large_sent_tokenize))\n","\n","#     # pb_large_sent_len_lst.append(len(pb_large_sent_tokenize))\n","\n","\n","#     # xlmr_large_sent = u\" \".join(copy.deepcopy(sentif['word_tokenize_lst']))\n","#     # xlmr_large_sent_tokenize = xlmr_large_tokenizer.tokenize(xlmr_large_sent)\n","\n","#     # xlmr_large_sent_maxlen = max(xlmr_large_sent_maxlen, len(xlmr_large_sent_tokenize))\n","#     # xlmr_large_sent_len_lst.append(len(xlmr_large_sent_tokenize))\n","\n","\n","\n","# print('pb_base_sent_maxlen: ', pb_base_sent_maxlen)\n","# # print('xlmr_base_sent_maxlen: ', xlmr_base_sent_maxlen)\n","# # print('pb_large_sent_maxlen: ', pb_large_sent_maxlen)\n","# # print('xlmr_large_sent_maxlen: ', xlmr_large_sent_maxlen)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JurhkcDLa7xH","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# print(pb_base_sent_len_lst == pb_large_sent_len_lst)\n","# print(xlmr_base_sent_len_lst == xlmr_large_sent_len_lst)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qEdxfgcBARDM","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["\n","# import pandas as pd\n","# from collections import Counter\n","\n","# # phobert\n","\n","# print('--phobert')\n","# print(pd.Series(pb_base_sent_len_lst).describe())\n","# most_common_len = Counter(pb_base_sent_len_lst).most_common(1)[0]\n","# print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n","# # # xlmr\n","\n","# # print('\\n--XLM-RoBERTa')\n","# # print(pd.Series(xlmr_base_sent_len_lst).describe())\n","# # most_common_len = Counter(xlmr_base_sent_len_lst).most_common(1)[0]\n","# # print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n","\n","\n","# # print('--phobert')\n","# # print(pd.Series(pb_large_sent_len_lst).describe())\n","# # most_common_len = Counter(pb_large_sent_len_lst).most_common(1)[0]\n","# # print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n","# # # xlmr\n","\n","# # print('\\n--XLM-RoBERTa')\n","# # print(pd.Series(xlmr_large_sent_len_lst).describe())\n","# # most_common_len = Counter(xlmr_large_sent_len_lst).most_common(1)[0]\n","# # print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SuL9lddpF3eS"},"source":["###### create input"]},{"cell_type":"code","metadata":{"id":"Ho30-2avoKm4","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# for sentif in jtest_data_v3:\n","#     if 'Hotspur' in sentif['new_sentence']:\n","#         print(sentif)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4Lb-dzlCpWp","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["'''\n","# thêm token vào phobert để tránh bị <unk> token, token này sẽ có embedding được khởi tạo một cái random\n","# https://github.com/huggingface/transformers/issues/1413\n","# https://huggingface.co/transformers/internal/tokenization_utils.html?highlight=add_token\n","\n","print(len(pb_tokenizer))\n","\n","add_Hotspur_to_pb = pb_tokenizer.add_tokens([unicodedata.normalize(\"NFC\", 'Hotspur')])\n","print('We have added', add_Hotspur_to_pb, 'tokens')\n","# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n","\n","print(len(pb_tokenizer))\n","\n","pb_model.resize_token_embeddings(len(pb_tokenizer))\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NpJ2RKTg65ft","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# test_pb_base_input_ids = []\n","# test_pb_base_attention_masks = []\n","# test_pb_base_entity_1_eids = []\n","# test_pb_base_entity_2_eids = []\n","# #test_pb_labels = []\n","\n","# # test_xlmr_base_input_ids = []\n","# # test_xlmr_base_attention_masks = []\n","# # test_xlmr_base_entity_1_eids = []\n","# # test_xlmr_base_entity_2_eids = []\n","# # #test_xlmr_labels = []\n","\n","# # test_pb_large_input_ids = []\n","# # test_pb_large_attention_masks = []\n","# # test_pb_large_entity_1_eids = []\n","# # test_pb_large_entity_2_eids = []\n","# # #test_pb_labels = []\n","\n","# # test_xlmr_large_input_ids = []\n","# # test_xlmr_large_attention_masks = []\n","# # test_xlmr_large_entity_1_eids = []\n","# # test_xlmr_large_entity_2_eids = []\n","# #test_xlmr_labels = []\n","\n","# sent_ids = []\n","\n","# test_labels = []\n","\n","# # Do entity_eids của các entity trong các câu không cùng chiều dài nên ta cần chuyển về cùng chiều dài thì mới biến thành tensor được\n","# # để chuyển về cùng chiều dài ta sẽ pad các eids ngắn hơn bằng -2.\n","# # vì eids phải >= 1 nên để số < 0 sẽ không sợ nhầm và ta chỉ thêm vào bên phải.\n","# # >= 1 vì lúc tìm eids đã tính <s> nên đã +1 sẵn nên min = 1\n","# # giả sử 1 entity_eids chỉ có chiều dài max là 30\n","# pad_ent_eid = -2\n","# max_len_ent_eid = 30\n","\n","# assert (pad_ent_eid < 0), str('pad_ent_eid must < 0')\n","\n","# jtest_data_use = copy.deepcopy(jtest_data_v3)\n","\n","# for isentif, sentif in enumerate(jtest_data_use):\n","\n","\n","#     # if True:\n","#     #     # xlmr_base\n","#     #     # xlmr_base biến … thành ... khi tokenize nên cần sửa lại wpi_start_pos, wpi_end_pos\n","#     #             # và với cái wpi này thì chấp nhận sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi\n","#     #             # tương tự với ½ thành 1⁄2\n","\n","#     #     # Lưu ý: XLM-R có một số kí tự như … bị biến thành ..., ½ thành 1⁄2 dẫn tới việc check, kiểm tra so sánh chuỗi bị khác\n","#     #     # và dù trong câu lẫn word_tokenize_lst có kí tự \\ufeff nhưng khi XLM-R lại loại bỏ khi toknenize nên kí tự cũng bị thay đổi vị trí\n","#     #     # các vấn đề này được fix trong hàm: get_entity_word_piece_index()\n","\n","#     #     #xlmr_base_input_sent = sentif['new_sentence']\n","#     #     xlmr_base_input_sent = u\" \".join(sentif['word_tokenize_lst'])\n","\n","#     #     xlmr_base_encode_dict = xlmr_base_tokenizer(xlmr_base_input_sent, add_special_tokens=True, padding='max_length', max_length=746)\n","\n","#     #     xlmr_base_tokenize_lst = xlmr_base_tokenizer.tokenize(xlmr_base_input_sent)\n","#     #     assert ((len(xlmr_base_tokenize_lst) + 2) <= 746), str('len xlmr_base_tokenize_lst > 746')\n","\n","#     #     xlmr_base_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_base_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'xlmr_base', xlmr_base_encode_dict['input_ids'], 'test')\n","#     #     xlmr_base_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_base_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'xlmr_base', xlmr_base_encode_dict['input_ids'], 'test')\n","\n","#     #     # pad\n","#     #     assert ((len(xlmr_base_entity_1_eids) <= max_len_ent_eid) and (len(xlmr_base_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n","\n","#     #     xlmr_base_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_base_entity_1_eids))\n","#     #     xlmr_base_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_base_entity_2_eids))\n","\n","\n","#     #     if isentif < 10:\n","#     #         print('\\n')\n","#     #         print(xlmr_base_tokenize_lst)\n","#     #         print(sentif['new_entity_1']['text'])\n","#     #         print(xlmr_base_entity_1_eids)\n","#     #         print(sentif['new_entity_2']['text'])\n","#     #         print(xlmr_base_entity_2_eids)\n","\n","\n","#     #     test_xlmr_base_input_ids.append(copy.deepcopy(xlmr_base_encode_dict['input_ids']))\n","#     #     test_xlmr_base_attention_masks.append(copy.deepcopy(xlmr_base_encode_dict['attention_mask']))\n","#     #     test_xlmr_base_entity_1_eids.append(copy.deepcopy(xlmr_base_entity_1_eids))\n","#     #     test_xlmr_base_entity_2_eids.append(copy.deepcopy(xlmr_base_entity_2_eids))\n","#     #     #test_xlmr_base_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","\n","\n","\n","#     # if True:\n","#     #     # xlmr_large\n","#     #     # xlmr_large biến … thành ... khi tokenize nên cần sửa lại wpi_start_pos, wpi_end_pos\n","#     #             # và với cái wpi này thì chấp nhận sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi\n","#     #             # tương tự với ½ thành 1⁄2\n","\n","#     #     # Lưu ý: XLM-R có một số kí tự như … bị biến thành ..., ½ thành 1⁄2 dẫn tới việc check, kiểm tra so sánh chuỗi bị khác\n","#     #     # và dù trong câu lẫn word_tokenize_lst có kí tự \\ufeff nhưng khi XLM-R lại loại bỏ khi toknenize nên kí tự cũng bị thay đổi vị trí\n","#     #     # các vấn đề này được fix trong hàm: get_entity_word_piece_index()\n","\n","#     #     #xlmr_large_input_sent = sentif['new_sentence']\n","#     #     xlmr_large_input_sent = u\" \".join(sentif['word_tokenize_lst'])\n","\n","#     #     xlmr_large_encode_dict = xlmr_large_tokenizer(xlmr_large_input_sent, add_special_tokens=True, padding='max_length', max_length=746)\n","\n","#     #     xlmr_large_tokenize_lst = xlmr_large_tokenizer.tokenize(xlmr_large_input_sent)\n","#     #     assert ((len(xlmr_large_tokenize_lst) + 2) <= 746), str('len xlmr_large_tokenize_lst > 746')\n","\n","#     #     xlmr_large_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_large_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'xlmr_large', xlmr_large_encode_dict['input_ids'], 'test')\n","#     #     xlmr_large_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_large_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'xlmr_large', xlmr_large_encode_dict['input_ids'], 'test')\n","\n","#     #     # pad\n","#     #     assert ((len(xlmr_large_entity_1_eids) <= max_len_ent_eid) and (len(xlmr_large_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n","\n","#     #     xlmr_large_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_large_entity_1_eids))\n","#     #     xlmr_large_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_large_entity_2_eids))\n","\n","\n","#     #     if isentif < 10:\n","#     #         print('\\n')\n","#     #         print(xlmr_large_tokenize_lst)\n","#     #         print(sentif['new_entity_1']['text'])\n","#     #         print(xlmr_large_entity_1_eids)\n","#     #         print(sentif['new_entity_2']['text'])\n","#     #         print(xlmr_large_entity_2_eids)\n","\n","\n","#     #     test_xlmr_large_input_ids.append(copy.deepcopy(xlmr_large_encode_dict['input_ids']))\n","#     #     test_xlmr_large_attention_masks.append(copy.deepcopy(xlmr_large_encode_dict['attention_mask']))\n","#     #     test_xlmr_large_entity_1_eids.append(copy.deepcopy(xlmr_large_entity_1_eids))\n","#     #     test_xlmr_large_entity_2_eids.append(copy.deepcopy(xlmr_large_entity_2_eids))\n","#     #     #test_xlmr_large_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","\n","\n","\n","\n","#     if True:\n","#         # phobert\n","#         # lưu ý: phải để phobert ở bên dưới xlmr_base để những thay đổi bên dưới chỉ ảnh hưởng tới phobert chứ không ảnh hưởng tới XLM-R\n","#         # trong các câu chứa các cụm dưới, chả hiểu sao trong phobert '’' khi đứng 1 mình thì encode là 1 wpi bthg\n","#         # nhưng đứng trong cụm dưới dưới thì lại thành <unk>\n","#         # ta sẽ đổi ’ thành ' thì sẽ k bị lỗi nữa\n","\n","#         if ('Hanoi Kids ’ Art Center' in sentif['word_tokenize_lst']) or ('Girl’s Day' in sentif['word_tokenize_lst']) or\\\n","#         ('Jermaine O’Neal' in sentif['word_tokenize_lst']) or ('O’Neal' in sentif['word_tokenize_lst']) or\\\n","#         ('Kon K’tu' in sentif['word_tokenize_lst']) or ('M’nông' in sentif['word_tokenize_lst']) or\\\n","#         ('H’rung' in sentif['word_tokenize_lst']) or ('K’Yếu' in sentif['word_tokenize_lst']) or\\\n","#         ('Moody’s' in sentif['word_tokenize_lst']) or ('Las Vegas’s Route' in sentif['word_tokenize_lst']) or\\\n","#         ('Women’s Summit' in sentif['word_tokenize_lst']) or ('E’Twaun Moore' in sentif['word_tokenize_lst']) or\\\n","#         ('King’s Garden' in sentif['word_tokenize_lst']):\n","#             assert (sentif['new_sentence'].count('’') == 1), str('count ’ in new_sentence not equal 1.')\n","\n","#             for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n","#                 if '’' in wtk_item:\n","#                     sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","#                     break\n","\n","\n","#             sentif['new_sentence'] = sentif['new_sentence'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","#             sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","#             sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","\n","#         if ('Garbinẽ Muguruza' in sentif['word_tokenize_lst']):\n","#             assert (sentif['new_sentence'].count('Garbinẽ Muguruza') == 1), str('count Garbinẽ Muguruza in new_sentence not equal 1.')\n","\n","#             for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n","#                 if 'Garbinẽ Muguruza' in wtk_item:\n","#                     sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","#                     break\n","\n","\n","#             sentif['new_sentence'] = sentif['new_sentence'].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","#             sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","#             sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","\n","\n","\n","#         pb_base_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n","\n","#         pb_base_encode_dict = pb_base_tokenizer(pb_base_input_sent, add_special_tokens=True, padding='max_length', max_length=507)\n","\n","#         pb_base_tokenize_lst = pb_base_tokenizer.tokenize(pb_base_input_sent)\n","#         assert ((len(pb_base_tokenize_lst) + 2) <= 507), str('len pb_base_tokenize_lst > 507')\n","\n","#         pb_base_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], pb_base_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'phobert_base', pb_base_encode_dict['input_ids'], 'test')\n","#         pb_base_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], pb_base_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'phobert_base', pb_base_encode_dict['input_ids'], 'test')\n","\n","#         # pad\n","#         assert ((len(pb_base_entity_1_eids) <= max_len_ent_eid) and (len(pb_base_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n","\n","#         pb_base_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_base_entity_1_eids))\n","#         pb_base_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_base_entity_2_eids))\n","\n","\n","\n","#         if isentif < 10:\n","#             print('\\n')\n","#             print(pb_base_tokenize_lst)\n","#             print(sentif['new_entity_1']['text'])\n","#             print(pb_base_entity_1_eids)\n","#             print(sentif['new_entity_2']['text'])\n","#             print(pb_base_entity_2_eids)\n","\n","\n","\n","#         test_pb_base_input_ids.append(copy.deepcopy(pb_base_encode_dict['input_ids']))\n","#         test_pb_base_attention_masks.append(copy.deepcopy(pb_base_encode_dict['attention_mask']))\n","#         test_pb_base_entity_1_eids.append(copy.deepcopy(pb_base_entity_1_eids))\n","#         test_pb_base_entity_2_eids.append(copy.deepcopy(pb_base_entity_2_eids))\n","#         #test_pb_base_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","\n","\n","#     # if True:\n","#     #     # phobert\n","#     #     # lưu ý: phải để phobert ở bên dưới xlmr_large để những thay đổi bên dưới chỉ ảnh hưởng tới phobert chứ không ảnh hưởng tới XLM-R\n","#     #     # trong các câu chứa các cụm dưới, chả hiểu sao trong phobert '’' khi đứng 1 mình thì encode là 1 wpi bthg\n","#     #     # nhưng đứng trong cụm dưới dưới thì lại thành <unk>\n","#     #     # ta sẽ đổi ’ thành ' thì sẽ k bị lỗi nữa\n","#     #     if ('Hanoi Kids ’ Art Center' in sentif['word_tokenize_lst']) or ('Girl’s Day' in sentif['word_tokenize_lst']) or\\\n","#     #     ('Jermaine O’Neal' in sentif['word_tokenize_lst']) or ('O’Neal' in sentif['word_tokenize_lst']) or\\\n","#     #     ('Kon K’tu' in sentif['word_tokenize_lst']) or ('M’nông' in sentif['word_tokenize_lst']) or\\\n","#     #     ('H’rung' in sentif['word_tokenize_lst']) or ('K’Yếu' in sentif['word_tokenize_lst']) or\\\n","#     #     ('Moody’s' in sentif['word_tokenize_lst']) or ('Las Vegas’s Route' in sentif['word_tokenize_lst']) or\\\n","#     #     ('Women’s Summit' in sentif['word_tokenize_lst']) or ('E’Twaun Moore' in sentif['word_tokenize_lst']) or\\\n","#     #     ('King’s Garden' in sentif['word_tokenize_lst']):\n","#     #         assert (sentif['new_sentence'].count('’') == 1), str('count ’ in new_sentence not equal 1.')\n","\n","#     #         for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n","#     #             if '’' in wtk_item:\n","#     #                 sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","#     #                 break\n","\n","\n","#     #         sentif['new_sentence'] = sentif['new_sentence'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","#     #         sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","#     #         sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n","\n","#     #     if ('Garbinẽ Muguruza' in sentif['word_tokenize_lst']):\n","#     #         assert (sentif['new_sentence'].count('Garbinẽ Muguruza') == 1), str('count Garbinẽ Muguruza in new_sentence not equal 1.')\n","\n","#     #         for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n","#     #             if 'Garbinẽ Muguruza' in wtk_item:\n","#     #                 sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","#     #                 break\n","\n","\n","#     #         sentif['new_sentence'] = sentif['new_sentence'].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","#     #         sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","#     #         sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('Garbinẽ Muguruza', unicodedata.normalize(\"NFC\", \"Garbine Muguruza\"))\n","\n","\n","\n","\n","\n","#     #     pb_large_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n","\n","#     #     pb_large_encode_dict = pb_large_tokenizer(pb_large_input_sent, add_special_tokens=True, padding='max_length', max_length=507)\n","\n","#     #     pb_large_tokenize_lst = pb_large_tokenizer.tokenize(pb_large_input_sent)\n","#     #     assert ((len(pb_large_tokenize_lst) + 2) <= 507), str('len pb_large_tokenize_lst > 507')\n","\n","#     #     pb_large_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], pb_large_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'phobert_large', pb_large_encode_dict['input_ids'], 'test')\n","#     #     pb_large_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], pb_large_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'phobert_large', pb_large_encode_dict['input_ids'], 'test')\n","\n","#     #     # pad\n","#     #     assert ((len(pb_large_entity_1_eids) <= max_len_ent_eid) and (len(pb_large_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n","\n","#     #     pb_large_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_large_entity_1_eids))\n","#     #     pb_large_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_large_entity_2_eids))\n","\n","\n","\n","#     #     if isentif < 10:\n","#     #         print('\\n')\n","#     #         print(pb_large_tokenize_lst)\n","#     #         print(sentif['new_entity_1']['text'])\n","#     #         print(pb_large_entity_1_eids)\n","#     #         print(sentif['new_entity_2']['text'])\n","#     #         print(pb_large_entity_2_eids)\n","\n","\n","\n","#     #     test_pb_large_input_ids.append(copy.deepcopy(pb_large_encode_dict['input_ids']))\n","#     #     test_pb_large_attention_masks.append(copy.deepcopy(pb_large_encode_dict['attention_mask']))\n","#     #     test_pb_large_entity_1_eids.append(copy.deepcopy(pb_large_entity_1_eids))\n","#     #     test_pb_large_entity_2_eids.append(copy.deepcopy(pb_large_entity_2_eids))\n","#     #     #test_pb_large_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","\n","\n","#     test_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n","#     sent_ids.append(copy.deepcopy(sentif['sent_id']))\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-yzwOtCqi13","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# convert to tensor\n","\n","pad_eid = -2\n","\n","\n","test_pb_base_input_ids = torch.tensor(test_pb_base_input_ids)\n","test_pb_base_attention_masks = torch.tensor(test_pb_base_attention_masks)\n","test_pb_base_entity_1_eids = torch.tensor(test_pb_base_entity_1_eids)\n","test_pb_base_entity_2_eids = torch.tensor(test_pb_base_entity_2_eids)\n","#test_pb_labels = torch.tensor(test_pb_labels)\n","\n","# test_xlmr_base_input_ids = torch.tensor(test_xlmr_base_input_ids)\n","# test_xlmr_base_attention_masks = torch.tensor(test_xlmr_base_attention_masks)\n","# test_xlmr_base_entity_1_eids = torch.tensor(test_xlmr_base_entity_1_eids)\n","# test_xlmr_base_entity_2_eids = torch.tensor(test_xlmr_base_entity_2_eids)\n","# #test_xlmr_labels = torch.tensor(test_xlmr_labels)\n","\n","\n","\n","# test_pb_large_input_ids = torch.tensor(test_pb_large_input_ids)\n","# test_pb_large_attention_masks = torch.tensor(test_pb_large_attention_masks)\n","# test_pb_large_entity_1_eids = torch.tensor(test_pb_large_entity_1_eids)\n","# test_pb_large_entity_2_eids = torch.tensor(test_pb_large_entity_2_eids)\n","# #test_pb_labels = torch.tensor(test_pb_labels)\n","\n","\n","\n","# test_xlmr_large_input_ids = torch.tensor(test_xlmr_large_input_ids)\n","# test_xlmr_large_attention_masks = torch.tensor(test_xlmr_large_attention_masks)\n","# test_xlmr_large_entity_1_eids = torch.tensor(test_xlmr_large_entity_1_eids)\n","# test_xlmr_large_entity_2_eids = torch.tensor(test_xlmr_large_entity_2_eids)\n","# #test_xlmr_labels = torch.tensor(test_xlmr_labels)\n","\n","sent_ids = torch.tensor(sent_ids)\n","test_labels = torch.tensor(test_labels)\n","\n","print('DONE')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXbHGBay7ZhL","executionInfo":{"status":"aborted","timestamp":1717425279842,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# print(torch.all(torch.eq(test_pb_base_input_ids, test_pb_large_input_ids)))\n","# print(torch.all(torch.eq(test_pb_base_attention_masks, test_pb_large_attention_masks)))\n","# print(torch.all(torch.eq(test_pb_base_entity_1_eids, test_pb_large_entity_1_eids)))\n","# print(torch.all(torch.eq(test_pb_base_entity_2_eids, test_pb_large_entity_2_eids)))\n","\n","# print(torch.all(torch.eq(test_xlmr_base_input_ids, test_xlmr_large_input_ids)))\n","# print(torch.all(torch.eq(test_xlmr_base_attention_masks, test_xlmr_large_attention_masks)))\n","# print(torch.all(torch.eq(test_xlmr_base_entity_1_eids, test_xlmr_large_entity_1_eids)))\n","# print(torch.all(torch.eq(test_xlmr_base_entity_2_eids, test_xlmr_large_entity_2_eids)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOlIRV0x8suz","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["test_pb_input_ids = copy.deepcopy(test_pb_base_input_ids)\n","test_pb_attention_masks = copy.deepcopy(test_pb_base_attention_masks)\n","test_pb_entity_1_eids = copy.deepcopy(test_pb_base_entity_1_eids)\n","test_pb_entity_2_eids = copy.deepcopy(test_pb_base_entity_2_eids)\n","#test_pb_labels = torch.tensor(test_pb_labels)\n","\n","# test_xlmr_input_ids = copy.deepcopy(test_xlmr_base_input_ids)\n","# test_xlmr_attention_masks = copy.deepcopy(test_xlmr_base_attention_masks)\n","# test_xlmr_entity_1_eids = copy.deepcopy(test_xlmr_base_entity_1_eids)\n","# test_xlmr_entity_2_eids = copy.deepcopy(test_xlmr_base_entity_2_eids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQnGMcvkDajP","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["'''\n","if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n","    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, \\\n","                                  train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids, \\\n","                                  train_labels)\n","\n","elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n","    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, train_labels)\n","\n","elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n","    train_dataset = TensorDataset(train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids, train_labels)\n","'''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYAF_MORQfQi","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["#train_dataloader = DataLoader(train_dataset, batch_size=flags['batch_size'], shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-2w44XoqKy_P"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"JP4BFfO0cVk1","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["class BERTModel(nn.Module):\n","    def __init__(self, model_type, entity_handle_type, emb_layer_lst, emb_layer_handle_type):\n","        super().__init__()\n","\n","        self.model_type = model_type\n","\n","        if self.model_type == 'phobert_base':\n","            print('Using ', self.model_type, '.')\n","            self.bert_model = AutoModel.from_pretrained(\"vinai/phobert-base\", output_hidden_states=True)\n","\n","        elif self.model_type == 'phobert_large':\n","            print('Using ', self.model_type, '.')\n","            self.bert_model = AutoModel.from_pretrained(\"vinai/phobert-large\", output_hidden_states=True)\n","\n","        elif self.model_type == 'xlmr_base':\n","            print('Using ', self.model_type, '.')\n","            self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base', output_hidden_states=True)\n","\n","        elif self.model_type == 'xlmr_large':\n","            print('Using ', self.model_type, '.')\n","            self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-large', output_hidden_states=True)\n","\n","        else:\n","            assert False, str('Unkown model name: ' + self.model_type + '. Allow: phobert_base, phobert_large, xlmr_base, xlmr_large')\n","\n","\n","        self.entity_handle_type = entity_handle_type\n","        self.emb_layer_lst = emb_layer_lst\n","        self.emb_layer_handle_type = emb_layer_handle_type\n","\n","        # dùng để kiểm tra 1 phần xem code có chạy ổn không\n","        self.sent_emb_len, self.wpi_emb_len = self.calculate_len_embedding()\n","\n","\n","\n","    def forward(self, b_input_ids, b_attention_mask, b_entity_1_eids, b_entity_2_eids):\n","\n","        outputs = self.bert_model(b_input_ids, b_attention_mask)\n","\n","        # num_layer (13) * batch_size * max_sent_len * emb_size\n","        hidden_states = outputs[2]\n","\n","        b_sent_final_embedding = self.get_sent_final_vector(hidden_states, b_entity_1_eids, b_entity_2_eids)\n","\n","        return b_sent_final_embedding\n","\n","\n","    '''\n","\n","    hàm dưới sẽ duyệt từng cặp enitty trong 1 câu\n","    sau đó tìm vector đại diện cho từng entity trong cặp này -> 2 vector embedding đại diện cho 2 entity\n","    từ 2 vector này ta sẽ kết hợp lại theo luật dưới, rồi concat lại với nhau\n","    [h_s,h_t,h_s*h_t,h_s+h_t,|h_s-h_t|]\n","    cuối cùng sẽ thu được 1 vector duy nhất đại diện cho câu, và vector này có thể dùng cho lớp linear,... để phân loại\n","\n","    Lưu ý: hàm này sẽ trả về batch vector đại diện cho batch câu\n","    '''\n","    def get_sent_final_vector(self, hidden_states, b_entity_1_eids, b_entity_2_eids):\n","\n","        assert (len(b_entity_1_eids) == len(b_entity_2_eids)), str('len(b_entity_1_eids) != len(b_entity_2_eids)')\n","\n","        sent_final_embedding_lst = []\n","\n","        for isent in range(len(b_entity_1_eids)):   # từng câu 1 trong batch\n","\n","\n","            entity_1_final_vector = self.get_entity_embedding_vector(hidden_states, b_entity_1_eids[isent], isent)\n","            entity_2_final_vector = self.get_entity_embedding_vector(hidden_states, b_entity_2_eids[isent], isent)\n","\n","            assert (entity_1_final_vector.size() == entity_2_final_vector.size()), str('entity_1_final_vector size != entity_2_final_vector size')\n","\n","            # not implement custom emb stack yet\n","            entity_sum_vector = torch.add(entity_1_final_vector, entity_2_final_vector)\n","            entity_mul_vector = torch.mul(entity_1_final_vector, entity_2_final_vector)\n","            entity_abs_sub_vector = torch.abs(torch.sub(entity_1_final_vector, entity_2_final_vector))\n","\n","            # [h_s,h_t,h_s*h_t,h_s+h_t,|h_s-h_t|]\n","            sent_final_vector = torch.cat((entity_1_final_vector, entity_2_final_vector, entity_mul_vector, entity_sum_vector, entity_abs_sub_vector))\n","\n","            assert (len(sent_final_vector.size()) == 1), str('sent_final_vector is not a vector')\n","\n","            assert (sent_final_vector.size()[0] == self.sent_emb_len), str('sent_emb_len is not: ' + str(self.sent_emb_len))\n","\n","\n","            sent_final_embedding_lst.append(sent_final_vector)\n","\n","\n","        assert (len(sent_final_embedding_lst) == len(b_entity_1_eids)), str(self.model_type + ': len batch sent embedding not qual batch_size.')\n","        sent_final_embedding_lst = torch.stack(sent_final_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","\n","\n","        return sent_final_embedding_lst\n","\n","\n","\n","\n","\n","    '''\n","    hàm dưới dùng để lấy ra 1 vector embedding đại diện duy nhất cho 1 entity\n","    đầu tiên, duyệt từng word pice trong danh sách cách word piece của entity\n","\n","    với mỗi word pice, ta sẽ lấy embedding của word piece này ở các layer mà ta muốn sau đó gộp thành 1 vector đại diện cho word pice duy nhất\n","    tức là ví dụ: với mỗi word piece ta sẽ lấy các embedding của word piece này trong 4 layer cuối -> 4 vector từ 4 layer cho 1 word pice,\n","    sau đó ta có thể sum element wise 4 vector này để ra 1 vector duy nhất đại diện cho word piece\n","\n","    cuối cùng ta sẽ có 1 list các embedding (đại diện) của các word piece trong 1 entity\n","    từ các embedding này ta có thể chọn ngẫu nhiên 1 cái hoăc lấy max pooling các embedding này để ra 1 vector duy nhất cho 1 entity\n","    '''\n","    def get_entity_embedding_vector(self, hidden_states, entity_eids, isent):\n","\n","        entity_wpi_embedding_lst = []\n","        for ient_eid, entity_eid in enumerate(entity_eids):                    # từng word piece của entity\n","\n","            if entity_eid < 0:  # nếu gặp padding wpi (-2) thì dừng\n","                if not (ient_eid > 0):\n","                    print('EORRRRRRRRRRRRRRR')\n","                    print(entity_eids)\n","                    print(isent)\n","                    assert False, str('No wpi id')\n","                break\n","\n","            wpi_final_vector = None\n","            wpi_embedding_lst = []\n","            # thu thập mọi vector trong các layer muốn lấy của 1 word piece\n","            for emb_layer in self.emb_layer_lst:          # từng layer mà ta muốn lấy embedding\n","                wpi_embedding_lst.append(hidden_states[emb_layer-1][isent][entity_eid])\n","\n","            # xử lý embedding thuộc các layer khác nhau của 1 word piece\n","            if self.emb_layer_handle_type == 'sum':\n","                wpi_embedding_lst = torch.stack(wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","                wpi_final_vector = torch.sum(wpi_embedding_lst, dim=0)\n","\n","            elif self.emb_layer_handle_type == 'concat':\n","                wpi_final_vector = torch.cat(wpi_embedding_lst)\n","\n","            elif self.emb_layer_handle_type == 'max_pooling':\n","                wpi_embedding_lst = torch.stack(wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","                wpi_final_vector = torch.max(wpi_embedding_lst, dim=0).values\n","\n","            elif self.emb_layer_handle_type == 'average_pooling':\n","                wpi_embedding_lst = torch.stack(wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","                wpi_final_vector = torch.mean(wpi_embedding_lst, dim=0)\n","\n","            else:\n","                assert False, \\\n","                str(self.model_type + ': Unknow emb_layer_handle_type: ' + self.emb_layer_handle_type + '. Allow: sum, concat, max_pooling, average_pooling.')\n","\n","            assert (len(wpi_final_vector.size()) == 1), str('entity_final_vector is not a vector.')\n","            assert (wpi_final_vector.size()[0] == self.wpi_emb_len), str('wpi_emb_len is not: ' + str(self.wpi_emb_len))\n","\n","            entity_wpi_embedding_lst.append(wpi_final_vector)\n","\n","\n","        assert (len(entity_wpi_embedding_lst) > 0), str('entity_wpi_embedding_lst is empty.')\n","\n","        # xử lý embedding của mọi word piece trong 1 entity\n","        if self.entity_handle_type == 'max_pooling':\n","            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","            entity_final_vector = torch.max(entity_wpi_embedding_lst, dim=0).values\n","\n","        elif self.entity_handle_type == 'average_pooling':\n","            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","            entity_final_vector = torch.mean(entity_wpi_embedding_lst, dim=0)\n","\n","        elif self.entity_handle_type == 'sum':\n","            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","            entity_final_vector = torch.sum(entity_wpi_embedding_lst, dim=0)\n","\n","        elif self.entity_handle_type == 'random':\n","            rand_index = torch.randint(len(entity_wpi_embedding_lst), (1,))\n","            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n","            entity_final_vector = entity_wpi_embedding_lst[rand_index][0]\n","\n","        else:\n","            assert False, \\\n","            str(self.model_type + ': Unknow entity_handle_type: ' + self.entity_handle_type + '. Allow: max_pooling, average_pooling, sum, random.')\n","\n","\n","        assert (len(entity_final_vector.size()) == 1), str('entity_final_vector is not a vector.')\n","\n","        assert (entity_final_vector.size()[0] == self.wpi_emb_len), str('entity_final_vector is not equal wpi_emb_len: ' + str(self.wpi_emb_len))\n","\n","\n","        return entity_final_vector\n","\n","\n","\n","    #  tính len của vector đại diện cho câu\n","    def calculate_len_embedding(self):\n","\n","        if (self.model_type == 'phobert_base') or (self.model_type == 'xlmr_base'):\n","            wpi_emb_len = 768\n","        elif self.model_type == 'phobert_large' or (self.model_type == 'xlmr_large'):\n","            wpi_emb_len = 1024\n","        else:\n","            assert False, str('Unkown model name: ' + self.model_type + '. Allow: phobert_base, phobert_large, xlmr_base, xlmr_large')\n","\n","        # do entity thì ta chỉ max, average pooling hoặc lấy sum các word piece nên độ dài sẽ bằng luôn độ dài vector đại diện word piece\n","        # nếu không phải concat thì chiều vector đại diện wordpiece sẽ giữ nguyên\n","        if (self.emb_layer_handle_type == 'sum') or (self.emb_layer_handle_type == 'max_pooling') \\\n","        or (self.emb_layer_handle_type == 'average_pooling'):\n","            entity_emb_len = wpi_emb_len\n","\n","        # nếu là concat thì chiều vector đại diện wordpiece sẽ nhân với số layer concat\n","        elif self.emb_layer_handle_type == 'concat':\n","            wpi_emb_len = wpi_emb_len * len(self.emb_layer_lst)\n","            entity_emb_len = wpi_emb_len\n","        else:\n","            assert False, \\\n","            str(self.model_type + ': Unknow emb_layer_handle_type: ' + self.emb_layer_handle_type + '. Allow: sum, concat, max_pooling, average_pooling.')\n","\n","\n","\n","        # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n","        # sau này nếu đổi\n","        sent_emb_len = entity_emb_len * 5\n","\n","\n","        return sent_emb_len, wpi_emb_len\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMBOFVoQYLQv","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["class REClassifier(nn.Module):\n","\n","    def __init__(self, flags):\n","        super().__init__()\n","\n","\n","        if flags['use_phobert'] == True:\n","            self.pb_model = BERTModel(flags['phobert_model'], flags['pb_entity_handle_type'], flags['pb_emb_layer_lst'], flags['pb_emb_layer_handle_type'])\n","            pb_sent_emb_len = self.calculate_len_sent_embedding(flags['phobert_model'], flags['pb_emb_layer_lst'], flags['pb_emb_layer_handle_type'])\n","\n","        if flags['use_xlmr'] == True:\n","            self.xlmr_model = BERTModel(flags['xlmr_model'], flags['xlmr_entity_handle_type'], flags['xlmr_emb_layer_lst'], flags['xlmr_emb_layer_handle_type'])\n","            xlmr_sent_emb_len = self.calculate_len_sent_embedding(flags['xlmr_model'], flags['xlmr_emb_layer_lst'], flags['xlmr_emb_layer_handle_type'])\n","\n","        if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n","            self.final_sent_emb_len = pb_sent_emb_len + xlmr_sent_emb_len\n","\n","        elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n","            self.final_sent_emb_len = pb_sent_emb_len\n","\n","        elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n","            self.final_sent_emb_len = xlmr_sent_emb_len\n","\n","\n","        self.flags = flags\n","\n","        self.dropout1 = nn.Dropout(p=flags['dropout1_rate'])\n","        self.linear1 = nn.Linear(self.final_sent_emb_len, flags['out_linear1'])\n","        self.dropout2 = nn.Dropout(p=flags['dropout2_rate'])\n","        self.linear2 = nn.Linear(flags['out_linear1'], 8)\n","\n","\n","\n","    def forward(self, pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n","                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids):\n","\n","        if (self.flags['use_phobert'] == True) and (self.flags['use_xlmr'] == True):\n","\n","\n","            pb_sent_final_embedding = self.pb_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n","            xlmr_sent_final_embedding = self.xlmr_model(xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n","\n","            # concat two embedding\n","            bert_sent_final_embedding = torch.cat((pb_sent_final_embedding, xlmr_sent_final_embedding), dim=1)\n","\n","            assert (len(bert_sent_final_embedding.size()) == 2) and (bert_sent_final_embedding.size()[0] == pb_sent_final_embedding.size()[0]) \\\n","            and (bert_sent_final_embedding.size()[0] == xlmr_sent_final_embedding.size()[0]) \\\n","            and (bert_sent_final_embedding.size()[1] == self.final_sent_emb_len), \\\n","            str('REClassifier: PROBLEM WITH sent_final_embedding len.')\n","\n","        elif (self.flags['use_phobert'] == True) and (self.flags['use_xlmr'] == False):\n","\n","\n","            bert_sent_final_embedding = self.pb_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n","\n","            assert (bert_sent_final_embedding.size()[1] == self.final_sent_emb_len), \\\n","            str('REClassifier: PROBLEM WITH sent_final_embedding len.')\n","\n","\n","        elif (self.flags['use_phobert'] == False) and (self.flags['use_xlmr'] == True):\n","\n","\n","            bert_sent_final_embedding = self.xlmr_model(xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n","\n","            assert (bert_sent_final_embedding.size()[1] == self.final_sent_emb_len), \\\n","            str('REClassifier: PROBLEM WITH sent_final_embedding len.')\n","\n","\n","        x = self.dropout1(bert_sent_final_embedding)\n","        x = self.linear1(x)\n","        x = self.dropout2(x)\n","        x = self.linear2(x)\n","\n","        return x\n","\n","\n","\n","    #  tính len của vector đại diện cho câu\n","    def calculate_len_sent_embedding(self, model_type, emb_layer_lst, emb_layer_handle_type):\n","\n","        if (model_type == 'phobert_base') or (model_type == 'xlmr_base'):\n","            wpi_emb_len = 768\n","        elif (model_type == 'phobert_large') or (model_type == 'xlmr_large'):\n","            wpi_emb_len = 1024\n","        else:\n","            assert False, str('Unkown model name: ' + model_type + '. Allow: phobert_base, phobert_large, xlmr_base, xlmr_large')\n","\n","        # do entity thì ta chỉ max, average pooling hoặc lấy sum các word piece nên độ dài sẽ bằng luôn độ dài vector đại diện word piece\n","        # nếu không phải concat thì chiều vector đại diện wordpiece sẽ giữ nguyên\n","        if (emb_layer_handle_type == 'sum') or (emb_layer_handle_type == 'max_pooling') \\\n","        or (emb_layer_handle_type == 'average_pooling'):\n","            entity_emb_len = wpi_emb_len\n","\n","        # nếu là concat thì chiều vector đại diện wordpiece sẽ nhân với số layer concat\n","        elif emb_layer_handle_type == 'concat':\n","            wpi_emb_len = wpi_emb_len * len(emb_layer_lst)\n","            entity_emb_len = wpi_emb_len\n","        else:\n","            assert False, \\\n","            str(model_type + ': Unknow emb_layer_handle_type: ' + emb_layer_handle_type + '. Allow: sum, concat, max_pooling, average_pooling.')\n","\n","\n","\n","        # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n","        # sau này nếu đổi\n","        sent_emb_len = entity_emb_len * 5\n","\n","\n","        return sent_emb_len\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8TJjwwBgu32B"},"source":["## Trainer"]},{"cell_type":"markdown","metadata":{"id":"k7SbTS2ol2bC"},"source":["### test_dataset"]},{"cell_type":"code","metadata":{"id":"jDc6lLJGlijU","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["test_dataset = TensorDataset(test_pb_input_ids, test_pb_attention_masks, test_pb_entity_1_eids, test_pb_entity_2_eids, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d8ulUGZfMIjh"},"source":["### Main\n","\n"]},{"cell_type":"code","metadata":{"id":"lxdvAntREnO1","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n9HUHFe0QRKc","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7epI-VsS9QF"},"source":["**YOU NEED TO CHANGE THE PATH TO YOUR MODEL.BIN AND FLAGS.TXT**"]},{"cell_type":"code","metadata":{"id":"FQ8AL8A9AFdi","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["model_1_path = '/gdrive/MyDrive/rec_model_micro_6.bin'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kzez-ChQqWm","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["with open('/gdrive/MyDrive//flags.txt', 'r') as f:\n","    model_1_flags = json.load(f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hMwCnvoNxVCo","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["if torch.cuda.is_available():\n","    # Tell PyTorch to use the GPU.\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwM2q4CifcO7","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["re_model_1 = REClassifier(model_1_flags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ob3FyMLQw9TN","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["re_model_1.load_state_dict(torch.load(model_1_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlYSevWpTZfc","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["def decode_label(sentence_label):\n","    label = -1\n","    if sentence_label == 0:\n","        label = \"LOCATED\"\n","    elif sentence_label == 1:\n","        label = \"PART_WHOLE\"\n","    elif sentence_label == 2:\n","        label = \"PERSONAL_SOCIAL\"\n","    elif sentence_label == 3:\n","        label = \"AFFILIATION\"\n","    elif sentence_label == 4:\n","        label = \"IS_LOCATED\"\n","    elif sentence_label == 5:\n","        label = \"WHOLE_PART\"\n","    elif sentence_label == 6:\n","        label = \"AFFILIATION_TO\"\n","    elif sentence_label == 7:\n","        label = \"OTHERS\"\n","    else:\n","        assert False, \"UNKNOWN LABEL\"\n","\n","    return label\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I77dIVAa4XYZ","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["re_model_1.to(device)\n","\n","re_model_1.eval()\n","\n","model_1_outputs = []\n","\n","dev_predict_lst = []\n","dev_target_lst = []\n","\n","\n","with torch.no_grad():\n","\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset,\n","        sampler = torch.utils.data.SequentialSampler(test_dataset),\n","        batch_size=32)\n","\n","    for batch_num, batch in enumerate(test_loader):\n","        if batch_num % 30 == 0:\n","            print(batch_num)\n","\n","        # pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n","        # xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids, targets, sent_id = \\\n","        # batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), \\\n","        # batch[4].to(device), batch[5].to(device), batch[6].to(device), batch[7].to(device), batch[8].to(device), batch[9].to(device)\n","\n","        pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, targets = \\\n","                batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device)\n","\n","        # Acquires the network's best guesses at each class\n","        # output = re_model_1(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n","        #                         xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n","\n","        # output = re_model_1(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n","        #                        xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n","\n","        output = re_model_1(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, None, None, None, None)\n","\n","        dev_predict_lst.append(torch.argmax(output, 1))\n","        dev_target_lst.append(targets)\n","        # labels = torch.argmax(output, dim=1)\n","\n","        # labels_decoded = [decode_label(label) for label in labels]\n","\n","        # model_1_outputs.extend(copy.deepcopy(labels_decoded))\n","    dev_predict_lst = torch.cat(dev_predict_lst).to(torch.device(\"cpu\"))\n","    dev_target_lst = torch.cat(dev_target_lst).to(torch.device(\"cpu\"))\n","\n","    dev_f1_macro = sklearn.metrics.f1_score(list(dev_target_lst), list(dev_predict_lst), average='macro')\n","    dev_f1_micro = sklearn.metrics.f1_score(list(dev_target_lst), list(dev_predict_lst), average='micro')\n","\n","    print('Finish eval epoch: ', epoch, ' after: ', (time.time() - eval_start_time))\n","    print('dev_f1_macro: ', dev_f1_macro, ' -  dev_f1_micro: ', dev_f1_micro)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NG-9bMJ5r53","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["model_1_results = copy.deepcopy(jtest_data_v3)\n","\n","for i in range(len(jtest_data_v3)):\n","    model_1_results[i]['label'] = copy.deepcopy(model_1_outputs[i])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BhdS2eARwPe","executionInfo":{"status":"aborted","timestamp":1717425279843,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Chí Dũng","userId":"12772378414475579913"}}},"source":["# review\n","for i in range(len(model_1_results)):\n","    if model_1_results[i]['label'] != 'OTHERS':\n","        print(model_1_results[i])"],"execution_count":null,"outputs":[]}]}